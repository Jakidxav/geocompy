[
  {
    "objectID": "index.html#motivations",
    "href": "index.html#motivations",
    "title": "Geocomputation with Python",
    "section": "1.1 Motivations",
    "text": "1.1 Motivations\nGeocomputation with Python, is motivated by the need for an introductory yet rigorous and maintained resource on working with geographic data in Python. A unique feature of the book is that it that demonstrates code for working with both vector and raster geographic data types.  There are many resources on Python packages for geographic research and various applications but, to the best of our knowledge, no other resource brings together the following features into a single home:\n\nSmall introductory textbook focuses on doing basic operations well\nIntegration of vector and raster datasets in the same book, and within each section\nClear explanation of the code and exercises to maximize learning for newcomers\nProvision of lucid example datasets and meaningful operations to illustrate the applied nature of geographic research\n\nThe book aims to supplement other resources in the ecosystem, as highlighted by comparison with the book’s scope with existing and in-progress works:\n\nLearning Geospatial Analysis with Python and Geoprocessing with Python focuses on processing spatial data using low-level Python interfaces for GDAL, such as the gdal, gdalnumeric, and ogr packages from osgeo. This approach is more complex, less “Pythonic”, and perhaps outdated in light of development of packages such as geopandas and rasterio covered here\npythongis.org (at an early stage of development) seeks to provide a general introduction to ‘GIS in Python’, with parts focusing on Python essentials, using Python with GIS, and case studies. Compared with pythongis.org, geocompy has a relatively narrow scope (1) and a greater focus on raster-vector interoperability\ngeographicdata.science is an ambitious project with chapters dedicated to advanced topics, with Chapter 4 on Spatial Weights getting into complex topics relatively early, for example. Geocompy would be shorter, simpler and more introductory, and cover raster and vector data with equal importance (1 to 4)\n\nGeocompy is a sister project of Geocomputation with R – a book on geographic data analysis, visualization, and modeling using the R programming language."
  },
  {
    "objectID": "index.html#reproducing-this-book",
    "href": "index.html#reproducing-this-book",
    "title": "Geocomputation with Python",
    "section": "1.2 Reproducing this book",
    "text": "1.2 Reproducing this book\nAn important aspect of scientific research and ‘citizen science’ that is participatory is reproducibility of results.\nTo reproduce this book you can simply click on the link below to see the code running in your web browser (see details of how this works at mybinder.org):\n\n\n\nBinder\n\n\nTo run the code locally, recommended for using the material on real data, you need to have a reasonable computer, e.g. with 8 GB RAM. You’ll need administrative rights to install the requirements, which include:\n\nA suitable integrated development environment (IDE) such as VS Code, RStudio or Jupyter Notebook\nQuarto, if you want to reproduce the book’s open access website\nEither an Anaconda-like environment (we recommend miniconda3) or Docker to get systems dependencies\n\nSee the project’s README for details on getting set-up. After you have installed the necessary dependencies and cloned or unzipped the book’s source code, you should be able to reproduce the code in its entirety with the following command:\nquarto preview\nIf you see output like that below (with the IDE and browser arranged to see live updates after editing the source code), congratulations, it has worked!"
  },
  {
    "objectID": "02-spatial-data.html#introduction",
    "href": "02-spatial-data.html#introduction",
    "title": "2  Geographic data in Python",
    "section": "2.1 Introduction",
    "text": "2.1 Introduction\nThis chapter introduces key Python packages and data structures for working with the two major types of spatial data, namely:\n\nshapely and geopandas — for working with vector layers\nrasterio and xarray — for working with rasters\n\nAs we will see in the code chunks presented later in this chapter, shapely and geopandas are related:\n\nshapely is a “low-level” package for working with individual vector geometry objects\ngeopandas is a “high-level” package for working with geometry columns (GeoSeries objects), which internally contain shapely geometries, and vector layers (GeoDataFrame objects)\n\nWhile geopandas (including its shapely dependency), at present, comprises a ubiquitous comprehensive approach for working with vector layers in Python, this is not the case for rasters. Work with rasters in Python is much less unified. There are several alternative packages, each with its own advantages and disadvantages. We focus on the two most comprehensive and fundamental packages, namely:\n\nrasterio — a spatial-oriented package, focused on “simple” raster formats (such as GeoTIFF), representing a raster using a combination of a numpy array, and a metadata object (dict) specifying the spatial referencing of the array\nxarray — A general-purpose package for working with labeled arrays, thus advantageous for processing “complex” raster format (such as NetCDF), representing a raster using its own native classes, namely xarray.Dataset and xarray.DataArray\n\nThis chapter will briefly explain the fundamental geographic data models: vector and raster. Before demonstrating their implementation in Python, we will introduce the theory behind each data model and the disciplines in which they predominate.\nThe vector data model represents the world using points, lines, and polygons. These have discrete, well-defined borders, meaning that vector datasets usually have a high level of precision (but not necessarily accuracy, as we will see in Section …). The raster data model divides the surface up into cells of constant size. Raster datasets are the basis of background images used in web-mapping and have been a vital source of geographic data since the origins of aerial photography and satellite-based remote sensing devices. Rasters aggregate spatially specific features to a given resolution, meaning that they are consistent over space and scalable (many worldwide raster datasets are available).\nWhich to use? The answer likely depends on your domain of application:\n\nVector data tends to dominate the social sciences because human settlements tend to have discrete borders\nRaster dominates many environmental sciences because of the reliance on remote sensing data\n\nThere is much overlap in some fields, and raster and vector datasets can be used together: ecologists and demographers, for example, commonly use both vector and raster data. Furthermore, it is possible to convert between the two forms (see Section …). Whether your work involves more use of vector or raster datasets, it is worth understanding the underlying data model before using them, as discussed in subsequent chapters. This book mostly uses geopandas and rasterio packages to work with vector data and raster datasets, respectively."
  },
  {
    "objectID": "02-spatial-data.html#vector-data",
    "href": "02-spatial-data.html#vector-data",
    "title": "2  Geographic data in Python",
    "section": "2.2 Vector data",
    "text": "2.2 Vector data\nThe geographic vector data model is based on points located within a coordinate reference system (CRS). Points can represent self-standing features (e.g., the location of a bus stop), or they can be linked together to form more complex geometries such as lines and polygons. Most point geometries contain only two dimensions (3-dimensional CRSs contain an additional \\(z\\) value, typically representing height above sea level).\nIn this system, London, for example, can be represented by the coordinates (-0.1, 51.5). This means that its location is -0.1 degrees east and 51.5 degrees north of the origin. The origin, in this case, is at 0 degrees longitude (the Prime Meridian) and 0 degree latitude (the Equator) in a geographic (‘lon/lat’) CRS (Figure …, left panel). The same point could also be approximated in a projected CRS with ‘Easting/Northing’ values of (530000, 180000) in the British National Grid, meaning that London is located 530 \\(km\\) East and 180 \\(km\\) North of the origin of the CRS. This can be verified visually: slightly more than 5 ‘boxes’—square areas bounded by the gray grid lines 100 \\(km\\) in width—separate the point representing London from the origin (Figure 2.1, right panel).\nThe location of National Grid’s origin, in the sea beyond South West Peninsular, ensures that most locations in the UK have positive Easting and Northing values. There is more to CRSs, as described in Sections … and … but, for the purposes of this section, it is sufficient to know that coordinates consist of two numbers representing the distance from an origin, usually in \\(x\\) then \\(y\\) dimensions.\n… FIGURE …: Illustration of vector (point) data in which location of London (the red X) is represented with reference to an origin (the blue circle). The left plot represents a geographic CRS with an origin at 0° longitude and latitude. The right plot represents a projected CRS with an origin located in the sea west of the South West Peninsula.\ngeopandas provides classes for geographic vector data and a consistent command-line interface to important low-level libraries for geocomputation:\n\nGDAL, for reading, writing, and manipulating a wide range of geographic data formats, covered in Chapter 8\nPROJ, a powerful library for coordinate system transformations, which underlies the content covered in Chapter 7\nGEOS, a planar geometry engine for operations such as calculating buffers and centroids on data with a projected CRS, covered in Chapter 5\n\nNowadays, we take it for granted, however, only the tight integration with different geographic libraries makes reproducible geocomputation possible in the first place.\nThis section introduces geopandas classes in preparation for subsequent chapters (Chapters 5 and 8 cover the GEOS and GDAL interface, respectively).\n\n2.2.1 Introduction\nWhen introducing the packages for working with vector layers in Python, we are going to go from the complex class (vector layer), through the intermediate (geometry column), to the simple (geometry). As we will see, the three classes are hierarchical, meaning that the complex encompasses the simple:\n\nA vector layer (class GeoDataFrame) contains a geometry column (class GeoSeries) as one of the columns\nA geometry column (class GeoSeries) is composed of individual geometries (class shapely)\n\nThe first two classes (GeoDataFrame and GeoSeries) are defined in package geopandas. The third class is defined in package shapely, which deals with individual geometries, and is a main dependency of the geopandas package.\n\n\n2.2.2 Vector layers\nThe typical data structure for vector data is a vector layer. There are several methods to work with vector layers in Python, ranging from low-level (e.g., osgeo, fiona) to high-level (geopandas). In this book, we focus on geopandas.\nBefore we begin, we need to import the geopandas package, conventionally as gpd:\n\nimport geopandas as gpd\n\n/usr/local/lib/python3.8/dist-packages/geopandas/_compat.py:112: UserWarning: The Shapely GEOS version (3.10.2-CAPI-1.16.0) is incompatible with the GEOS version PyGEOS was compiled with (3.10.1-CAPI-1.16.0). Conversions between both will be slow.\n  warnings.warn(\n\n\nWe also limit the maximum number of printed rows to four, to save space, using the \"display.max_rows\" option of pandas:\n\nimport pandas as pd\npd.set_option(\"display.max_rows\", 4)\n\nMost often, we import an existing vector layer from a file, such as an ESRI Shapefile (.shp) or a GeoPackage (.gpkg) file. For example, the following line of code imports a GeoPackage file data/world.gpkg into a GeoDataFrame named gdf:\n\ngdf = gpd.read_file(\"data/world.gpkg\")\n\nThe result is a GeoDataFrame with 177 rows (features) and 11 columns:\n\ntype(gdf)\n\ngeopandas.geodataframe.GeoDataFrame\n\n\nThe GeoDataFrame class is an extension of the DataFrame class. Thus, we can treat a vector layer as a table, and process it using the ordinary, i.e., non-spatial, pandas methods. For example, the following expression creates a subset with just the country name and the geometry (see below):\n\ngdf = gdf[[\"name_long\", \"geometry\"]]\ngdf\n\n\n\n\n  \n    \n      \n      name_long\n      geometry\n    \n  \n  \n    \n      0\n      Fiji\n      MULTIPOLYGON (((-180.00000 -16.55522, -179.917...\n    \n    \n      1\n      Tanzania\n      MULTIPOLYGON (((33.90371 -0.95000, 31.86617 -1...\n    \n    \n      ...\n      ...\n      ...\n    \n    \n      175\n      Trinidad and Tobago\n      MULTIPOLYGON (((-61.68000 10.76000, -61.66000 ...\n    \n    \n      176\n      South Sudan\n      MULTIPOLYGON (((30.83385 3.50917, 31.24556 3.7...\n    \n  \n\n177 rows × 2 columns\n\n\n\nThe following expression creates a subset based on a condition, such as equality of the \"name_long\" column to the string \"Egypt\":\n\ngdf[gdf[\"name_long\"] == \"Egypt\"]\n\n\n\n\n  \n    \n      \n      name_long\n      geometry\n    \n  \n  \n    \n      163\n      Egypt\n      MULTIPOLYGON (((36.86623 22.00000, 36.69069 22...\n    \n  \n\n\n\n\nFinally, to get a sense of the spatial component of the vector layer, it can be plotted using the .plot method, as follows:\n\ngdf.plot();\n\n\n\n\nor using .explore to get an interactive plot:\n\ngdf.explore()\n\nMake this Notebook Trusted to load map: File -> Trust Notebook\n\n\n\n\n2.2.3 Geometry columns\nOne of the columns in a GeoDataFrame is a geometry column, of class GeoSeries. The geometry column contains the geometric part of the vector layer, e.g., the \"MultiPolygon\" geometries of the 177 countries in gdf:\n\ngdf[\"geometry\"]\n\n0      MULTIPOLYGON (((-180.00000 -16.55522, -179.917...\n1      MULTIPOLYGON (((33.90371 -0.95000, 31.86617 -1...\n                             ...                        \n175    MULTIPOLYGON (((-61.68000 10.76000, -61.66000 ...\n176    MULTIPOLYGON (((30.83385 3.50917, 31.24556 3.7...\nName: geometry, Length: 177, dtype: geometry\n\n\nThe geometry column also contains the spatial reference information, if any (see below).\nMany of the spatial operators, such as calculating the centroid, buffer, or bounding box of each feature, in fact involve just the geometry. Applying this type of operation on a GeoDataFrame is therefore basically a shortcut to applying it on the geometry column GeoSeries. For example, the following expressions give exactly the same result, a GeoSeries with country centroids (results not shown):\n\ngdf.centroid\n\n\ngdf[\"geometry\"].centroid\n\nAnother useful property of the geometry column is the geometry type (see below). Note that the types of geometries contained in a geometry column (and, thus, a vector layer) are not necessarily the same. Accordingly, the .type property returns a Series (of type string), rather than a single value:\n\ngdf[\"geometry\"].type\n\n0      MultiPolygon\n1      MultiPolygon\n           ...     \n175    MultiPolygon\n176    MultiPolygon\nLength: 177, dtype: object\n\n\nTo summarize the occurrence of different geometry types in a geometry column, we can use the pandas method called value_counts:\n\ngdf[\"geometry\"].type.value_counts()\n\nMultiPolygon    177\ndtype: int64\n\n\nIn this case, we see that the gdf layer contains only \"MultiPolygon\" geometries.\n\n\n2.2.4 The Simple Features standard\nGeometries are the basic building blocks of vector layers. Although the Simple Features standard defines about 20 types of geometries, we will focus on the seven most commonly used types: POINT, LINESTRING, POLYGON, MULTIPOINT, MULTILINESTRING, MULTIPOLYGON and GEOMETRYCOLLECTION. Find the whole list of possible feature types in the PostGIS manual.\nGenerally, well-known binary (WKB) or well-known text (WKT) are the standard encodings for simple feature geometries. WKB representations are usually hexadecimal strings easily readable for computers. This is why GIS and spatial databases use WKB to transfer and store geometry objects. WKT, on the other hand, is a human-readable text markup description of simple features. Both formats are exchangeable, and if we present one, we will naturally choose the WKT representation.\nThe basis for each geometry type is the point. A point is simply a coordinate in 2D, 3D, or 4D space such as (see the left panel in Figure …):\nPOINT (5 2)\nA linestring is a sequence of points with a straight line connecting the points, for example (see middle panel in Figure …):\nLINESTRING (1 5, 4 4, 4 1, 2 2, 3 2)\nA polygon is a sequence of points that form a closed, non-intersecting ring. Closed means that the first and the last point of a polygon have the same coordinates (see right panel in Figure …).\nPOLYGON ((1 5, 2 2, 4 1, 4 4, 1 5))\nIllustration of point, linestring and polygon geometries… FIGURE …: Illustration of point, linestring and polygon geometries…\nSo far we have created geometries with only one geometric entity per feature. However, the Simple Features standard allows multiple geometries to exist within a single feature, using “multi” versions of each geometry type:\nMULTIPOINT (5 2, 1 3, 3 4, 3 2)\nMULTILINESTRING ((1 5, 4 4, 4 1, 2 2, 3 2), (1 2, 2 4))\nMULTIPOLYGON (((1 5, 2 2, 4 1, 4 4, 1 5), (0 2, 1 2, 1 3, 0 3, 0 2)))\nIllustration of multi* geometries… FIGURE …: Illustration of multi* geometries…\nFinally, a geometry collection can contain any combination of geometries including (multi)points and linestrings (see Figure …):\nGEOMETRYCOLLECTION (MULTIPOINT (5 2, 1 3, 3 4, 3 2), LINESTRING (1 5, 4 4, 4 1, 2 2, 3 2))\n\n\n2.2.5 Geometries\nEach element in the geometry column is a geometry object, of class shapely. For example, here is one specific geometry selected by implicit index (that of Canada):\n\ngdf[\"geometry\"].iloc[3]\n\n\n\n\nWe can also select a specific geometry based on the \"name_long\" attribute:\n\ngdf[gdf[\"name_long\"] == \"Egypt\"][\"geometry\"].iloc[0]\n\n\n\n\nThe shapely package is compatible with the Simple Features standard. Accordingly, seven types of geometries are supported. The following section demonstrates creating a shapely geometry of each type, from scratch or using a string in the WKT format as input. To do so, we need to import the shapely.wkt module and geometry types:\n\nimport shapely.wkt as wkt\nfrom shapely.geometry import Point\n\nCreating a point object is as simple as:\n\npoint = Point(5, 2)\npoint\n\n\n\n\nAlternatively, we can use the wkt.loads (stands for “load a WKT string”) to transform a WKT string to a shapely geometry object. Here is an example of a \"Point\" geometry:\n\npoint = wkt.loads(\"POINT (5 2)\")\npoint\n\n\n\n\nHere is an example of a \"MultiPoint\" geometry:\n\nfrom shapely.geometry import MultiPoint\nmultipoint = MultiPoint([(5,2), (1,3), (3,4), (3,2)])\nmultipoint\n\n\n\n\nHere is an example of a \"LineString\" geometry:\n\nfrom shapely.geometry import LineString\nlinestring = LineString([(1,5), (4,4), (4,1), (2,2), (3,2)])\nlinestring\n\n\n\n\nHere is an example of a \"MultiLineString\" geometry:\n\nfrom shapely.geometry import MultiLineString\nlinestring = MultiLineString([[(1,5), (4,4), (4,1), (2,2), (3,2)], [(1,2), (2,4)]])\nlinestring\n\n\n\n\nHere is an example of a \"Polygon\" geometry:\n\nfrom shapely.geometry import Polygon\npolygon = Polygon([(1,5), (2,2), (4,1), (4,4), (1,5)], [[(2,4), (3,4), (3,3), (2,3), (2,4)]])\npolygon\n\n\n\n\nHere is an example of a \"MultiPolygon\" geometry:\n\nfrom shapely.geometry import MultiPolygon\nmultipolygon = MultiPolygon([Polygon([(1,5), (2,2), (4,1), (4,4), (1,5)]), \n                             Polygon([(0,2), (1,2), (1,3), (0,3), (0,2)])])\nmultipolygon\n\n\n\n\nAnd, finally, here is an example of a \"GeometryCollection\" geometry:\n\nfrom shapely.geometry import GeometryCollection\nmultipoint = GeometryCollection([MultiPoint([(5,2), (1,3), (3,4), (3,2)]),\n                                 MultiLineString([[(1,5), (4,4), (4,1), (2,2), (3,2)], [(1,2), (2,4)]])])\nmultipoint\n\n\n\n\nshapely geometries act as atomic units of vector data, as spatial operations on a geometry return a single new geometry. For example, the following expression calculates the difference between the buffered multipolygon (using distance of 0.2) and itself:\n\nmultipolygon.buffer(0.2).difference(multipolygon)\n\n\n\n\nAs demonstrated above, a shapely geometry object is automatically evaluated to a small image of the geometry (when using an interface capable of displaying it, such as a Jupyter Notebook). To print the WKT string instead, we can use the print function:\n\nprint(linestring)\n\nMULTILINESTRING ((1 5, 4 4, 4 1, 2 2, 3 2), (1 2, 2 4))\n\n\nWe can determine the geometry type using the .geom_type property, which returns a string:\n\nlinestring.geom_type\n\n'MultiLineString'\n\n\nFinally, it is important to note that raw coordinates of shapely geometries are accessible through a combination of the .coords, .geoms, .exterior, and .interiors, properties (depending on the geometry type). These access methods are helpful when we need to develop our own spatial operators for specific tasks. For example, the following expression returns the coordinates of the polygon geometry exterior (note that the returned object is iterable, thus enclosed in a list to return all coordinates at once):\n\nlist(polygon.exterior.coords)\n\n[(1.0, 5.0), (2.0, 2.0), (4.0, 1.0), (4.0, 4.0), (1.0, 5.0)]"
  },
  {
    "objectID": "02-spatial-data.html#raster-data",
    "href": "02-spatial-data.html#raster-data",
    "title": "2  Geographic data in Python",
    "section": "2.3 Raster data",
    "text": "2.3 Raster data\n\n2.3.1 Introduction\nAs mentioned above, working with rasters in Python is less organized around one comprehensive package (compared to the case for vector layers and geopandas). Instead, several packages provide alternative subsets of method for working with raster data.\nThe two most notable approaches for working with rasters in Python are provided by the rasterio and xarray packages. As we will see shortly, they differ in their scope and underlying data models. Specifically, rasterio represents rasters as numpy arrays associated with a separate object holding the spatial metadata. The xarray package, however, represents rasters with the native DataArray object, which is an extension of numpy array designed to hold axis labels and attributes, in the same object, together with the array of raster values.\nBoth packages are not exhaustive in the same way as geopandas is. For example, when working with rasterio, on the one hand, more packages may be needed to accomplish common tasks such as zonal statistics (package rasterstats) or calculating topographic indices (package richdem). On the other hand, xarray was extended to accommodate spatial operators missing from the core package itself, with the rioxarray and xarray-spatial packages.\nIn the following two sections, we introduce the two well-established packages, rasterio and xarray, which form the basis for most raster functionality in Python. Using any of the add-on packages, or the extensions, should be straightforward, once the reader is familiar with the basics.\n\n\n2.3.2 Using rasterio\nTo work with the rasterio package, we first need to import it. We also import numpy, since the underlying raster data are stored in numpy arrays. To effectively work with those, we expose all numpy functions. Finally, we import the show function from the rasterio.plot sub-module for quick visualization of rasters.\n\nimport numpy as np\nimport rasterio\nfrom rasterio.plot import show\nimport subprocess\n\nRasters are typically imported from existing files. When working with rasterio, importing a raster is actually a two-step process:\n\nFirst, we open a raster file “connection” using rasterio.open\nSecond, we read raster values from the connection using the .read method\n\nThis separation is analogous to basic Python functions for reading from files, such as open and .readline to read from a text file. The rationale is that we do not always want to read all information from the file into memory, which is particularly important as rasters size can be larger than RAM size. Accordingly, the second step (.read) is selective. For example, we may want to read just one raster band rather than reading all bands.\nIn the first step, we pass a file path to the rasterio.open function to create a file connection. For this example, we use a single-band raster representing elevation in Zion National Park:\n\nsrc = rasterio.open(\"data/srtm.tif\")\n\nTo get a first impression of the raster values, we can plot it using the show function:\n\nshow(src);\n\n\n\n\nThe “connection” object contains the raster metadata, that is, all of the information other than the raster values. Let us examine it:\n\nsrc.meta\n\n{'driver': 'GTiff',\n 'dtype': 'uint16',\n 'nodata': 65535.0,\n 'width': 465,\n 'height': 457,\n 'count': 1,\n 'crs': CRS.from_epsg(4326),\n 'transform': Affine(0.0008333333332777796, 0.0, -113.23958321278403,\n        0.0, -0.0008333333332777843, 37.512916763165805)}\n\n\nImportantly, we can see:\n\nThe raster data type (dtype)\nRaster dimensions (width, height, and count, i.e., number of layers)\nRaster Coordinate Reference System (crs)\nThe raster affine transformation matrix (transform)\n\nThe last item (i.e., transform) deserves a few more words. To position a raster in geographical space, in addition to the CRS we must specify the raster origin (\\(x_{min}\\), \\(y_{max}\\)) and resolution (\\(delta_{x}\\), \\(delta_{y}\\)). In the transform matrix notation, these data items are stored as follows:\nAffine(delta_x, 0.0, x_min,\n       0.0, delta_y, y_max)\nNote that, by convention, raster y-axis origin is set to the maximum value (\\(y_{max}\\)) rather than the minimum, and, accordingly, the y-axis resolution (\\(delta_{y}\\)) is negative.\nThe .read method of a raster file connection object is used to read the last but not least piece of information: the raster values. Importantly, we can read:\n\nA particular layer, passing a numeric index (as in .read(1))\nA subset of layers, passing a list of indices (as in .read([1,2]))\nAll layers (as in .read())\n\nNote that the layer indices start from 1, contrary to the Python convention of the first index being 0.\nThe resulting object is a numpy array, with either two or three dimensions:\n\nThree dimensions, when reading more than one layer (e.g., .read() or .read([1,2])). In such case, the dimensions pattern is (layers, rows, columns)\nTwo dimensions, when reading one specific layer (e.g., .read(1))\n\nFor example, let’s read the first (and only) layer from the srtm.tif raster, using the file connection object src:\n\ns = src.read(1)\ns\n\narray([[1728, 1718, 1715, ..., 2654, 2674, 2685],\n       [1737, 1727, 1717, ..., 2649, 2677, 2693],\n       [1739, 1734, 1727, ..., 2644, 2672, 2695],\n       ...,\n       [1326, 1328, 1329, ..., 1777, 1778, 1775],\n       [1320, 1323, 1326, ..., 1771, 1770, 1772],\n       [1319, 1319, 1322, ..., 1768, 1770, 1772]], dtype=uint16)\n\n\nThe result s is a two-dimensional numpy array.\n\n\n2.3.3 Using xarray\n…\n\nimport xarray as xr\n\nReading source:\n\nx = xr.open_dataset(\"data/absolute_v5.nc\")\nx\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n<xarray.Dataset>\nDimensions:  (time: 12, lon: 72, lat: 36)\nCoordinates:\n  * time     (time) float64 0.5 1.5 2.5 3.5 4.5 5.5 6.5 7.5 8.5 9.5 10.5 11.5\n  * lon      (lon) float32 -177.5 -172.5 -167.5 -162.5 ... 167.5 172.5 177.5\n  * lat      (lat) float32 -87.5 -82.5 -77.5 -72.5 -67.5 ... 72.5 77.5 82.5 87.5\nData variables:\n    tem      (time, lat, lon) float32 -26.6 -27.4 -25.2 ... -29.4 -29.3 -29.4\nAttributes:\n    CDI:                       Climate Data Interface version ?? (http://mpim...\n    Conventions:               CF-1.6\n    history:                   Wed May 20 16:30:15 2020: ncap2 -O -s time=tim...\n    CDO:                       Climate Data Operators version 1.9.3 (http://m...\n    NCO:                       4.7.2\n    nco_openmp_thread_number:  1\n    reference:                 Osborn TJ, Jones PD, Lister DH, Morice CP, Sim...\n    licence:                   Open Government Licence http://www.nationalarc...xarray.DatasetDimensions:time: 12lon: 72lat: 36Coordinates: (3)time(time)float640.5 1.5 2.5 3.5 ... 9.5 10.5 11.5axis :Tcalendar :proleptic_gregorianstandard_name :timeunits :monthsarray([ 0.5,  1.5,  2.5,  3.5,  4.5,  5.5,  6.5,  7.5,  8.5,  9.5, 10.5, 11.5])lon(lon)float32-177.5 -172.5 ... 172.5 177.5standard_name :longitudelong_name :longitudeunits :degrees_eastaxis :Xarray([-177.5, -172.5, -167.5, -162.5, -157.5, -152.5, -147.5, -142.5, -137.5,\n       -132.5, -127.5, -122.5, -117.5, -112.5, -107.5, -102.5,  -97.5,  -92.5,\n        -87.5,  -82.5,  -77.5,  -72.5,  -67.5,  -62.5,  -57.5,  -52.5,  -47.5,\n        -42.5,  -37.5,  -32.5,  -27.5,  -22.5,  -17.5,  -12.5,   -7.5,   -2.5,\n          2.5,    7.5,   12.5,   17.5,   22.5,   27.5,   32.5,   37.5,   42.5,\n         47.5,   52.5,   57.5,   62.5,   67.5,   72.5,   77.5,   82.5,   87.5,\n         92.5,   97.5,  102.5,  107.5,  112.5,  117.5,  122.5,  127.5,  132.5,\n        137.5,  142.5,  147.5,  152.5,  157.5,  162.5,  167.5,  172.5,  177.5],\n      dtype=float32)lat(lat)float32-87.5 -82.5 -77.5 ... 82.5 87.5standard_name :latitudelong_name :latitudeunits :degrees_northaxis :Yarray([-87.5, -82.5, -77.5, -72.5, -67.5, -62.5, -57.5, -52.5, -47.5, -42.5,\n       -37.5, -32.5, -27.5, -22.5, -17.5, -12.5,  -7.5,  -2.5,   2.5,   7.5,\n        12.5,  17.5,  22.5,  27.5,  32.5,  37.5,  42.5,  47.5,  52.5,  57.5,\n        62.5,  67.5,  72.5,  77.5,  82.5,  87.5], dtype=float32)Data variables: (1)tem(time, lat, lon)float32...long_name :CRU_Global_1961-1990_Mean_Monthly_Surface_Temperature_Climatologyunits :celsiusarray([[[-26.599998, -27.4     , ..., -27.4     , -27.5     ],\n        [ -4.7     ,  -4.4     , ...,  -6.4     ,  -5.6     ],\n        ...,\n        [-29.3     , -29.199999, ..., -29.5     , -29.3     ],\n        [-30.099998, -30.099998, ..., -30.699999, -30.5     ]],\n\n       [[-38.3     , -39.2     , ..., -39.399998, -39.399998],\n        [-11.099999, -10.599999, ..., -13.4     , -12.3     ],\n        ...,\n        [-29.4     , -29.4     , ..., -29.599998, -29.5     ],\n        [-30.5     , -30.599998, ..., -31.      , -30.8     ]],\n\n       ...,\n\n       [[-36.899998, -37.7     , ..., -37.899998, -37.899998],\n        [-12.      , -11.7     , ..., -14.099999, -13.099999],\n        ...,\n        [-22.3     , -22.199999, ..., -22.5     , -22.5     ],\n        [-24.4     , -24.5     , ..., -24.6     , -24.699999]],\n\n       [[-26.699999, -27.4     , ..., -27.5     , -27.599998],\n        [ -5.2     ,  -4.9     , ...,  -6.9     ,  -6.1     ],\n        ...,\n        [-27.      , -27.099998, ..., -27.099998, -27.099998],\n        [-29.3     , -29.5     , ..., -29.3     , -29.4     ]]], dtype=float32)Attributes: (8)CDI :Climate Data Interface version ?? (http://mpimet.mpg.de/cdi)Conventions :CF-1.6history :Wed May 20 16:30:15 2020: ncap2 -O -s time=time-1 better_absolute_2.nc better_absolute_3.nc\nWed May 20 16:30:15 2020: cdo invertlat better_absolute_1.nc better_absolute_2.ncCDO :Climate Data Operators version 1.9.3 (http://mpimet.mpg.de/cdo)NCO :4.7.2nco_openmp_thread_number :1reference :Osborn TJ, Jones PD, Lister DH, Morice CP, Simpson IR, Winn J, Hogan E and Harris IC (submitted) Land surface air temperature variations across the globe updated to 2019: the CRUTEM5 dataset. Submitted to Journal of Geophysical Research.licence :Open Government Licence http://www.nationalarchives.gov.uk/doc/open-government-licence/version/3/\n\n\n\nx[\"tem\"]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n<xarray.DataArray 'tem' (time: 12, lat: 36, lon: 72)>\narray([[[-26.599998, -27.4     , ..., -27.4     , -27.5     ],\n        [ -4.7     ,  -4.4     , ...,  -6.4     ,  -5.6     ],\n        ...,\n        [-29.3     , -29.199999, ..., -29.5     , -29.3     ],\n        [-30.099998, -30.099998, ..., -30.699999, -30.5     ]],\n\n       [[-38.3     , -39.2     , ..., -39.399998, -39.399998],\n        [-11.099999, -10.599999, ..., -13.4     , -12.3     ],\n        ...,\n        [-29.4     , -29.4     , ..., -29.599998, -29.5     ],\n        [-30.5     , -30.599998, ..., -31.      , -30.8     ]],\n\n       ...,\n\n       [[-36.899998, -37.7     , ..., -37.899998, -37.899998],\n        [-12.      , -11.7     , ..., -14.099999, -13.099999],\n        ...,\n        [-22.3     , -22.199999, ..., -22.5     , -22.5     ],\n        [-24.4     , -24.5     , ..., -24.6     , -24.699999]],\n\n       [[-26.699999, -27.4     , ..., -27.5     , -27.599998],\n        [ -5.2     ,  -4.9     , ...,  -6.9     ,  -6.1     ],\n        ...,\n        [-27.      , -27.099998, ..., -27.099998, -27.099998],\n        [-29.3     , -29.5     , ..., -29.3     , -29.4     ]]], dtype=float32)\nCoordinates:\n  * time     (time) float64 0.5 1.5 2.5 3.5 4.5 5.5 6.5 7.5 8.5 9.5 10.5 11.5\n  * lon      (lon) float32 -177.5 -172.5 -167.5 -162.5 ... 167.5 172.5 177.5\n  * lat      (lat) float32 -87.5 -82.5 -77.5 -72.5 -67.5 ... 72.5 77.5 82.5 87.5\nAttributes:\n    long_name:  CRU_Global_1961-1990_Mean_Monthly_Surface_Temperature_Climato...\n    units:      celsiusxarray.DataArray'tem'time: 12lat: 36lon: 72-26.6 -27.4 -25.2 -21.2 -19.8 -17.8 ... -29.5 -29.4 -29.4 -29.3 -29.4array([[[-26.599998, -27.4     , ..., -27.4     , -27.5     ],\n        [ -4.7     ,  -4.4     , ...,  -6.4     ,  -5.6     ],\n        ...,\n        [-29.3     , -29.199999, ..., -29.5     , -29.3     ],\n        [-30.099998, -30.099998, ..., -30.699999, -30.5     ]],\n\n       [[-38.3     , -39.2     , ..., -39.399998, -39.399998],\n        [-11.099999, -10.599999, ..., -13.4     , -12.3     ],\n        ...,\n        [-29.4     , -29.4     , ..., -29.599998, -29.5     ],\n        [-30.5     , -30.599998, ..., -31.      , -30.8     ]],\n\n       ...,\n\n       [[-36.899998, -37.7     , ..., -37.899998, -37.899998],\n        [-12.      , -11.7     , ..., -14.099999, -13.099999],\n        ...,\n        [-22.3     , -22.199999, ..., -22.5     , -22.5     ],\n        [-24.4     , -24.5     , ..., -24.6     , -24.699999]],\n\n       [[-26.699999, -27.4     , ..., -27.5     , -27.599998],\n        [ -5.2     ,  -4.9     , ...,  -6.9     ,  -6.1     ],\n        ...,\n        [-27.      , -27.099998, ..., -27.099998, -27.099998],\n        [-29.3     , -29.5     , ..., -29.3     , -29.4     ]]], dtype=float32)Coordinates: (3)time(time)float640.5 1.5 2.5 3.5 ... 9.5 10.5 11.5axis :Tcalendar :proleptic_gregorianstandard_name :timeunits :monthsarray([ 0.5,  1.5,  2.5,  3.5,  4.5,  5.5,  6.5,  7.5,  8.5,  9.5, 10.5, 11.5])lon(lon)float32-177.5 -172.5 ... 172.5 177.5standard_name :longitudelong_name :longitudeunits :degrees_eastaxis :Xarray([-177.5, -172.5, -167.5, -162.5, -157.5, -152.5, -147.5, -142.5, -137.5,\n       -132.5, -127.5, -122.5, -117.5, -112.5, -107.5, -102.5,  -97.5,  -92.5,\n        -87.5,  -82.5,  -77.5,  -72.5,  -67.5,  -62.5,  -57.5,  -52.5,  -47.5,\n        -42.5,  -37.5,  -32.5,  -27.5,  -22.5,  -17.5,  -12.5,   -7.5,   -2.5,\n          2.5,    7.5,   12.5,   17.5,   22.5,   27.5,   32.5,   37.5,   42.5,\n         47.5,   52.5,   57.5,   62.5,   67.5,   72.5,   77.5,   82.5,   87.5,\n         92.5,   97.5,  102.5,  107.5,  112.5,  117.5,  122.5,  127.5,  132.5,\n        137.5,  142.5,  147.5,  152.5,  157.5,  162.5,  167.5,  172.5,  177.5],\n      dtype=float32)lat(lat)float32-87.5 -82.5 -77.5 ... 82.5 87.5standard_name :latitudelong_name :latitudeunits :degrees_northaxis :Yarray([-87.5, -82.5, -77.5, -72.5, -67.5, -62.5, -57.5, -52.5, -47.5, -42.5,\n       -37.5, -32.5, -27.5, -22.5, -17.5, -12.5,  -7.5,  -2.5,   2.5,   7.5,\n        12.5,  17.5,  22.5,  27.5,  32.5,  37.5,  42.5,  47.5,  52.5,  57.5,\n        62.5,  67.5,  72.5,  77.5,  82.5,  87.5], dtype=float32)Attributes: (2)long_name :CRU_Global_1961-1990_Mean_Monthly_Surface_Temperature_Climatologyunits :celsius\n\n\nPlot:\n\nx[\"tem\"].plot(col=\"time\", col_wrap=4)\n\n<xarray.plot.facetgrid.FacetGrid at 0x7fd328989b50>"
  },
  {
    "objectID": "02-spatial-data.html#coordinate-reference-systems",
    "href": "02-spatial-data.html#coordinate-reference-systems",
    "title": "2  Geographic data in Python",
    "section": "2.4 Coordinate Reference Systems",
    "text": "2.4 Coordinate Reference Systems\nVector and raster spatial data types share concepts intrinsic to spatial data. Perhaps the most fundamental of these is the Coordinate Reference System (CRS), which defines how the spatial elements of the data relate to the surface of the Earth (or other bodies). CRSs are either geographic or projected, as introduced at the beginning of this chapter (see …). This section explains each type, laying the foundations for Chapter 7, which provides a deep dive into setting, transforming, and querying CRSs.\n\n2.4.1 Geographic coordinate systems\nGeographic coordinate systems identify any location on the Earth’s surface using two values — longitude and latitude (see left panel of Figure …). Longitude is a location in the East-West direction in angular distance from the Prime Meridian plane, while latitude is an angular distance North or South of the equatorial plane. Distances in geographic CRSs are therefore not measured in meters. This has important consequences, as demonstrated in Section 7.\nA spherical or ellipsoidal surface represents the surface of the Earth in geographic coordinate systems. Spherical models assume that the Earth is a perfect sphere of a given radius — they have the advantage of simplicity, but, at the same time, they are inaccurate: the Earth is not a sphere! Ellipsoidal models are defined by two parameters: the equatorial radius and the polar radius. These are suitable because the Earth is compressed: the equatorial radius is around 11.5 km longer than the polar radius (Maling 1992…).\nEllipsoids are part of a broader component of CRSs: the datum. This contains information on what ellipsoid to use and the precise relationship between the Cartesian coordinates and location on the Earth’s surface. There are two types of datum — geocentric (such as WGS84) and local (such as NAD83). You can see examples of these two types of datums in Figure …. Black lines represent a geocentric datum, whose center is located in the Earth’s center of gravity and is not optimized for a specific location. In a local datum, shown as a purple dashed line, the ellipsoidal surface is shifted to align with the surface at a particular location. These allow local variations on Earth’s surface, such as large mountain ranges, to be accounted for in a local CRS. This can be seen in Figure …, where the local datum is fitted to the area of Philippines, but is misaligned with most of the rest of the planet’s surface. Both datums in Figure … are put on top of a geoid - a model of global mean sea level.\n\n\n2.4.2 Projected coordinate reference systems\nAll projected CRSs are based on a geographic CRS, described in the previous section, and rely on map projections to convert the three-dimensional surface of the Earth into Easting and Northing (x and y) values in a projected CRS. Projected CRSs are based on Cartesian coordinates on an implicitly flat surface (right panel of Figure …). They have an origin, x and y axes, and a linear unit of measurement such as meters.\nThis transition cannot be done without adding some deformations. Therefore, some properties of the Earth’s surface are distorted in this process, such as area, direction, distance, and shape. A projected coordinate system can preserve only one or two of those properties. Projections are often named based on a property they preserve: equal-area preserves area, azimuthal preserves direction, equidistant preserves distance, and conformal preserves local shape.\nThere are three main groups of projection types - conic, cylindrical, and planar (azimuthal). In a conic projection, the Earth’s surface is projected onto a cone along a single line of tangency or two lines of tangency. Distortions are minimized along the tangency lines and rise with the distance from those lines in this projection. Therefore, it is best suited for maps of mid-latitude areas. A cylindrical projection maps the surface onto a cylinder. This projection could also be created by touching the Earth’s surface along a single line of tangency or two lines of tangency. Cylindrical projections are used most often when mapping the entire world. A planar projection projects data onto a flat surface touching the globe at a point or along a line of tangency. It is typically used in mapping polar regions.\nLike most open-source geospatial software, the geopandas and rasterio packages use the PROJ software for CRS definition and calculations. The pyproj package is a low-level interface to PROJ. Using its functions, we can examine the list of supported projections:\n\nimport pyproj\nepsg_codes = pyproj.get_codes('EPSG', 'CRS')  ## List of supported EPSG codes\nepsg_codes[:5]  ## print first five\n\n['2000', '20004', '20005', '20006', '20007']\n\n\n\npyproj.CRS.from_epsg(4326)  ## Printout of WGS84 CRS (EPSG:4326)\n\n<Geographic 2D CRS: EPSG:4326>\nName: WGS 84\nAxis Info [ellipsoidal]:\n- Lat[north]: Geodetic latitude (degree)\n- Lon[east]: Geodetic longitude (degree)\nArea of Use:\n- name: World.\n- bounds: (-180.0, -90.0, 180.0, 90.0)\nDatum: World Geodetic System 1984 ensemble\n- Ellipsoid: WGS 84\n- Prime Meridian: Greenwich\n\n\nA quick summary of different projections, their types, properties, and suitability can be found in “Map Projections” (1993) and at https://www.geo-projections.com/. We will expand on CRSs and explain how to project from one CRS to another in Chapter 7. But, for now, it is sufficient to know:\n\nThat coordinate systems are a key component of geographic objects\nKnowing which CRS your data is in, and whether it is in geographic (lon/lat) or projected (typically meters), is important and has consequences for how Python handles spatial and geometry operations\nCRSs of geopandas (vector layer or geometry column) and rasterio (raster) objects can be queried with the .crs property\n\nHere is a demonstration of the last bullet point:\n\ngdf.crs\n\n<Geographic 2D CRS: EPSG:4326>\nName: WGS 84\nAxis Info [ellipsoidal]:\n- Lat[north]: Geodetic latitude (degree)\n- Lon[east]: Geodetic longitude (degree)\nArea of Use:\n- name: World.\n- bounds: (-180.0, -90.0, 180.0, 90.0)\nDatum: World Geodetic System 1984 ensemble\n- Ellipsoid: WGS 84\n- Prime Meridian: Greenwich\n\n\n\nsrc.crs\n\nCRS.from_epsg(4326)"
  },
  {
    "objectID": "02-spatial-data.html#units",
    "href": "02-spatial-data.html#units",
    "title": "2  Geographic data in Python",
    "section": "2.5 Units",
    "text": "2.5 Units\nAn essential feature of CRSs is that they contain information about spatial units. Clearly, it is vital to know whether a house’s measurements are in feet or meters, and the same applies to maps. It is a good cartographic practice to add a scale bar or some other distance indicator onto maps to demonstrate the relationship between distances on the page or screen and distances on the ground. Likewise, it is important for the user to be aware of the units in which the geometry coordinates are, to ensure that subsequent calculations are done in the right context.\nPython spatial data structures in geopandas and rasterio do not natively support the concept of measurement. The coordinates of a vector layer or a raster are plain numbers, referring to an arbitrary plane. For example, according to the .transform matrix of srtm.tif we can see that the raster resolution is 0.000833 and that its CRS is WGS84 (EPSG: 4326). We may know (or can find out) that the units of WGS84 are decimal degrees. However, that information is not encoded in any numeric calculation.\n\nsrc.meta\n\n{'driver': 'GTiff',\n 'dtype': 'uint16',\n 'nodata': 65535.0,\n 'width': 465,\n 'height': 457,\n 'count': 1,\n 'crs': CRS.from_epsg(4326),\n 'transform': Affine(0.0008333333332777796, 0.0, -113.23958321278403,\n        0.0, -0.0008333333332777843, 37.512916763165805)}\n\n\nConsequently, we need to be aware of the CRS units we are working with. Typically, these are decimal degrees, in a geographic CRS, or \\(m\\), in a projected CRS, although there are exceptions. Geometric calculations such as length, area, or distance, return plain numbers in the same units of the CRS (such as \\(m\\) or \\(m^2\\)). It is up to the user to determine which units the result is given in and treat the result accordingly. For example, if the area output was in \\(m^2\\) and we need the result in \\(km^2\\), then we need to divide the result by \\(1000^2\\)."
  },
  {
    "objectID": "02-spatial-data.html#exercises",
    "href": "02-spatial-data.html#exercises",
    "title": "2  Geographic data in Python",
    "section": "2.6 Exercises",
    "text": "2.6 Exercises\n…"
  },
  {
    "objectID": "03-attribute-operations.html#prerequisites",
    "href": "03-attribute-operations.html#prerequisites",
    "title": "3  Attribute data operations",
    "section": "3.1 Prerequisites",
    "text": "3.1 Prerequisites\nPackages…\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport geopandas as gpd\nimport rasterio\n\n/usr/local/lib/python3.8/dist-packages/geopandas/_compat.py:112: UserWarning: The Shapely GEOS version (3.10.2-CAPI-1.16.0) is incompatible with the GEOS version PyGEOS was compiled with (3.10.1-CAPI-1.16.0). Conversions between both will be slow.\n  warnings.warn(\n\n\nSample data…\n\n\nAttempting to get the data\n\n\n\nworld = gpd.read_file(\"data/world.gpkg\")\nsrc_elev = rasterio.open(\"data/elev.tif\")\nsrc_multi_rast = rasterio.open(\"data/landsat.tif\")"
  },
  {
    "objectID": "03-attribute-operations.html#introduction",
    "href": "03-attribute-operations.html#introduction",
    "title": "3  Attribute data operations",
    "section": "3.2 Introduction",
    "text": "3.2 Introduction\n…"
  },
  {
    "objectID": "03-attribute-operations.html#vector-attribute-manipulation",
    "href": "03-attribute-operations.html#vector-attribute-manipulation",
    "title": "3  Attribute data operations",
    "section": "3.3 Vector attribute manipulation",
    "text": "3.3 Vector attribute manipulation\nAs mentioned previously (…), vector layers (GeoDataFrame, from package geopandas) are basically extended tables (DataFrame from package pandas), the difference being that a vector layer has a geometry column. Since GeoDataFrame extends DataFrame, all ordinary table-related operations from package pandas are supported for vector laters as well, as shown below.\n\n3.3.1 Vector attribute subsetting\npandas supports several subsetting interfaces, though the most recommended ones are:\n\n.loc, which uses pandas indices, and\n.iloc, which uses (implicit) numpy-style numeric indices.\n\nIn both cases the method is followed by square brackets, and two indices, separated by a comma. Each index can comprise:\n\nA specific value, as in 1\nA slice, as in 0:3\nA list, as in [0,2,4]\n:—indicating “all” indices\n\nThe once exception which we are going to with subsetting by indices is when selecting columns, directly using a list, as in df[[\"a\",\"b\"]], instead of df.loc[:, [\"a\",\"b\"]], to select columns \"a\" and \"b\" from df.\nHere are few examples of subsetting the GeoDataFrame of world countries.\nSubsetting rows by position:\n\nworld.iloc[0:3, :]\n\n\n\n\n  \n    \n      \n      iso_a2\n      name_long\n      continent\n      ...\n      lifeExp\n      gdpPercap\n      geometry\n    \n  \n  \n    \n      0\n      FJ\n      Fiji\n      Oceania\n      ...\n      69.960\n      8222.253784\n      MULTIPOLYGON (((-180.00000 -16....\n    \n    \n      1\n      TZ\n      Tanzania\n      Africa\n      ...\n      64.163\n      2402.099404\n      MULTIPOLYGON (((33.90371 -0.950...\n    \n    \n      2\n      EH\n      Western Sahara\n      Africa\n      ...\n      NaN\n      NaN\n      MULTIPOLYGON (((-8.66559 27.656...\n    \n  \n\n3 rows × 11 columns\n\n\n\nSubsetting columns by position:\n\nworld.iloc[:, 0:3]\n\n\n\n\n  \n    \n      \n      iso_a2\n      name_long\n      continent\n    \n  \n  \n    \n      0\n      FJ\n      Fiji\n      Oceania\n    \n    \n      1\n      TZ\n      Tanzania\n      Africa\n    \n    \n      2\n      EH\n      Western Sahara\n      Africa\n    \n    \n      ...\n      ...\n      ...\n      ...\n    \n    \n      174\n      XK\n      Kosovo\n      Europe\n    \n    \n      175\n      TT\n      Trinidad and Tobago\n      North America\n    \n    \n      176\n      SS\n      South Sudan\n      Africa\n    \n  \n\n177 rows × 3 columns\n\n\n\nSubsetting rows and columns by position:\n\nworld.iloc[0:3, 0:3]\n\n\n\n\n  \n    \n      \n      iso_a2\n      name_long\n      continent\n    \n  \n  \n    \n      0\n      FJ\n      Fiji\n      Oceania\n    \n    \n      1\n      TZ\n      Tanzania\n      Africa\n    \n    \n      2\n      EH\n      Western Sahara\n      Africa\n    \n  \n\n\n\n\nSubsetting columns by name:\n\nworld[[\"name_long\", \"geometry\"]]\n\n\n\n\n  \n    \n      \n      name_long\n      geometry\n    \n  \n  \n    \n      0\n      Fiji\n      MULTIPOLYGON (((-180.00000 -16....\n    \n    \n      1\n      Tanzania\n      MULTIPOLYGON (((33.90371 -0.950...\n    \n    \n      2\n      Western Sahara\n      MULTIPOLYGON (((-8.66559 27.656...\n    \n    \n      ...\n      ...\n      ...\n    \n    \n      174\n      Kosovo\n      MULTIPOLYGON (((20.59025 41.855...\n    \n    \n      175\n      Trinidad and Tobago\n      MULTIPOLYGON (((-61.68000 10.76...\n    \n    \n      176\n      South Sudan\n      MULTIPOLYGON (((30.83385 3.5091...\n    \n  \n\n177 rows × 2 columns\n\n\n\n“Slice” of columns between given ones:\n\nworld.loc[:, \"name_long\":\"pop\"]\n\n\n\n\n  \n    \n      \n      name_long\n      continent\n      region_un\n      ...\n      type\n      area_km2\n      pop\n    \n  \n  \n    \n      0\n      Fiji\n      Oceania\n      Oceania\n      ...\n      Sovereign country\n      19289.970733\n      885806.0\n    \n    \n      1\n      Tanzania\n      Africa\n      Africa\n      ...\n      Sovereign country\n      932745.792357\n      52234869.0\n    \n    \n      2\n      Western Sahara\n      Africa\n      Africa\n      ...\n      Indeterminate\n      96270.601041\n      NaN\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      174\n      Kosovo\n      Europe\n      Europe\n      ...\n      Sovereign country\n      11230.261672\n      1821800.0\n    \n    \n      175\n      Trinidad and Tobago\n      North America\n      Americas\n      ...\n      Sovereign country\n      7737.809855\n      1354493.0\n    \n    \n      176\n      South Sudan\n      Africa\n      Africa\n      ...\n      Sovereign country\n      624909.099086\n      11530971.0\n    \n  \n\n177 rows × 7 columns\n\n\n\nSubsetting by a boolean series:\n\nx = np.array([1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0], dtype=bool)\nworld.iloc[:, x]\n\n\n\n\n  \n    \n      \n      iso_a2\n      name_long\n      pop\n      lifeExp\n    \n  \n  \n    \n      0\n      FJ\n      Fiji\n      885806.0\n      69.960000\n    \n    \n      1\n      TZ\n      Tanzania\n      52234869.0\n      64.163000\n    \n    \n      2\n      EH\n      Western Sahara\n      NaN\n      NaN\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      174\n      XK\n      Kosovo\n      1821800.0\n      71.097561\n    \n    \n      175\n      TT\n      Trinidad and Tobago\n      1354493.0\n      70.426000\n    \n    \n      176\n      SS\n      South Sudan\n      11530971.0\n      55.817000\n    \n  \n\n177 rows × 4 columns\n\n\n\nWe can remove specific columns using the .drop method and axis=1 (i.e., columns):\n\nworld.drop([\"name_long\", \"continent\"], axis=1)\n\n\n\n\n  \n    \n      \n      iso_a2\n      region_un\n      subregion\n      ...\n      lifeExp\n      gdpPercap\n      geometry\n    \n  \n  \n    \n      0\n      FJ\n      Oceania\n      Melanesia\n      ...\n      69.960000\n      8222.253784\n      MULTIPOLYGON (((-180.00000 -16....\n    \n    \n      1\n      TZ\n      Africa\n      Eastern Africa\n      ...\n      64.163000\n      2402.099404\n      MULTIPOLYGON (((33.90371 -0.950...\n    \n    \n      2\n      EH\n      Africa\n      Northern Africa\n      ...\n      NaN\n      NaN\n      MULTIPOLYGON (((-8.66559 27.656...\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      174\n      XK\n      Europe\n      Southern Europe\n      ...\n      71.097561\n      8698.291559\n      MULTIPOLYGON (((20.59025 41.855...\n    \n    \n      175\n      TT\n      Americas\n      Caribbean\n      ...\n      70.426000\n      31181.821196\n      MULTIPOLYGON (((-61.68000 10.76...\n    \n    \n      176\n      SS\n      Africa\n      Eastern Africa\n      ...\n      55.817000\n      1935.879400\n      MULTIPOLYGON (((30.83385 3.5091...\n    \n  \n\n177 rows × 9 columns\n\n\n\nWe can rename (some of) the selected columns using the .rename method:\n\nworld[[\"name_long\", \"pop\"]].rename(columns={\"pop\": \"population\"})\n\n\n\n\n  \n    \n      \n      name_long\n      population\n    \n  \n  \n    \n      0\n      Fiji\n      885806.0\n    \n    \n      1\n      Tanzania\n      52234869.0\n    \n    \n      2\n      Western Sahara\n      NaN\n    \n    \n      ...\n      ...\n      ...\n    \n    \n      174\n      Kosovo\n      1821800.0\n    \n    \n      175\n      Trinidad and Tobago\n      1354493.0\n    \n    \n      176\n      South Sudan\n      11530971.0\n    \n  \n\n177 rows × 2 columns\n\n\n\nThe standard numpy comparison operators can be used in boolean subsetting, as illustrated in Table …\nTABLE …: Comparison operators that return Booleans (TRUE/FALSE).\n\n\n\nSymbol\nName\n\n\n\n\n==\nEqual to\n\n\n!=\nNot equal to\n\n\n>, <\nGreater/Less than\n\n\n>=, <=\nGreater/Less than or equal\n\n\n&, |, ~\nLogical operators: And, Or, Not\n\n\n\nA demonstration of the utility of using logical vectors for subsetting is shown in the code chunk below. This creates a new object, small_countries, containing nations whose surface area is smaller than 10,000 km2:\n\ni_small = world[\"area_km2\"] < 10000  ## a logical 'Series'\nsmall_countries = world[i_small]\nsmall_countries\n\n\n\n\n  \n    \n      \n      iso_a2\n      name_long\n      continent\n      ...\n      lifeExp\n      gdpPercap\n      geometry\n    \n  \n  \n    \n      45\n      PR\n      Puerto Rico\n      North America\n      ...\n      79.390122\n      35066.046376\n      MULTIPOLYGON (((-66.28243 18.51...\n    \n    \n      79\n      PS\n      Palestine\n      Asia\n      ...\n      73.126000\n      4319.528283\n      MULTIPOLYGON (((35.39756 31.489...\n    \n    \n      89\n      VU\n      Vanuatu\n      Oceania\n      ...\n      71.709000\n      2892.341604\n      MULTIPOLYGON (((166.79316 -15.6...\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      160\n      None\n      Northern Cyprus\n      Asia\n      ...\n      NaN\n      NaN\n      MULTIPOLYGON (((32.73178 35.140...\n    \n    \n      161\n      CY\n      Cyprus\n      Asia\n      ...\n      80.173000\n      29786.365653\n      MULTIPOLYGON (((32.73178 35.140...\n    \n    \n      175\n      TT\n      Trinidad and Tobago\n      North America\n      ...\n      70.426000\n      31181.821196\n      MULTIPOLYGON (((-61.68000 10.76...\n    \n  \n\n7 rows × 11 columns\n\n\n\nThe intermediary i_small (short for index representing small countries) is a boolean Series that can be used to subset the seven smallest countries in the world by surface area. A more concise command, which omits the intermediary object, generates the same result:\n\nsmall_countries = world[world[\"area_km2\"] < 10000]\n\nThe various methods shown above can be chained for any combination with several subsetting steps. For example:\n\nworld[world[\"continent\"] == \"Asia\"]  \\\n    .loc[:, [\"name_long\", \"continent\"]]  \\\n    .iloc[0:5, :]\n\n\n\n\n  \n    \n      \n      name_long\n      continent\n    \n  \n  \n    \n      5\n      Kazakhstan\n      Asia\n    \n    \n      6\n      Uzbekistan\n      Asia\n    \n    \n      8\n      Indonesia\n      Asia\n    \n    \n      24\n      Timor-Leste\n      Asia\n    \n    \n      76\n      Israel\n      Asia\n    \n  \n\n\n\n\n\n\n3.3.2 Vector attribute aggregation\nAggregation involves summarizing data with one or more grouping variables, typically from columns in the table to be aggregated (geographic aggregation is covered in the next chapter). An example of attribute aggregation is calculating the number of people per continent based on country-level data (one row per country). The world dataset contains the necessary ingredients: the columns pop and continent, the population and the grouping variable, respectively. The aim is to find the sum() of country populations for each continent, resulting in a smaller data frame (aggregation is a form of data reduction and can be a useful early step when working with large datasets). This can be done with a combination of .groupby and .sum:\n\nworld_agg1 = world[['continent', 'pop']].groupby('continent').sum()\nworld_agg1\n\n\n\n\n  \n    \n      \n      pop\n    \n    \n      continent\n      \n    \n  \n  \n    \n      Africa\n      1.154947e+09\n    \n    \n      Antarctica\n      0.000000e+00\n    \n    \n      Asia\n      4.311408e+09\n    \n    \n      ...\n      ...\n    \n    \n      Oceania\n      3.775783e+07\n    \n    \n      Seven seas (open ocean)\n      0.000000e+00\n    \n    \n      South America\n      4.120608e+08\n    \n  \n\n8 rows × 1 columns\n\n\n\nThe result is a (non-spatial) table with eight rows, one per continent, and two columns reporting the name and population of each continent.\nAlternatively, to include the geometry in the aggregation result, we can use the .dissolve method. That way, in addition to the summed population we also get the associated geometry per continent, i.e., the union of all countries. Note that we use the by parameter to choose which column(s) are used for grouping, and the aggfunc parameter to choose the summary function for non-geometry columns:\n\nworld_agg2 = world[['continent', 'pop', 'geometry']] \\\n    .dissolve(by='continent', aggfunc='sum')\nworld_agg2\n\n\n\n\n  \n    \n      \n      geometry\n      pop\n    \n    \n      continent\n      \n      \n    \n  \n  \n    \n      Africa\n      MULTIPOLYGON (((-11.43878 6.785...\n      1.154947e+09\n    \n    \n      Antarctica\n      MULTIPOLYGON (((-61.13898 -79.9...\n      0.000000e+00\n    \n    \n      Asia\n      MULTIPOLYGON (((48.67923 14.003...\n      4.311408e+09\n    \n    \n      ...\n      ...\n      ...\n    \n    \n      Oceania\n      MULTIPOLYGON (((147.91405 -43.2...\n      3.775783e+07\n    \n    \n      Seven seas (open ocean)\n      POLYGON ((68.93500 -48.62500, 6...\n      0.000000e+00\n    \n    \n      South America\n      MULTIPOLYGON (((-68.63999 -55.5...\n      4.120608e+08\n    \n  \n\n8 rows × 2 columns\n\n\n\nHere is a plot of the result:\n\nworld_agg2.plot(column='pop');\n\n\n\n\nThe resulting world_agg2 object is a vector layer containing 8 features representing the continents of the world (and the open ocean).\nOther options for the aggfunc parameter in .dissolve include:\n\n'first'\n'last'\n'min'\n'max'\n'sum'\n'mean'\n'median'\n\nAdditionally, we can pass a custom functiom.\nFor example, here is how we can calculate the summed population, summed area, and count of countries, per continent. We do this in two steps, then join the results:\n\nworld_agg3a = world[['continent', 'area_km2', 'geometry']] \\\n    .dissolve(by='continent', aggfunc='sum')\nworld_agg3b = world[['continent', 'name_long', 'geometry']] \\\n    .dissolve(by='continent', aggfunc=lambda x: x.nunique()) \\\n    .rename(columns={\"name_long\": \"n\"})\nworld_agg = pd.merge(world_agg3a, world_agg3b, on='continent')\n\n…\n\n\n3.3.3 Vector attribute joining\nJoin by attribute…\n\ncoffee_data = pd.read_csv(\"data/coffee_data.csv\")\ncoffee_data\n\n\n\n\n  \n    \n      \n      name_long\n      coffee_production_2016\n      coffee_production_2017\n    \n  \n  \n    \n      0\n      Angola\n      NaN\n      NaN\n    \n    \n      1\n      Bolivia\n      3.0\n      4.0\n    \n    \n      2\n      Brazil\n      3277.0\n      2786.0\n    \n    \n      ...\n      ...\n      ...\n      ...\n    \n    \n      44\n      Zambia\n      3.0\n      NaN\n    \n    \n      45\n      Zimbabwe\n      1.0\n      1.0\n    \n    \n      46\n      Others\n      23.0\n      26.0\n    \n  \n\n47 rows × 3 columns\n\n\n\nJoin by \"name_long\" column…\n\nworld_coffee = pd.merge(world, coffee_data, on=\"name_long\", how=\"left\")\nworld_coffee\n\n\n\n\n  \n    \n      \n      iso_a2\n      name_long\n      continent\n      ...\n      geometry\n      coffee_production_2016\n      coffee_production_2017\n    \n  \n  \n    \n      0\n      FJ\n      Fiji\n      Oceania\n      ...\n      MULTIPOLYGON (((-180.00000 -16....\n      NaN\n      NaN\n    \n    \n      1\n      TZ\n      Tanzania\n      Africa\n      ...\n      MULTIPOLYGON (((33.90371 -0.950...\n      81.0\n      66.0\n    \n    \n      2\n      EH\n      Western Sahara\n      Africa\n      ...\n      MULTIPOLYGON (((-8.66559 27.656...\n      NaN\n      NaN\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      174\n      XK\n      Kosovo\n      Europe\n      ...\n      MULTIPOLYGON (((20.59025 41.855...\n      NaN\n      NaN\n    \n    \n      175\n      TT\n      Trinidad and Tobago\n      North America\n      ...\n      MULTIPOLYGON (((-61.68000 10.76...\n      NaN\n      NaN\n    \n    \n      176\n      SS\n      South Sudan\n      Africa\n      ...\n      MULTIPOLYGON (((30.83385 3.5091...\n      NaN\n      NaN\n    \n  \n\n177 rows × 13 columns\n\n\n\nPlot…\n\nbase = world.plot(color=\"white\", edgecolor=\"lightgrey\")\nworld_coffee.plot(ax=base, column=\"coffee_production_2017\");\n\n\n\n\n\n\n3.3.4 Creating attributes and removing spatial information\nCalculate new column…\n\nworld2 = world.copy()\nworld2[\"pop_dens\"] = world2[\"pop\"] / world2[\"area_km2\"]\n\nUnite columns…\n\nworld2[\"con_reg\"] = world[\"continent\"] + \":\" + world2[\"region_un\"]\nworld2 = world2.drop([\"continent\", \"region_un\"], axis=1)\n\nSplit column…\n\nworld2[[\"continent\", \"region_un\"]] = world2[\"con_reg\"] \\\n    .str.split(\":\", expand=True)\n\nRename…\n\nworld2.rename(columns={\"name_long\": \"name\"})\n\n\n\n\n  \n    \n      \n      iso_a2\n      name\n      subregion\n      ...\n      con_reg\n      continent\n      region_un\n    \n  \n  \n    \n      0\n      FJ\n      Fiji\n      Melanesia\n      ...\n      Oceania:Oceania\n      Oceania\n      Oceania\n    \n    \n      1\n      TZ\n      Tanzania\n      Eastern Africa\n      ...\n      Africa:Africa\n      Africa\n      Africa\n    \n    \n      2\n      EH\n      Western Sahara\n      Northern Africa\n      ...\n      Africa:Africa\n      Africa\n      Africa\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      174\n      XK\n      Kosovo\n      Southern Europe\n      ...\n      Europe:Europe\n      Europe\n      Europe\n    \n    \n      175\n      TT\n      Trinidad and Tobago\n      Caribbean\n      ...\n      North America:Americas\n      North America\n      Americas\n    \n    \n      176\n      SS\n      South Sudan\n      Eastern Africa\n      ...\n      Africa:Africa\n      Africa\n      Africa\n    \n  \n\n177 rows × 13 columns\n\n\n\nRenaming all columns…\n\nnew_names =[\"i\", \"n\", \"c\", \"r\", \"s\", \"t\", \"a\", \"p\", \"l\", \"gP\", \"geom\"]\nworld.columns = new_names\n\nDropping geometry…\n\npd.DataFrame(world.drop(columns=\"geom\"))\n\n\n\n\n  \n    \n      \n      i\n      n\n      c\n      ...\n      p\n      l\n      gP\n    \n  \n  \n    \n      0\n      FJ\n      Fiji\n      Oceania\n      ...\n      885806.0\n      69.960000\n      8222.253784\n    \n    \n      1\n      TZ\n      Tanzania\n      Africa\n      ...\n      52234869.0\n      64.163000\n      2402.099404\n    \n    \n      2\n      EH\n      Western Sahara\n      Africa\n      ...\n      NaN\n      NaN\n      NaN\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      174\n      XK\n      Kosovo\n      Europe\n      ...\n      1821800.0\n      71.097561\n      8698.291559\n    \n    \n      175\n      TT\n      Trinidad and Tobago\n      North America\n      ...\n      1354493.0\n      70.426000\n      31181.821196\n    \n    \n      176\n      SS\n      South Sudan\n      Africa\n      ...\n      11530971.0\n      55.817000\n      1935.879400\n    \n  \n\n177 rows × 10 columns"
  },
  {
    "objectID": "03-attribute-operations.html#manipulating-raster-objects",
    "href": "03-attribute-operations.html#manipulating-raster-objects",
    "title": "3  Attribute data operations",
    "section": "3.4 Manipulating raster objects",
    "text": "3.4 Manipulating raster objects\n\n3.4.1 Raster subsetting\nWhen using rasterio, raster values are accessible through a numpy array, which can be imported with the .read method:\n\nelev = src_elev.read(1)\nelev\n\narray([[ 1.,  2.,  3.,  4.,  5.,  6.],\n       [ 7.,  8.,  9., 10., 11., 12.],\n       [13., 14., 15., 16., 17., 18.],\n       [19., 20., 21., 22., 23., 24.],\n       [25., 26., 27., 28., 29., 30.],\n       [31., 32., 33., 34., 35., 36.]], dtype=float32)\n\n\nThen, we can access any subset of cell values using numpy methods. For example:\n\nelev[0, 0]  ## Value at row 1, column 1\n\n1.0\n\n\nCell values can be modified by overwriting existing values in conjunction with a subsetting operation. The following expression, for example, sets the upper left cell of elev to 0:\n\nelev[0, 0] = 0\nelev\n\narray([[ 0.,  2.,  3.,  4.,  5.,  6.],\n       [ 7.,  8.,  9., 10., 11., 12.],\n       [13., 14., 15., 16., 17., 18.],\n       [19., 20., 21., 22., 23., 24.],\n       [25., 26., 27., 28., 29., 30.],\n       [31., 32., 33., 34., 35., 36.]], dtype=float32)\n\n\nMultiple cells can also be modified in this way:\n\nelev[0, 0:2] = 0\nelev\n\narray([[ 0.,  0.,  3.,  4.,  5.,  6.],\n       [ 7.,  8.,  9., 10., 11., 12.],\n       [13., 14., 15., 16., 17., 18.],\n       [19., 20., 21., 22., 23., 24.],\n       [25., 26., 27., 28., 29., 30.],\n       [31., 32., 33., 34., 35., 36.]], dtype=float32)\n\n\n\n\n3.4.2 Summarizing raster objects\nGlobal summaries of raster values can be calculated by applying numpy summary functions—such as np.mean—on the array with raster values. For example:\n\nnp.mean(elev)\n\n18.416666\n\n\nNote that “No Data”-safe functions–such as np.nanmean—should be used in case the raster contains “No Data” values which need to be ignored:\n\nelev[0, 2] = np.nan\nelev\n\narray([[ 0.,  0., nan,  4.,  5.,  6.],\n       [ 7.,  8.,  9., 10., 11., 12.],\n       [13., 14., 15., 16., 17., 18.],\n       [19., 20., 21., 22., 23., 24.],\n       [25., 26., 27., 28., 29., 30.],\n       [31., 32., 33., 34., 35., 36.]], dtype=float32)\n\n\n\nnp.mean(elev)\n\nnan\n\n\n\nnp.nanmean(elev)\n\n18.857143\n\n\nRaster value statistics can be visualized in a variety of ways. One approach is to “flatten” the raster values into a one-dimensional array, then use a graphical function such as plt.hist or plt.boxplot (from matplotlib.pyplot). For example:\n\nx = elev.flatten()\nplt.hist(x);"
  },
  {
    "objectID": "03-attribute-operations.html#exercises",
    "href": "03-attribute-operations.html#exercises",
    "title": "3  Attribute data operations",
    "section": "3.5 Exercises",
    "text": "3.5 Exercises"
  },
  {
    "objectID": "04-spatial-operations.html#prerequisites",
    "href": "04-spatial-operations.html#prerequisites",
    "title": "4  Spatial data operations",
    "section": "4.1 Prerequisites",
    "text": "4.1 Prerequisites\nPackages…\n\nimport geopandas as gpd\nimport numpy as np\nimport os\nimport rasterio\nimport scipy.ndimage\n\nfrom rasterio.plot import show\n\n/usr/local/lib/python3.8/dist-packages/geopandas/_compat.py:112: UserWarning: The Shapely GEOS version (3.10.2-CAPI-1.16.0) is incompatible with the GEOS version PyGEOS was compiled with (3.10.1-CAPI-1.16.0). Conversions between both will be slow.\n  warnings.warn(\n\n\nLet us load the sample data for this chapter:\n\nnz = gpd.read_file(\"data/nz.gpkg\")\nnz_height = gpd.read_file(\"data/nz_height.gpkg\")\nsrc_elev = rasterio.open(\"data/elev.tif\")\nsrc_multi_rast = rasterio.open(\"data/landsat.tif\")"
  },
  {
    "objectID": "04-spatial-operations.html#introduction",
    "href": "04-spatial-operations.html#introduction",
    "title": "4  Spatial data operations",
    "section": "4.2 Introduction",
    "text": "4.2 Introduction"
  },
  {
    "objectID": "04-spatial-operations.html#spatial-vec",
    "href": "04-spatial-operations.html#spatial-vec",
    "title": "4  Spatial data operations",
    "section": "4.3 Spatial operations on vector data",
    "text": "4.3 Spatial operations on vector data\n\n4.3.1 Spatial subsetting\nPlot…\n\nbase = nz.plot(color=\"white\", edgecolor=\"lightgrey\")\nnz_height.plot(ax=base, color=\"None\", edgecolor=\"red\");\n\n\n\n\nSpatial subsetting…\n\ncanterbury = nz[nz[\"Name\"] == \"Canterbury\"]\ncanterbury_height = nz_height.overlay(canterbury, how='intersection')\n\nPlot…\n\nbase = nz.plot(color=\"white\", edgecolor=\"lightgrey\")\ncanterbury_height.plot(ax=base, color=\"None\", edgecolor=\"red\");\n\n\n\n\nSpatial subsetting 2…\n\nnon_canterbury_height = nz_height.overlay(canterbury, how='difference')\n\nPlot…\n\nbase = nz.plot(color=\"white\", edgecolor=\"lightgrey\")\nnon_canterbury_height.plot(ax=base, color=\"None\", edgecolor=\"red\");\n\n\n\n\n…\n\n\n4.3.2 Topological relations\n…\n\nfrom shapely.geometry import Point, LineString, Polygon\npoints = gpd.GeoSeries([Point(0.2,0.1), Point(0.7,0.2), Point(0.4,0.8)])\nline = LineString([(0.4,0.2), (1,0.5)])\npoly = Polygon([(0,0), (0,1), (1,1), (1,0.5), (0,0)])\n\np = gpd.GeoSeries(poly).plot(color='yellow')\np = gpd.GeoSeries(line).plot(ax=p, color='red')\npoints.plot(ax=p)\n\n<AxesSubplot:>\n\n\n\n\n\n\npoints.intersects(poly)\n\n0     True\n1    False\n2     True\ndtype: bool\n\n\n\npoints.within(poly)\n\n0    False\n1    False\n2     True\ndtype: bool\n\n\n\npoints.touches(poly)\n\n0     True\n1    False\n2    False\ndtype: bool\n\n\n\npoints.disjoint(poly)\n\n0    False\n1     True\n2    False\ndtype: bool\n\n\n\npoints.distance(poly) < 0.2\n\n0    True\n1    True\n2    True\ndtype: bool\n\n\n\n\n4.3.3 DE-9IM strings\n…\n\n\n4.3.4 Spatial joining\n…\n\n\n4.3.5 Non-overlapping joins\n…\n\n\n4.3.6 Spatial aggregation\n…\n\n\n4.3.7 Joining incongruent layers\n…\n\n\n4.3.8 Distance relations\n…"
  },
  {
    "objectID": "04-spatial-operations.html#spatial-ras",
    "href": "04-spatial-operations.html#spatial-ras",
    "title": "4  Spatial data operations",
    "section": "4.4 Spatial operations on raster data",
    "text": "4.4 Spatial operations on raster data\n\n4.4.1 Spatial subsetting\nThe previous chapter (Section …) demonstrated how to retrieve values associated with specific cell IDs or row and column combinations. Raster objects can also be extracted by location (coordinates) and other spatial objects. To use coordinates for subsetting, we can use the .sample method of a rasterio file connection object, combined with a list of coordinate tuples. The methods is demonstrated below to find the value of the cell that covers a point located at coordinates of 0.1, 0.1 in elev. The resutned object is a generator; in case we want all values at once we can apply list. The result is 16:\n\nlist(src_elev.sample([(0.1, 0.1)]))\n\n[array([16.], dtype=float32)]\n\n\nRaster objects can also be subset with another raster object, as demonstrated in the code chunk below:\n…\n\n# ...\n\nAnother common use case of spatial subsetting is using a boolean mask, based on another raster with the same extent and resolution, or the original one, as illustrated in Figure …. To do that, we “erase” the values in the array of one raster, according to another corresponding “mask” raster. For example, let us read the elev.tif raster array:\n\nelev = src_elev.read(1)\nelev\n\narray([[ 1.,  2.,  3.,  4.,  5.,  6.],\n       [ 7.,  8.,  9., 10., 11., 12.],\n       [13., 14., 15., 16., 17., 18.],\n       [19., 20., 21., 22., 23., 24.],\n       [25., 26., 27., 28., 29., 30.],\n       [31., 32., 33., 34., 35., 36.]], dtype=float32)\n\n\nand create a correspinding random mask:\n\nnp.random.seed(1)\nmask = np.random.choice([True, False], elev.shape)\nmask\n\narray([[False, False,  True,  True, False, False],\n       [False, False, False,  True,  True, False],\n       [ True, False, False,  True,  True, False],\n       [ True,  True,  True, False,  True,  True],\n       [False,  True,  True,  True, False,  True],\n       [ True,  True, False, False, False, False]])\n\n\nIn the code chunk above, we have created a mask object called mask with values randomly assigned to True and False. Next, we want to keep those values of elev which are False in mask (i.e., they are not masked). In other words, we want to mask elev with mask. The result is stored in a copy named elev1:\n\nelev1 = elev.copy()\nelev1[mask] = np.nan\nelev1\n\narray([[ 1.,  2., nan, nan,  5.,  6.],\n       [ 7.,  8.,  9., nan, nan, 12.],\n       [nan, 14., 15., nan, nan, 18.],\n       [nan, nan, nan, 22., nan, nan],\n       [25., nan, nan, nan, 29., nan],\n       [nan, nan, 33., 34., 35., 36.]], dtype=float32)\n\n\nThe result is shown in figure…\n\nfig, axes = plt.subplots(ncols=3, figsize=(9,5))\nshow(elev, ax=axes[0])\nshow(mask, ax=axes[1])\nshow(elev1, ax=axes[2])\naxes[0].set_title(\"Original\")\naxes[1].set_title(\"Mask\")\naxes[2].set_title(\"Result\");\n\n\n\n\nThe above approach can be also used to replace some values (e.g., expected to be wrong) with nan:\n\nelev[elev < 20] = np.nan\nelev\n\narray([[nan, nan, nan, nan, nan, nan],\n       [nan, nan, nan, nan, nan, nan],\n       [nan, nan, nan, nan, nan, nan],\n       [nan, 20., 21., 22., 23., 24.],\n       [25., 26., 27., 28., 29., 30.],\n       [31., 32., 33., 34., 35., 36.]], dtype=float32)\n\n\nThese operations are in fact Boolean local operations, since we compare cell-wise two rasters. The next subsection explores these and related operations in more detail.\n\n\n4.4.2 Map algebra\nThe term ‘map algebra’ was coined in the late 1970s to describe a “set of conventions, capabilities, and techniques” for the analysis of geographic raster and (although less prominently) vector data (Tomlin 1994). In this context, we define map algebra more narrowly, as operations that modify or summarise raster cell values, with reference to surrounding cells, zones, or statistical functions that apply to every cell.\nMap algebra operations tend to be fast, because raster datasets only implicitly store coordinates, hence the old adage “raster is faster but vector is corrector”. The location of cells in raster datasets can be calculated by using its matrix position and the resolution and origin of the dataset (stored in the header). For the processing, however, the geographic position of a cell is barely relevant as long as we make sure that the cell position is still the same after the processing. Additionally, if two or more raster datasets share the same extent, projection and resolution, one could treat them as matrices for the processing.\nThis is the way that map algebra works with the terra package. First, the headers of the raster datasets are queried and (in cases where map algebra operations work on more than one dataset) checked to ensure the datasets are compatible. Second, map algebra retains the so-called one-to-one locational correspondence, meaning that cells cannot move. This differs from matrix algebra, in which values change position, for example when multiplying or dividing matrices.\nMap algebra (or cartographic modeling with raster data) divides raster operations into four subclasses (Tomlin 1990), with each working on one or several grids simultaneously:\n\nLocal or per-cell operations\nFocal or neighborhood operations. Most often the output cell value is the result of a 3 x 3 input cell block\nZonal operations are similar to focal operations, but the surrounding pixel grid on which new values are computed can have irregular sizes and shapes\nGlobal or per-raster operations; that means the output cell derives its value potentially from one or several entire rasters\n\nThis typology classifies map algebra operations by the number of cells used for each pixel processing step and the type of the output. For the sake of completeness, we should mention that raster operations can also be classified by discipline such as terrain, hydrological analysis, or image classification. The following sections explain how each type of map algebra operations can be used, with reference to worked examples.\n\n\n4.4.3 Local operations\nFirst, we need to read raster values:\n\nelev = src_elev.read(1)\nelev\n\narray([[ 1.,  2.,  3.,  4.,  5.,  6.],\n       [ 7.,  8.,  9., 10., 11., 12.],\n       [13., 14., 15., 16., 17., 18.],\n       [19., 20., 21., 22., 23., 24.],\n       [25., 26., 27., 28., 29., 30.],\n       [31., 32., 33., 34., 35., 36.]], dtype=float32)\n\n\nNow, any element-wise array operation can be applied. For example:\n\nelev + elev\n\narray([[ 2.,  4.,  6.,  8., 10., 12.],\n       [14., 16., 18., 20., 22., 24.],\n       [26., 28., 30., 32., 34., 36.],\n       [38., 40., 42., 44., 46., 48.],\n       [50., 52., 54., 56., 58., 60.],\n       [62., 64., 66., 68., 70., 72.]], dtype=float32)\n\n\nHere are few more examples:\n\nfig, axes = plt.subplots(ncols=4, figsize=(9,5))\nshow(elev + elev, ax=axes[0], cmap=\"Oranges\")\nshow(elev ** 2, ax=axes[1], cmap=\"Oranges\")\nshow(np.log(elev), ax=axes[2], cmap=\"Oranges\")\nshow(elev > 5, ax=axes[3], cmap=\"Oranges\")\naxes[0].set_title(\"elev+elev\")\naxes[1].set_title(\"elev ** 2\")\naxes[2].set_title(\"np.log(elev)\")\naxes[3].set_title(\"elev > 5\");\n\n\n\n\nAnother good example of local operations is the classification of intervals of numeric values into groups such as grouping a digital elevation model into low (class 1), middle (class 2) and high elevations (class 3). Here, we assign the raster values in the ranges 0–12, 12–24 and 24–36 are reclassified to take values 1, 2 and 3, respectively…\n\nrecl = elev.copy()\nrecl[(elev > 0)  & (elev <= 12)] = 1\nrecl[(elev > 12) & (elev <= 24)] = 2\nrecl[(elev > 24) & (elev <= 36)] = 3\n\nPlot…\n\nfig, axes = plt.subplots(ncols=2, figsize=(9,5))\nshow(elev, ax=axes[0], cmap=\"Oranges\")\nshow(recl, ax=axes[1], cmap=\"Oranges\")\naxes[0].set_title(\"Original\")\naxes[1].set_title(\"Reclassified\");\n\n\n\n\nThe calculation of the normalized difference vegetation index (NDVI) is a well-known local (pixel-by-pixel) raster operation. It returns a raster with values between -1 and 1; positive values indicate the presence of living plants (mostly > 0.2). NDVI is calculated from red and near-infrared (NIR) bands of remotely sensed imagery, typically from satellite systems such as Landsat or Sentinel. Vegetation absorbs light heavily in the visible light spectrum, and especially in the red channel, while reflecting NIR light, explaining the NVDI formula:\n\\[NDVI=\\frac{NIR-Red} {NIR+Red}\\]\nLet’s calculate NDVI for the multispectral satellite file of the Zion National Park.\n\nmulti_rast = src_multi_rast.read()\nnir = multi_rast[3,:,:]\nred = multi_rast[2,:,:]\nndvi = (nir-red)/(nir+red)\n\nConvert values >1 to “No Data”:\n\nndvi[ndvi>1] = np.nan\n\nWhen plotting an RGB image using the show function, the function assumes that:\n\nValues are in the range [0,1] for floats, or [0,255] for integers (otherwise clipped)\nThe order of bands is RGB\n\nTo “prepare” the multi-band raster for show, we therefore reverse the order of bands (which is originally BGR+NIR), and divided by the maximum to set the maximum value at 1:\n\nmulti_rast_rgb = multi_rast[(2,1,0), :, :]/multi_rast.max()\n\nPlot…\n\nfig, axes = plt.subplots(ncols=2, figsize=(9,5))\nshow(multi_rast_rgb, ax=axes[0], cmap=\"RdYlGn\")\nshow(ndvi, ax=axes[1], cmap=\"Greens\")\naxes[0].set_title(\"RGB image\")\naxes[1].set_title(\"NDVI\");\n\n\n\n\n\n\n4.4.4 Focal operations\nWhile local functions operate on one cell, though possibly from multiple layers, focal operations take into account a central (focal) cell and its neighbors. The neighborhood (also named kernel, filter or moving window) under consideration is typically of size 3-by-3 cells (that is the central cell and its eight surrounding neighbors), but can take on any other (not necessarily rectangular) shape as defined by the user. A focal operation applies an aggregation function to all cells within the specified neighborhood, uses the corresponding output as the new value for the the central cell, and moves on to the next central cell (Figure …). Other names for this operation are spatial filtering and convolution (Burrough, McDonnell, and Lloyd 2015).\nIn Python, the scipy.ndimage package has a comprehensive collection of functions to perform filtering of numpy arrays, such as:\n\nminimum_filter\nmaximum_filter\nuniform_filter (i.e., mean filter)\nmedian_filter etc.\n\nIn this group of functions, we define the shape of the moving window with either one of:\n\nsize—a single number or tuple, implying a filter of those dimensions\nfootprint—a boolean array, representing both the window shape and the identity of elements being included\n\nIn addition to specific built-in filters,\n\nconvolve applies the sum function after multiplying by a custom weights array\ngeneric_filter makes it possible to pass any custom function, where the user can specify any type of custom window-based calculatio.\n\nFor example, here we apply the minimum filter with window size of 3 on elev:\n\nelev\n\narray([[ 1.,  2.,  3.,  4.,  5.,  6.],\n       [ 7.,  8.,  9., 10., 11., 12.],\n       [13., 14., 15., 16., 17., 18.],\n       [19., 20., 21., 22., 23., 24.],\n       [25., 26., 27., 28., 29., 30.],\n       [31., 32., 33., 34., 35., 36.]], dtype=float32)\n\n\n\nelev_min = scipy.ndimage.minimum_filter(elev, size=3)\nelev_min\n\narray([[ 1.,  1.,  2.,  3.,  4.,  5.],\n       [ 1.,  1.,  2.,  3.,  4.,  5.],\n       [ 7.,  7.,  8.,  9., 10., 11.],\n       [13., 13., 14., 15., 16., 17.],\n       [19., 19., 20., 21., 22., 23.],\n       [25., 25., 26., 27., 28., 29.]], dtype=float32)\n\n\nSpecial care should be given to the edge pixels. How should they be calculated? scipy.ndimage gives several options through the mode parameter:\n\nreflect (the default)\nconstant\nnearest\nmirror\nwrap\n\nSometimes artificially extending raster edges is considered unsuitable. In other words, we may wish the resulting raster to contain pixel values with “complete” windows only, for example to have a uniform sample size or because values in all directions matter (such as in topographic calculations). There is no specific option not to extent edges in scipy.ndimage. However, to get the same effect, the edges of the filtered array can be assigned with nan, in a number of rows and columns according to filter size. For example, when using a filter of size=3, the first “layer” of pixels may be assigned with nan, reflecting the fact that these pixels have incomplete 3*3 neighborhoods:\n\nelev_min[:, [0, -1]] = np.nan\nelev_min[[0, -1], :] = np.nan\nelev_min\n\narray([[nan, nan, nan, nan, nan, nan],\n       [nan,  1.,  2.,  3.,  4., nan],\n       [nan,  7.,  8.,  9., 10., nan],\n       [nan, 13., 14., 15., 16., nan],\n       [nan, 19., 20., 21., 22., nan],\n       [nan, nan, nan, nan, nan, nan]], dtype=float32)\n\n\nWe can quickly check if the output meets our expectations. In our example, the minimum value has to be always the upper left corner of the moving window (remember we have created the input raster by row-wise incrementing the cell values by one starting at the upper left corner).\nFocal functions or filters play a dominant role in image processing. Low-pass or smoothing filters use the mean function to remove extremes. In the case of categorical data, we can replace the mean with the mode, which is the most common value. By contrast, high-pass filters accentuate features. The line detection Laplace and Sobel filters might serve as an example here.\nTerrain processing, the calculation of topographic characteristics such as slope, aspect and flow directions, relies on focal functions. The TerrainAttribute function from package richdem can be used to calculate common metrics, specified through the attrib argument, namely:\n\nslope_riserun Horn (1981) doi: 10.1109/PROC.1981.11918\nslope_percentage Horn (1981) doi: 10.1109/PROC.1981.11918\nslope_degrees Horn (1981) doi: 10.1109/PROC.1981.11918\nslope_radians Horn (1981) doi: 10.1109/PROC.1981.11918\naspect Horn (1981) doi: 10.1109/PROC.1981.11918\ncurvature Zevenbergen and Thorne (1987) doi: 10.1002/esp.3290120107\nplanform_curvature Zevenbergen and Thorne (1987) doi: 10.1002/esp.3290120107\nprofile_curvature Zevenbergen and Thorne (1987) doi: 10.1002/esp.3290120107\n\n\n\n4.4.5 Zonal operations\n…\n\n\n4.4.6 Global operations and distances\n…\n\n\n4.4.7 Map algebra counterparts in vector processing\n…\n\n\n4.4.8 Merging rasters\n…"
  },
  {
    "objectID": "04-spatial-operations.html#exercises",
    "href": "04-spatial-operations.html#exercises",
    "title": "4  Spatial data operations",
    "section": "4.5 Exercises",
    "text": "4.5 Exercises\n\nWrite a function which accepts and array and an int specifying the number of rows/columns to erase along an array edges. The function needs to return the modified array with nan values along its edges."
  },
  {
    "objectID": "05-geometry-operations.html#prerequisites",
    "href": "05-geometry-operations.html#prerequisites",
    "title": "5  Geometry operations",
    "section": "5.1 Prerequisites",
    "text": "5.1 Prerequisites\nPackages…\n\nimport shapely.geometry\nimport geopandas as gpd\n\n/usr/local/lib/python3.8/dist-packages/geopandas/_compat.py:112: UserWarning: The Shapely GEOS version (3.10.2-CAPI-1.16.0) is incompatible with the GEOS version PyGEOS was compiled with (3.10.1-CAPI-1.16.0). Conversions between both will be slow.\n  warnings.warn(\n\n\nSample data…\n\nseine = gpd.read_file(\"data/seine.gpkg\")\nus_states = gpd.read_file(\"data/us_states.gpkg\")\nnz = gpd.read_file(\"data/nz.gpkg\")"
  },
  {
    "objectID": "05-geometry-operations.html#introduction",
    "href": "05-geometry-operations.html#introduction",
    "title": "5  Geometry operations",
    "section": "5.2 Introduction",
    "text": "5.2 Introduction"
  },
  {
    "objectID": "05-geometry-operations.html#geo-vec",
    "href": "05-geometry-operations.html#geo-vec",
    "title": "5  Geometry operations",
    "section": "5.3 Geometric operations on vector data",
    "text": "5.3 Geometric operations on vector data\n\n5.3.1 Simplification\nSimplify…\n\nseine_simp = seine.simplify(2000)  # 2000 m\n\nPlot:\n\nfig, axes = plt.subplots(ncols=2)\nseine.plot(ax=axes[0])\nseine_simp.plot(ax=axes[1])\naxes[0].set_title(\"Original\")\naxes[1].set_title(\"Simplified (d=2000 m)\");\n\n\n\n\nCompare number of nodes:\n\nimport sys\nsys.getsizeof(seine)       ## Original (bytes)\n\n354\n\n\n\nsys.getsizeof(seine_simp)  ## Simplified (bytes)\n\n168\n\n\nUS states example…. Transform…\n\nus_states2163 = us_states.to_crs(2163)\n\nSimplify…\n\nus_states_simp1 = us_states2163.simplify(100000)\n\nPlot…\n\nus_states_simp1.plot();\n\n\n\n\n\nimport topojson as tp\ntopo = tp.Topology(us_states2163, prequantize=False)\nus_states_simp2 = topo.toposimplify(100000).to_gdf()\n\n\nfig, axes = plt.subplots(ncols=3, figsize=(9,5))\nus_states2163.plot(ax=axes[0])\nus_states_simp1.plot(ax=axes[1])\nus_states_simp2.plot(ax=axes[2])\naxes[0].set_title(\"Original\")\naxes[1].set_title(\"Simplified (w/ geopandas)\")\naxes[2].set_title(\"Simplified (w/ topojson)\");\n\n\n\n\n\n\n5.3.2 Centroids\nCentroid operations identify the center of geographic objects. Like statistical measures of central tendency (including mean and median definitions of ‘average’), there are many ways to define the geographic center of an object. All of them create single point representations of more complex vector objects.\nThe most commonly used centroid operation is the geographic centroid. This type of centroid operation (often referred to as ‘the centroid’) represents the center of mass in a spatial object (think of balancing a plate on your finger). Geographic centroids have many uses, for example to create a simple point representation of complex geometries, or to estimate distances between polygons. Centroids of the geometries in a GeoSeries or a GeoDataFrame are accessible through the .centroid property, as demonstrated in the code below, which generates the geographic centroids of regions in New Zealand and tributaries to the River Seine, illustrated with black points in Figure ….\n\nnz_centroid = nz.centroid\nseine_centroid = seine.centroid\n\nSometimes the geographic centroid falls outside the boundaries of their parent objects (think of a doughnut). In such cases point on surface operations can be used to guarantee the point will be in the parent object (e.g., for labeling irregular multipolygon objects such as island states), as illustrated by the red points in Figure …. Notice that these red points always lie on their parent objects. They were created with the representative_point method, as follows:\n\nnz_pos = nz.representative_point()\nseine_pos = seine.representative_point()\n\nThe centroids and points in surface are illustrated in Figure 5.1:\n\nfig, axes = plt.subplots(ncols=2)\nbase = nz.plot(ax=axes[0], color=\"white\", edgecolor=\"lightgrey\")\nnz_centroid.plot(ax=axes[0], color=\"None\", edgecolor=\"black\")\nnz_pos.plot(ax=axes[0], color=\"None\", edgecolor=\"red\");\nbase = seine.plot(ax=axes[1], color=\"grey\")\nseine_centroid.plot(ax=axes[1], color=\"None\", edgecolor=\"black\")\nseine_pos.plot(ax=axes[1], color=\"None\", edgecolor=\"red\");\n\n\n\n\nFigure 5.1: Centroids (black) and points on surface red of New Zealand and Seine datasets.\n\n\n\n\n\n\n5.3.3 Buffers\nBuffers…\n\nseine_buff_5km = seine.buffer(5000)\nseine_buff_50km = seine.buffer(50000)\n\nPlot…\n\nfig, axes = plt.subplots(ncols=2)\nseine_buff_5km.plot(ax=axes[0], color=\"None\", edgecolor=[\"red\", \"green\", \"blue\"])\nseine_buff_50km.plot(ax=axes[1], color=\"None\", edgecolor=[\"red\", \"green\", \"blue\"])\naxes[0].set_title(\"5 km buffer\")\naxes[1].set_title(\"50 km buffer\");\n\n\n\n\n\n\n5.3.4 Affine transformations\nAffine transformations of GeoSeries can be done using the .affine_transform method, which is a wrapper around the shapely.affinity.affine_transform function. According to the documentation, a 2D affine transformation requires a six-parameter list [a,b,d,e,xoff,yoff] which represents the following equations for transforming the coordinates:\n\\[\nx' = a x + b y + x_\\mathrm{off}\n\\]\n\\[\ny' = d x + e y + y_\\mathrm{off}\n\\]\nThere are also simplified GeoSeries methods for specific scenarios:\n\nGeoSeries.rotate(angle, origin='center', use_radians=False)\nGeoSeries.scale(xfact=1.0, yfact=1.0, zfact=1.0, origin='center')\nGeoSeries.skew(angle, origin='center', use_radians=False)\nGeoSeries.translate(xoff=0.0, yoff=0.0, zoff=0.0)\n\nFor example, shifting only requires the \\(x_{off}\\) and \\(y_{off}\\), using .translate. The code below shifts the y-coordinates by 100,000 meters to the north, but leaves the x-coordinates untouched:\n\nnz_shift = nz[\"geometry\"].translate(0, 100000)\n\nScale…\n\nnz_scale = nz[\"geometry\"].scale(0.5, 0.5, origin=\"centroid\")\n\nRotate…\n\nnz_rotate = nz[\"geometry\"].rotate(-30, origin=\"centroid\")\n\nPlot…\n\nfig, axes = plt.subplots(ncols=3, figsize=(9,5))\nnz.plot(ax=axes[0], color=\"lightgrey\", edgecolor=\"darkgrey\")\nnz_shift.plot(ax=axes[0], color=\"red\", edgecolor=\"darkgrey\")\nnz.plot(ax=axes[1], color=\"lightgrey\", edgecolor=\"darkgrey\")\nnz_scale.plot(ax=axes[1], color=\"red\", edgecolor=\"darkgrey\")\nnz.plot(ax=axes[2], color=\"lightgrey\", edgecolor=\"darkgrey\")\nnz_rotate.plot(ax=axes[2], color=\"red\", edgecolor=\"darkgrey\")\naxes[0].set_title(\"Shift\")\naxes[1].set_title(\"Scale\")\naxes[2].set_title(\"Rotate\");\n\n\n\n\n\n\n5.3.5 Clipping\n…\n\n\n5.3.6 Subsetting and clipping\n…\n\n\n5.3.7 Geometry unions\n…\n\n\n5.3.8 Type transformations\nTransformation of geometries, from one type to another, also known as “geometry casting”, is often required to facilitate spatial analysis. The shapely package can be used for geometry casting. The exact expression(s) depend on the specific transformation we are interested in. In general, you need to figure out the required input of the respective construstor function according to the “destination” geometry (e.g., shapely.geometry.LineString, etc.), then reshape the input of the “source” geometry into the right form to be passed to that function.\nLet’s create a \"MultiPoint\" to illustrate how geometry casting works on shapely geometry objects:\n\nmultipoint = shapely.geometry.MultiPoint([(1,1), (3,3), (5,1)])\nmultipoint\n\n\n\n\nA \"LineString\" can be created using shapely.geometry.LineString from a list of points. Consequently, a \"MultiPoint\" can be converted to a \"LineString\" by extracting the individual points into a list, then passing them to shapely.geometry.LineString:\n\nlinestring = shapely.geometry.LineString(list(multipoint.geoms))\nlinestring\n\n\n\n\nA \"Polygon\" can also be created using funtion shapely.geometry.Polygon, which acceps accepts a sequence of points. In principle, the last coordinate must be equal to the first, in order to form a closed shape. However, shapely.geometry.Polygon is able to complete the last coordinate automatically. Therefore:\n\npolygon = shapely.geometry.Polygon(list(multipoint.geoms))\npolygon\n\n\n\n\nThe source \"MultiPoint\" geometry, and the derived \"LineString\" and \"Polygon\" geometries are shown in Figure 5.2. Note that we convert the shapely geometries to GeoSeries for easier multi-panel plotting:\n\nfig, axes = plt.subplots(ncols=3, figsize=(9,5))\ngpd.GeoSeries(multipoint).plot(ax=axes[0])\ngpd.GeoSeries(linestring).plot(ax=axes[1])\ngpd.GeoSeries(polygon).plot(ax=axes[2])\naxes[0].set_title(\"MultiPoint\")\naxes[1].set_title(\"LineString\")\naxes[2].set_title(\"Polygon\");\n\n\n\n\nFigure 5.2: Examples of linestring and polygon casted from a multipoint geometry.\n\n\n\n\nConversion from multipoint to linestring is a common operation that creates a line object from ordered point observations, such as GPS measurements or geotagged media. This allows spatial operations such as the length of the path traveled. Conversion from multipoint or linestring to polygon is often used to calculate an area, for example from the set of GPS measurements taken around a lake or from the corners of a building lot.\nOur \"LineString\" geometry can be converted bact to a \"MultiPoint\" geometry by passing its coordinates directly to shapely.geometry.MultiPoint:\n\n# 'LineString' -> 'MultiPoint'\nshapely.geometry.MultiPoint(linestring.coords)\n\n\n\n\nThe \"Polygon\" (exterior) coordinates can be passed to shapely.geometry.MultiPoint as well:\n\n# 'Polygon' -> 'MultiPoint'\nshapely.geometry.MultiPoint(polygon.exterior.coords)\n\n\n\n\n…"
  },
  {
    "objectID": "05-geometry-operations.html#geo-ras",
    "href": "05-geometry-operations.html#geo-ras",
    "title": "5  Geometry operations",
    "section": "5.4 Geometric operations on raster data",
    "text": "5.4 Geometric operations on raster data\n\n5.4.1 Geometric intersections\n…\n\n\n5.4.2 Extent and origin\n…\n\n\n5.4.3 Aggregation and disaggregation\n…\n\n\n5.4.4 Resampling\n…"
  },
  {
    "objectID": "05-geometry-operations.html#exercises",
    "href": "05-geometry-operations.html#exercises",
    "title": "5  Geometry operations",
    "section": "5.5 Exercises",
    "text": "5.5 Exercises"
  },
  {
    "objectID": "06-raster-vector.html#prerequisites",
    "href": "06-raster-vector.html#prerequisites",
    "title": "6  Raster-vector interactions",
    "section": "6.1 Prerequisites",
    "text": "6.1 Prerequisites\nLet’s import the required packages:\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport geopandas as gpd\nimport rasterio\nimport rasterio.mask\nimport rasterstats\nfrom rasterio.plot import show\n\n/usr/local/lib/python3.8/dist-packages/geopandas/_compat.py:112: UserWarning: The Shapely GEOS version (3.10.2-CAPI-1.16.0) is incompatible with the GEOS version PyGEOS was compiled with (3.10.1-CAPI-1.16.0). Conversions between both will be slow.\n  warnings.warn(\n\n\nand load the sample data:\n\nsrc_srtm = rasterio.open(\"data/srtm.tif\")\nzion = gpd.read_file(\"data/zion.gpkg\")\nzion_points = gpd.read_file(\"data/zion_points.gpkg\")"
  },
  {
    "objectID": "06-raster-vector.html#introduction",
    "href": "06-raster-vector.html#introduction",
    "title": "6  Raster-vector interactions",
    "section": "6.2 Introduction",
    "text": "6.2 Introduction"
  },
  {
    "objectID": "06-raster-vector.html#raster-cropping",
    "href": "06-raster-vector.html#raster-cropping",
    "title": "6  Raster-vector interactions",
    "section": "6.3 Raster cropping",
    "text": "6.3 Raster cropping\nMany geographic data projects involve integrating data from many different sources, such as remote sensing images (rasters) and administrative boundaries (vectors). Often the extent of input raster datasets is larger than the area of interest. In this case raster cropping and masking are useful for unifying the spatial extent of input data. Both operations reduce object memory use and associated computational resources for subsequent analysis steps, and may be a necessary preprocessing step before creating attractive maps involving raster data.\nWe will use two objects to illustrate raster cropping:\n\nThe srtm.tif raster representing elevation (meters above sea level) in south-western Utah\nThe zion.gpkg vector layer representing the Zion National Park\n\nBoth target and cropping objects must have the same projection. The following reprojects the vector layer zion into the CRS of the raster src_srtm:\n\nzion = zion.to_crs(src_srtm.crs)\n\nTo mask the image, i.e., convert all pixels which do not intersect with the zion polygon to “No Data”, we use the rasterio.mask.mask function as follows:\n\nout_image_mask, out_transform_mask = rasterio.mask.mask(\n    src_srtm, \n    zion[\"geometry\"], \n    crop=False, \n    nodata=9999\n)\n\nNote that we need to specify a “No Data” value in agreement with the raster data type. Since srtm.tif is of type uint16, we choose 9999 (a positive integer that is guaranteed not to occur in the raster).\nThe result is the out_image array with the masked values:\n\nout_image_mask\n\narray([[[9999, 9999, 9999, ..., 9999, 9999, 9999],\n        [9999, 9999, 9999, ..., 9999, 9999, 9999],\n        [9999, 9999, 9999, ..., 9999, 9999, 9999],\n        ...,\n        [9999, 9999, 9999, ..., 9999, 9999, 9999],\n        [9999, 9999, 9999, ..., 9999, 9999, 9999],\n        [9999, 9999, 9999, ..., 9999, 9999, 9999]]], dtype=uint16)\n\n\nand the new out_transform:\n\nout_transform_mask\n\nAffine(0.0008333333332777796, 0.0, -113.23958321278403,\n       0.0, -0.0008333333332777843, 37.512916763165805)\n\n\nNote that masking (without cropping!) does not modify the raster spatial configuration. Therefore, the new transform is identical to the original:\n\nsrc_srtm.transform\n\nAffine(0.0008333333332777796, 0.0, -113.23958321278403,\n       0.0, -0.0008333333332777843, 37.512916763165805)\n\n\nUnfortunately, the out_image and out_transform object do not contain any information indicating that 9999 represents “No Data”. To associate the information with the raster, we must write it to file along with the corresponding metadata. For example, to write the cropped raster to file, we need to modify the “No Data” setting in the metadata:\n\nout_meta = src_srtm.meta\nout_meta.update(nodata=9999)\nout_meta\n\n{'driver': 'GTiff',\n 'dtype': 'uint16',\n 'nodata': 9999,\n 'width': 465,\n 'height': 457,\n 'count': 1,\n 'crs': CRS.from_epsg(4326),\n 'transform': Affine(0.0008333333332777796, 0.0, -113.23958321278403,\n        0.0, -0.0008333333332777843, 37.512916763165805)}\n\n\nThen we can write the cropped raster to file:\n\nnew_dataset = rasterio.open(\"output/srtm_masked.tif\", \"w\", **out_meta)\nnew_dataset.write(out_image_mask)\nnew_dataset.close()\n\nNow we can re-import the raster:\n\nsrc_srtm_mask = rasterio.open(\"output/srtm_masked.tif\")\n\nThe .meta property contains the nodata entry. Now, any relevant operation (such as plotting) will take “No Data” into account:\n\nsrc_srtm_mask.meta\n\n{'driver': 'GTiff',\n 'dtype': 'uint16',\n 'nodata': 9999.0,\n 'width': 465,\n 'height': 457,\n 'count': 1,\n 'crs': CRS.from_epsg(4326),\n 'transform': Affine(0.0008333333332777796, 0.0, -113.23958321278403,\n        0.0, -0.0008333333332777843, 37.512916763165805)}\n\n\nCropping means reducing the raster extent to the extent of the vector layer:\n\nTo crop and mask, we can use the same in rasterio.mask.mask expression shown above for masking, just setting crop=True instead of crop=False.\nTo just crop, without masking, we can derive the extent polygon and then crop using it.\n\nFor example, here is how we can obtain the extent polygon of zion, as a shapely geometry object:\n\nbb = zion.unary_union.envelope\nbb\n\n\n\n\nThe extent can now be used for masking. Here, we are also using the all_touched=True option so that pixels partially overlapping with the extent are included:\n\nout_image_crop, out_transform_crop = rasterio.mask.mask(\n    src_srtm, \n    [bb], \n    crop=True, \n    all_touched=True, \n    nodata=9999\n)\n\nFigure 6.1 shows the original raster, and the cropped and masked results.\n\nfig, axes = plt.subplots(ncols=3, figsize=(9,5))\nshow(src_srtm, ax=axes[0])\nzion.plot(ax=axes[0], color=\"none\", edgecolor=\"black\")\nshow(src_srtm_mask, ax=axes[1])\nzion.plot(ax=axes[1], color=\"none\", edgecolor=\"black\")\nshow(out_image_crop, transform=out_transform_crop, ax=axes[2])\nzion.plot(ax=axes[2], color=\"none\", edgecolor=\"black\")\naxes[0].set_title(\"Original\")\naxes[1].set_title(\"Mask\")\naxes[2].set_title(\"Crop\");\n\n\n\n\nFigure 6.1: Raster masking and cropping"
  },
  {
    "objectID": "06-raster-vector.html#raster-extraction",
    "href": "06-raster-vector.html#raster-extraction",
    "title": "6  Raster-vector interactions",
    "section": "6.4 Raster extraction",
    "text": "6.4 Raster extraction\nRaster extraction is the process of identifying and returning the values associated with a ‘target’ raster at specific locations, based on a (typically vector) geographic ‘selector’ object. The reverse of raster extraction — assigning raster cell values based on vector objects — is rasterization, described in Section …\nIn the following examples, we use a third-party package called rasterstats, which is specifically aimed at extracting raster values:\n\nto points, via the rasterstats.point_query function, or\nto polygons, via the rasterstats.zonal_stats function.\n\n\n6.4.1 Extraction to points\nThe basic example is of extracting the value of a raster cell at specific points. For this purpose, we will use zion_points, which contain a sample of 30 locations within the Zion National Park (Figure …). The following expression extracts elevation values from srtm:\n\nresult = rasterstats.point_query(\n    zion_points, \n    src_srtm.read(1), \n    nodata = src_srtm.nodata, \n    affine = src_srtm.transform,\n    interpolate='nearest'\n)\n\nThe resulting object is a list of raster values, corresponding to zion_points:\n\nresult[:5]\n\n[1802, 2433, 1886, 1370, 1452]\n\n\nTo create a DataFrame with points’ IDs (one value per vector’s row) and related srtm values for each point, we need to assign it:\n\nzion_points['elev'] = result\nzion_points\n\n\n\n\n  \n    \n      \n      geometry\n      elev\n    \n  \n  \n    \n      0\n      POINT (-112.91587 37.20013)\n      1802\n    \n    \n      1\n      POINT (-113.09369 37.39263)\n      2433\n    \n    \n      2\n      POINT (-113.02462 37.33466)\n      1886\n    \n    \n      ...\n      ...\n      ...\n    \n    \n      27\n      POINT (-113.03655 37.23446)\n      1372\n    \n    \n      28\n      POINT (-113.13933 37.39004)\n      1905\n    \n    \n      29\n      POINT (-113.09677 37.24237)\n      1574\n    \n  \n\n30 rows × 2 columns\n\n\n\n\n\n6.4.2 Extraction to lines\nRaster extraction also works with line selectors. Then, it extracts one value for each raster cell touched by a line. However, the line extraction approach is not recommended to obtain values along the transects as it is hard to get the correct distance between each pair of extracted raster values.\nIn this case, a better approach is to split the line into many points and then extract the values for these points. To demonstrate this, the code below creates zion_transect, a straight line going from northwest to southeast of the Zion National Park, illustrated in Figure 6.3(A) (see Section 2.2 for a recap on the vector data model):\nzion_transect = cbind(c(-113.2, -112.9), c(37.45, 37.2)) |> st_linestring() |> st_sfc(crs = crs(srtm)) |> st_sf(geometry = _)\nThe utility of extracting heights from a linear selector is illustrated by imagining that you are planning a hike. The method demonstrated below provides an ‘elevation profile’ of the route (the line does not need to be straight), useful for estimating how long it will take due to long climbs.\nThe first step is to add a unique id for each transect. Next, with the st_segmentize() function we can add points along our line(s) with a provided density (dfMaxLength) and convert them into points with st_cast().\nzion_transect$id = 1:nrow(zion_transect) zion_transect = st_segmentize(zion_transect, dfMaxLength = 250) zion_transect = st_cast(zion_transect, “POINT”)\nNow, we have a large set of points, and we want to derive a distance between the first point in our transects and each of the subsequent points. In this case, we only have one transect, but the code, in principle, should work on any number of transects:\nzion_transect = zion_transect |> group_by(id) |> mutate(dist = st_distance(geometry)[, 1])\nFinally, we can extract elevation values for each point in our transects and combine this information with our main object.\nzion_elev = terra::extract(srtm, vect(zion_transect)) zion_transect = cbind(zion_transect, zion_elev)\nThe resulting zion_transect can be used to create elevation profiles, as illustrated in Figure 6.3(B).\n\n\n6.4.3 Extraction to polygons\nThe final type of geographic vector object for raster extraction is polygons. Like lines, polygons tend to return many raster values per polygon. Typically, we generate summary statistics for raster values per polygon, for example to characterize a single region or to compare many regions. The generation of raster summary statistics, by polygons, is demonstrated in the code below, which creates a list of summary statistics (in this case a list of length 1, since there is just one polygon), again using rasterstats:\n\nrasterstats.zonal_stats(\n    zion, \n    src_srtm.read(1), \n    nodata = src_srtm.nodata, \n    affine = src_srtm.transform, \n    stats = ['mean', 'min', 'max']\n)\n\n[{'min': 1122.0, 'max': 2661.0, 'mean': 1818.211830154405}]\n\n\nThe results provide useful summaries, for example that the maximum height in the park is around 2,661 meters above see level (other summary statistics, such as standard deviation, can also be calculated in this way). Because there is only one polygon in the example a data frame with a single row is returned; however, the method works when multiple selector polygons are used.\nNote the stats argument, where we determine what type of statistics are calculated per polygon. Possible values other than \"mean\", \"min\", \"max\" are:\n\n\"count\"—The number of valid (i.e., excluding “No Data”) pixels\n\"nodata\"—The number of pixels with “No Data”\n\"majority\"—The most frequently occurring value\n\"median\"—The median value\n\nSee the documentation for the complete list. Additionally, the zonal_stats function accepts user-defined functions for calculating any custom statistics.\nFrom polygon (nlcd)…\nThe similar approach works for counting occurrences of categorical raster values within polygons. This is illustrated with a land cover dataset (nlcd) from the spDataLarge package in Figure 6.4(B), and demonstrated in the code below:\nnlcd = rast(system.file(“raster/nlcd.tif”, package = “spDataLarge”)) zion2 = st_transform(zion, st_crs(nlcd)) zion_nlcd = terra::extract(nlcd, vect(zion2)) zion_nlcd |> group_by(ID, levels) |> count() #> # A tibble: 7 × 3 #> # Groups: ID, levels [7] #> ID levels n #>    #> 1 1 Developed 4205 #> 2 1 Barren 98285 #> 3 1 Forest 298299 #> 4 1 Shrubland 203701 #> # … with 3 more rows"
  },
  {
    "objectID": "06-raster-vector.html#rasterization",
    "href": "06-raster-vector.html#rasterization",
    "title": "6  Raster-vector interactions",
    "section": "6.5 Rasterization",
    "text": "6.5 Rasterization\n…"
  },
  {
    "objectID": "06-raster-vector.html#spatial-vectorization",
    "href": "06-raster-vector.html#spatial-vectorization",
    "title": "6  Raster-vector interactions",
    "section": "6.6 Spatial vectorization",
    "text": "6.6 Spatial vectorization\nSpatial vectorization is the counterpart of rasterization (Section …), but in the opposite direction. It involves converting spatially continuous raster data into spatially discrete vector data such as points, lines or polygons.\nThere are three standard methods to convert a raster to a vector layer:\n\nRaster to polygons\nRaster to points\nRaster to contours\n\nThe most straightforward form of vectorization is the first one, converting raster cells to polygons, where each pixel is represented by a rectangular polygon. The second method, raster to points, has the additional step of calculating polygon centroids. The third method, raster to contours, is somewhat unrelated. Let us demonstrate the three in the given order.\n\nsrc = rasterio.open(\"data/grain.tif\")\n\nTo polygons… …\nFIGURE 6.9: Illustration of vectorization of raster (left) into polygons (dissolve = FALSE; center) and aggregated polygons (dissolve = TRUE; right).\n\nsrc = rasterio.open(\"data/elev.tif\")\n\nTo points…\n\nsrc = rasterio.open(\"data/elev.tif\")\n\nTo contours…\n…\nAnother common type of spatial vectorization is the creation of contour lines representing lines of continuous height or temperatures (isotherms) for example. We will use a real-world digital elevation model (DEM) because the artificial raster elev produces parallel lines (task for the reader: verify this and explain why this happens). Contour lines can be created with the terra function as.contour(), which is itself a wrapper around filled.contour(), as demonstrated below (not shown):\nContours can also be added to existing plots with functions such as contour(), rasterVis::contourplot() or tmap::tm_iso(). As illustrated in Figure 6.8, isolines can be labelled.\nThe final type of vectorization involves conversion of rasters to polygons. This can be done with terra::as.polygons(), which converts each raster cell into a polygon consisting of five coordinates, all of which are stored in memory (explaining why rasters are often fast compared with vectors!).\nThis is illustrated below by converting the grain object into polygons and subsequently dissolving borders between polygons with the same attribute values (also see the dissolve argument in as.polygons())."
  },
  {
    "objectID": "06-raster-vector.html#exercises",
    "href": "06-raster-vector.html#exercises",
    "title": "6  Raster-vector interactions",
    "section": "6.7 Exercises",
    "text": "6.7 Exercises"
  },
  {
    "objectID": "07-reproj.html#introduction",
    "href": "07-reproj.html#introduction",
    "title": "7  Reprojecting geographic data",
    "section": "7.1 Introduction",
    "text": "7.1 Introduction"
  },
  {
    "objectID": "07-reproj.html#coordinate-reference-systems",
    "href": "07-reproj.html#coordinate-reference-systems",
    "title": "7  Reprojecting geographic data",
    "section": "7.2 Coordinate Reference Systems",
    "text": "7.2 Coordinate Reference Systems"
  },
  {
    "objectID": "07-reproj.html#querying-and-setting-coordinate-systems",
    "href": "07-reproj.html#querying-and-setting-coordinate-systems",
    "title": "7  Reprojecting geographic data",
    "section": "7.3 Querying and setting coordinate systems",
    "text": "7.3 Querying and setting coordinate systems"
  },
  {
    "objectID": "07-reproj.html#geometry-operations-on-projected-and-unprojected-data",
    "href": "07-reproj.html#geometry-operations-on-projected-and-unprojected-data",
    "title": "7  Reprojecting geographic data",
    "section": "7.4 Geometry operations on projected and unprojected data",
    "text": "7.4 Geometry operations on projected and unprojected data"
  },
  {
    "objectID": "07-reproj.html#when-to-reproject",
    "href": "07-reproj.html#when-to-reproject",
    "title": "7  Reprojecting geographic data",
    "section": "7.5 When to reproject?",
    "text": "7.5 When to reproject?"
  },
  {
    "objectID": "07-reproj.html#which-crs-to-use",
    "href": "07-reproj.html#which-crs-to-use",
    "title": "7  Reprojecting geographic data",
    "section": "7.6 Which CRS to use?",
    "text": "7.6 Which CRS to use?"
  },
  {
    "objectID": "07-reproj.html#reprojecting-vector-geometries",
    "href": "07-reproj.html#reprojecting-vector-geometries",
    "title": "7  Reprojecting geographic data",
    "section": "7.7 Reprojecting vector geometries",
    "text": "7.7 Reprojecting vector geometries"
  },
  {
    "objectID": "07-reproj.html#reprojecting-raster-geometries",
    "href": "07-reproj.html#reprojecting-raster-geometries",
    "title": "7  Reprojecting geographic data",
    "section": "7.8 Reprojecting raster geometries",
    "text": "7.8 Reprojecting raster geometries"
  },
  {
    "objectID": "07-reproj.html#custom-map-projections",
    "href": "07-reproj.html#custom-map-projections",
    "title": "7  Reprojecting geographic data",
    "section": "7.9 Custom map projections",
    "text": "7.9 Custom map projections"
  },
  {
    "objectID": "07-reproj.html#exercises",
    "href": "07-reproj.html#exercises",
    "title": "7  Reprojecting geographic data",
    "section": "7.10 Exercises",
    "text": "7.10 Exercises"
  },
  {
    "objectID": "08-read-write-plot.html#introduction",
    "href": "08-read-write-plot.html#introduction",
    "title": "8  Geographic data I/O",
    "section": "8.1 Introduction",
    "text": "8.1 Introduction"
  },
  {
    "objectID": "08-read-write-plot.html#retrieving-open-data",
    "href": "08-read-write-plot.html#retrieving-open-data",
    "title": "8  Geographic data I/O",
    "section": "8.2 Retrieving open data",
    "text": "8.2 Retrieving open data"
  },
  {
    "objectID": "08-read-write-plot.html#geographic-data-packages",
    "href": "08-read-write-plot.html#geographic-data-packages",
    "title": "8  Geographic data I/O",
    "section": "8.3 Geographic data packages",
    "text": "8.3 Geographic data packages"
  },
  {
    "objectID": "08-read-write-plot.html#geographic-web-services",
    "href": "08-read-write-plot.html#geographic-web-services",
    "title": "8  Geographic data I/O",
    "section": "8.4 Geographic web services",
    "text": "8.4 Geographic web services"
  },
  {
    "objectID": "08-read-write-plot.html#file-formats",
    "href": "08-read-write-plot.html#file-formats",
    "title": "8  Geographic data I/O",
    "section": "8.5 File formats",
    "text": "8.5 File formats"
  },
  {
    "objectID": "08-read-write-plot.html#data-input-i",
    "href": "08-read-write-plot.html#data-input-i",
    "title": "8  Geographic data I/O",
    "section": "8.6 Data input (I)",
    "text": "8.6 Data input (I)\n\n8.6.1 Vector data\n\n\n8.6.2 Raster data"
  },
  {
    "objectID": "08-read-write-plot.html#data-output-o",
    "href": "08-read-write-plot.html#data-output-o",
    "title": "8  Geographic data I/O",
    "section": "8.7 Data output (O)",
    "text": "8.7 Data output (O)\n\n8.7.1 Vector data\n\n\n8.7.2 Raster data"
  },
  {
    "objectID": "08-read-write-plot.html#visual-outputs",
    "href": "08-read-write-plot.html#visual-outputs",
    "title": "8  Geographic data I/O",
    "section": "8.8 Visual outputs",
    "text": "8.8 Visual outputs"
  },
  {
    "objectID": "08-read-write-plot.html#exercises",
    "href": "08-read-write-plot.html#exercises",
    "title": "8  Geographic data I/O",
    "section": "8.9 Exercises",
    "text": "8.9 Exercises"
  },
  {
    "objectID": "09-mapping.html#introduction",
    "href": "09-mapping.html#introduction",
    "title": "9  Making maps with Python",
    "section": "9.1 Introduction",
    "text": "9.1 Introduction\n\nGeopandas explore has been used in previous chapters.\nWhen to focus on visualisation? At the end of geographic data processing workflows.\n\n\n\n\n\nimport matplotlib as mpl\nimport geopandas as gpd\nnz = gpd.read_file(\"data/nz.gpkg\") \n\n/usr/local/lib/python3.8/dist-packages/geopandas/_compat.py:112: UserWarning: The Shapely GEOS version (3.10.2-CAPI-1.16.0) is incompatible with the GEOS version PyGEOS was compiled with (3.10.1-CAPI-1.16.0). Conversions between both will be slow.\n  warnings.warn("
  },
  {
    "objectID": "09-mapping.html#static-maps",
    "href": "09-mapping.html#static-maps",
    "title": "9  Making maps with Python",
    "section": "9.2 Static maps",
    "text": "9.2 Static maps\n\nFocus on matlibplot\nFirst example: NZ with fill and borders\nScary matplotlib code here…\n\n\nnz.plot(color=\"grey\");\nnz.plot(color=\"none\", edgecolor=\"blue\");\nnz.plot(color=\"grey\", edgecolor=\"blue\");\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n9.2.1 Palettes\n\n\n9.2.2 Layers\n\n\n9.2.3 Faceted maps\n\n\n9.2.4 Exporting maps as images"
  },
  {
    "objectID": "09-mapping.html#interactive-maps",
    "href": "09-mapping.html#interactive-maps",
    "title": "9  Making maps with Python",
    "section": "9.3 Interactive maps",
    "text": "9.3 Interactive maps\n\nWhen are interactive maps useful\nHoloviews: facetted plotting\nPanel: allows you to create applications/dashboards\n\n\n9.3.1 GeoPandas explore\n\n\n9.3.2 Layers\n\n\n9.3.3 Publishing interactive maps\n\n\n9.3.4 Linking geographic and non-geographic visualisations"
  },
  {
    "objectID": "09-mapping.html#exercises",
    "href": "09-mapping.html#exercises",
    "title": "9  Making maps with Python",
    "section": "9.4 Exercises",
    "text": "9.4 Exercises"
  }
]