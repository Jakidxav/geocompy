[
  {
    "objectID": "index.html#motivations",
    "href": "index.html#motivations",
    "title": "Geocomputation with Python",
    "section": "1.1 Motivations",
    "text": "1.1 Motivations\nGeocomputation with Python, is motivated by the need for an introductory yet rigorous and maintained resource on working with geographic data in Python. A unique feature of the book is that it that demonstrates code for working with both vector and raster geographic data types.  There are many resources on Python packages for geographic research and various applications but, to the best of our knowledge, no other resource brings together the following features into a single home:\n\nSmall introductory textbook focuses on doing basic operations well\nIntegration of vector and raster datasets in the same book, and within each section\nClear explanation of the code and exercises to maximize learning for newcomers\nProvision of lucid example datasets and meaningful operations to illustrate the applied nature of geographic research\n\nThe book aims to supplement other resources in the ecosystem, as highlighted by comparison with the book’s scope with existing and in-progress works:\n\nLearning Geospatial Analysis with Python and Geoprocessing with Python focuses on processing spatial data using low-level Python interfaces for GDAL, such as the gdal, gdalnumeric, and ogr packages from osgeo. This approach is more complex, less “Pythonic”, and perhaps outdated in light of development of packages such as geopandas and rasterio covered here\npythongis.org (at an early stage of development) seeks to provide a general introduction to ‘GIS in Python’, with parts focusing on Python essentials, using Python with GIS, and case studies. Compared with pythongis.org, geocompy has a relatively narrow scope (1) and a greater focus on raster-vector interoperability\ngeographicdata.science is an ambitious project with chapters dedicated to advanced topics, with Chapter 4 on Spatial Weights getting into complex topics relatively early, for example. Geocompy would be shorter, simpler and more introductory, and cover raster and vector data with equal importance (1 to 4)\n\nGeocompy is a sister project of Geocomputation with R – a book on geographic data analysis, visualization, and modeling using the R programming language."
  },
  {
    "objectID": "index.html#reproducing-this-book",
    "href": "index.html#reproducing-this-book",
    "title": "Geocomputation with Python",
    "section": "1.2 Reproducing this book",
    "text": "1.2 Reproducing this book\nAn important aspect of scientific research and ‘citizen science’ that is participatory is reproducibility of results.\nTo reproduce this book you can simply click on the link below to see the code running in your web browser (see details of how this works at mybinder.org):\n\n\n\nBinder\n\n\nTo run the code locally, recommended for using the material on real data, you need to have a reasonable computer, e.g. with 8 GB RAM. You’ll need administrative rights to install the requirements, which include:\n\nA suitable integrated development environment (IDE) such as VS Code, RStudio or Jupyter Notebook\nQuarto, if you want to reproduce the book’s open access website\nEither an Anaconda-like environment (we recommend miniconda3) or Docker to get systems dependencies\n\nSee the project’s README for details on getting set-up. After you have installed the necessary dependencies and cloned or unzipped the book’s source code, you should be able to reproduce the code in its entirety with the following command:\nquarto preview\nIf you see output like that below (with the IDE and browser arranged to see live updates after editing the source code), congratulations, it has worked!"
  },
  {
    "objectID": "02-spatial-data.html#introduction",
    "href": "02-spatial-data.html#introduction",
    "title": "2  Geographic data in Python",
    "section": "2.1 Introduction",
    "text": "2.1 Introduction\nThis chapter introduces key Python packages and data structures for working with the two major types of spatial data, namely:\n\nshapely and geopandas — for working with vector layers\nrasterio and xarray — for working with rasters\n\nAs we will see in the code chunks presented later in this chapter, shapely and geopandas are related:\n\nshapely is a “low-level” package for working with individual vector geometry objects\ngeopandas is a “high-level” package for working with geometry columns (GeoSeries objects), which internally contain shapely geometries, and vector layers (GeoDataFrame objects)\n\nWhile geopandas (including its shapely dependency), at present, comprises a ubiquitous comprehensive approach for working with vector layers in Python, this is not the case for rasters. Work with rasters in Python is much less unified. There are several alternative packages, each with its own advantages and disadvantages. We focus on the two most comprehensive and fundamental packages, namely:\n\nrasterio — a spatial-oriented package, focused on “simple” raster formats (such as GeoTIFF), representing a raster using a combination of a numpy array, and a metadata object (dict) specifying the spatial referencing of the array\nxarray — A general-purpose package for working with labeled arrays, thus advantageous for processing “complex” raster format (such as NetCDF), representing a raster using its own native classes, namely xarray.Dataset and xarray.DataArray"
  },
  {
    "objectID": "02-spatial-data.html#vector-data",
    "href": "02-spatial-data.html#vector-data",
    "title": "2  Geographic data in Python",
    "section": "2.2 Vector data",
    "text": "2.2 Vector data\n\n2.2.1 Introduction\nWhen introducing the packages for working with vector layers in Python, we are going to go from the complex class (vector layer), through the intermediate (geometry column), to the simple (geometry). As we will see, the three classes are hierarchical, meaning that the complex encompasses the simple:\n\nA vector layer (class GeoDataFrame) contains a geometry column (class GeoSeries) as one of the columns\nA geometry column (class GeoSeries) is composed of individual geometries (class shapely)\n\nThe first two classes (GeoDataFrame and GeoSeries) are defined in package geopandas. The third class is defined in package shapely, which deals with individual geometries, and comprises on of the dependencies of the geopandas package.\n\n\n2.2.2 Vector layers\nThe typical data structure for vector data is a vector layer. There are several methods to work with vector layers in Python, ranging from low-level (e.g., fiona) to high-level (geopandas). In this book, we focus on geopandas.\nBefore we begin, we need to import the geopandas package, conventionally as gpd:\n\nimport geopandas as gpd\n\nWe will also limit the maximum number of printed rows to four, to save space, using the \"display.max_rows\" option of pandas:\n\nimport pandas as pd\npd.set_option(\"display.max_rows\", 4)\n\nMost often, we import an existing vector layer from a file, such as a Shapefile (.shp) or a GeoPackage (.gpkg) file.\n\n\npath exists\n\n\n\ngdf = gpd.read_file(\"data/world.gpkg\")\n\nThe result is a GeoDataFrame:\n\ntype(gdf)\n\ngeopandas.geodataframe.GeoDataFrame\n\n\nThe GeoDataFrame class is an extension of the DataFrame class. Thus, we can treat a vector layer as a table and process it using the ordinary, i.e., non-spatial, pandas methods. For example, the following expression creates a subset with just the country name and the geometry (see below):\n\ngdf = gdf[[\"name_long\", \"geometry\"]]\ngdf\n\n\n\n\n  \n    \n      \n      name_long\n      geometry\n    \n  \n  \n    \n      0\n      Fiji\n      MULTIPOLYGON (((-180.00000 -16.55522, -179.917...\n    \n    \n      1\n      Tanzania\n      MULTIPOLYGON (((33.90371 -0.95000, 31.86617 -1...\n    \n    \n      ...\n      ...\n      ...\n    \n    \n      175\n      Trinidad and Tobago\n      MULTIPOLYGON (((-61.68000 10.76000, -61.66000 ...\n    \n    \n      176\n      South Sudan\n      MULTIPOLYGON (((30.83385 3.50917, 31.24556 3.7...\n    \n  \n\n177 rows × 2 columns\n\n\n\nThe following expression creates a subset based on a condition, including just \"Egypt\":\n\ngdf[gdf[\"name_long\"] == \"Egypt\"]\n\n\n\n\n  \n    \n      \n      name_long\n      geometry\n    \n  \n  \n    \n      163\n      Egypt\n      MULTIPOLYGON (((36.86623 22.00000, 36.69069 22...\n    \n  \n\n\n\n\nFinally, to get a sense of the spatial component of the vector layer, it can be plotted using the .plot method, as follows:\n\ngdf.plot()\n\n<AxesSubplot:>\n\n\n\n\n\nor using .hvplot to get an interactive plot:\n\n# import hvplot.pandas\n# gdf.hvplot(title='Hello world', geo=True, hover_cols=['name_long'], legend=False).opts(bgcolor='lightgray', active_tools=['wheel_zoom']) \n\nThis way, we can also add background tiles:\n\n# gdf.hvplot(tiles='OSM', alpha=0.5, geo=True, title='Hello world', hover_cols=['name_long'], legend=False).opts(active_tools=['wheel_zoom']) \n\n\n\n2.2.3 Geometry columns\nOne of the columns in a GeoDataFrame is a geometry column, of class GeoSeries. The geometry column contains the geometric part of the vector layer, e.g., the POLYGON or MULTIPOLYGON geometries of the 177 countries in gdf:\n\ngdf[\"geometry\"]\n\n0      MULTIPOLYGON (((-180.00000 -16.55522, -179.917...\n1      MULTIPOLYGON (((33.90371 -0.95000, 31.86617 -1...\n                             ...                        \n175    MULTIPOLYGON (((-61.68000 10.76000, -61.66000 ...\n176    MULTIPOLYGON (((30.83385 3.50917, 31.24556 3.7...\nName: geometry, Length: 177, dtype: geometry\n\n\nThe geometry column also contains the spatial reference information, if any (see below).\nMany of the spatial operators, such as calculating the centroid, buffer, or bounding box of each feature, in fact involve just the geometry. Therefore, for example, the following expressions give exactly the same result, a GeoSeries with country bounding boxes:\n\ngdf.bounds\n\n\n\n\n  \n    \n      \n      minx\n      miny\n      maxx\n      maxy\n    \n  \n  \n    \n      0\n      -180.000000\n      -18.287990\n      179.999990\n      -16.020882\n    \n    \n      1\n      29.339998\n      -11.720938\n      40.316590\n      -0.950000\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      175\n      -61.950000\n      10.000000\n      -60.895000\n      10.890000\n    \n    \n      176\n      23.886980\n      3.509172\n      35.298007\n      12.248008\n    \n  \n\n177 rows × 4 columns\n\n\n\n\ngdf[\"geometry\"].bounds\n\n\n\n\n  \n    \n      \n      minx\n      miny\n      maxx\n      maxy\n    \n  \n  \n    \n      0\n      -180.000000\n      -18.287990\n      179.999990\n      -16.020882\n    \n    \n      1\n      29.339998\n      -11.720938\n      40.316590\n      -0.950000\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      175\n      -61.950000\n      10.000000\n      -60.895000\n      10.890000\n    \n    \n      176\n      23.886980\n      3.509172\n      35.298007\n      12.248008\n    \n  \n\n177 rows × 4 columns\n\n\n\nAnother useful property of the geometry column is the geometry type (see below). Note that the types of geometries contained in a geometry column (and, thus, a vector layer) are not necessarily the same. Accordingly, the .type property returns a Series (of type string), rather than a single value:\n\ngdf[\"geometry\"].type\n\n0      MultiPolygon\n1      MultiPolygon\n           ...     \n175    MultiPolygon\n176    MultiPolygon\nLength: 177, dtype: object\n\n\nTo summarize the occurrence of different geometry types in a geometry column, we can use the pandas method called value_counts:\n\ngdf[\"geometry\"].type.value_counts()\n\nMultiPolygon    177\ndtype: int64\n\n\nIn this case, we see that the gdf layer contains Polygon and MultiPolygon geometries.\n\n\n2.2.4 Geometries\nEach element in the geometry column is a geometry object, of class shapely. For example, here is one specific geometry selected by implicit index (that of Canada):\n\ngdf[\"geometry\"].iloc[3]\n\n\n\n\nand here is a specific geometry selected based on the \"name_long\" attribute:\n\ngdf[gdf[\"name_long\"] == \"Egypt\"][\"geometry\"].iloc[0]\n\n\n\n\nThe shapely package is compatible with the Simple Features standard. Accordingly, seven types of geometries are supported. The following section demonstrates creating a shapely geometry of each type, from scratch or using a string in the WKT format as input. To do so , we need to import the shapely.wkt module and geometry types:\n\nimport shapely.wkt as wkt\nfrom shapely.geometry import Point\n\nCreating a point object is as simple as:\n\npoint = Point(5,2)\npoint\n\n\n\n\nThen, we use the wkt.loads (stands for “load a WKT string”) to transform a WKT string to a shapely geometry object. Here is an example of a POINT geometry:\n\npoint = wkt.loads(\"POINT (5 2)\")\npoint\n\n\n\n\nHere is an example of a MULTIPOINT geometry:\n\nfrom shapely.geometry import MultiPoint\nmultipoint = MultiPoint([(5,2), (1,3), (3,4), (3,2)])\nmultipoint\n\n\n\n\n\nmultipoint = wkt.loads(\"MULTIPOINT ((5 2), (1 3), (3 4), (3 2))\")\nmultipoint\n\n\n\n\nHere is an example of a LINESTRING geometry:\n\nfrom shapely.geometry import LineString\nlinestring = LineString([(1,5), (4,4), (4,1), (2,2), (3,2)])\nlinestring\n\n\n\n\n\nlinestring = wkt.loads(\"LINESTRING (1 5, 4 4, 4 1, 2 2, 3 2)\")\nlinestring\n\n\n\n\nHere is an example of a MULTILINESTRING geometry:\n\nfrom shapely.geometry import MultiLineString\nlinestring = MultiLineString([[(1,5), (4,4), (4,1), (2,2), (3,2)], [(1,2), (2,4)]])\nlinestring\n\n\n\n\n\nmultilinestring = wkt.loads(\"MULTILINESTRING ((1 5, 4 4, 4 1, 2 2, 3 2), (1 2, 2 4))\")\nmultilinestring\n\n\n\n\nHere is an example of a POLYGON geometry:\n\nfrom shapely.geometry import Polygon\nlinestring = Polygon([(1,5), (2,2), (4,1), (4,4), (1,5)], [[(2,4), (3,4), (3,3), (2,3), (2,4)]])\nlinestring\n\n\n\n\n\npolygon = wkt.loads(\"POLYGON ((1 5, 2 2, 4 1, 4 4, 1 5), (2 4, 3 4, 3 3, 2 3, 2 4))\")\npolygon\n\n\n\n\nHere is an example of a MULTIPOLYGON geometry:\n\nfrom shapely.geometry import MultiPolygon\nmultipolygon = MultiPolygon([Polygon([(1,5), (2,2), (4,1), (4,4), (1,5)]), \n                             Polygon([(0,2), (1,2), (1,3), (0,3), (0,2)])])\nmultipolygon\n\n\n\n\n\nmultipolygon = wkt.loads(\"MULTIPOLYGON (((1 5, 2 2, 4 1, 4 4, 1 5)), ((0 2, 1 2, 1 3, 0 3, 0 2)))\")\nmultipolygon\n\n\n\n\nAnd, finally, here is an example of a GEOMETRYCOLLECTION geometry:\n\nfrom shapely.geometry import GeometryCollection\nmultipoint = GeometryCollection([MultiPoint([(5,2), (1,3), (3,4), (3,2)]),\n                                 MultiLineString([[(1,5), (4,4), (4,1), (2,2), (3,2)], [(1,2), (2,4)]])])\nmultipoint\n\n\n\n\n\ngeometrycollection = wkt.loads(\"GEOMETRYCOLLECTION (MULTIPOINT (5 2, 1 3, 3 4, 3 2), LINESTRING (1 5, 4 4, 4 1, 2 2, 3 2))\")\ngeometrycollection\n\n\n\n\nshapely geometries act as atomic units of vector data, as spatial operations on a geometry return a single new geometry. For example, the following expression calculates the difference between the buffered multipolygon (using distance of 0.1) and itself:\n\nmultipolygon.buffer(0.2).difference(multipolygon)\n\n\n\n\nInternally, many spatial operations on a geometry column (or a vector layer) are basically iterations where the operator is applied on all geometries, one by one, to return a new geometry column (or layer) with the combined results.\nAs demonstrated above, a shapely geometry object is automatically evaluated to a small image of the geometry (when using an interface capable of displaying it, such as a Jupyter Notebook). To print the WKT string instead, we can use the print function:\n\nprint(linestring)\n\nPOLYGON ((1 5, 2 2, 4 1, 4 4, 1 5), (2 4, 3 4, 3 3, 2 3, 2 4))\n\n\nWe can determine the geometry type using the .geom_type property, which is a string:\n\nlinestring.geom_type\n\n'Polygon'\n\n\nFinally, it is important to note that raw coordinates of shapely geometries are accessible through a combination of the .coords, .geoms, .exterior, and .interiors, properties (depending on the geometry type). These access methods are useful for when we need to develop our own spatial operators for specific tasks. For example, the following expression returns the coordinates of the polygon geometry exterior (note that the returned object is iterable, thus enclosed in a list to return all coordinates at once):\n\nlist(polygon.exterior.coords)\n\n[(1.0, 5.0), (2.0, 2.0), (4.0, 1.0), (4.0, 4.0), (1.0, 5.0)]"
  },
  {
    "objectID": "02-spatial-data.html#raster-data",
    "href": "02-spatial-data.html#raster-data",
    "title": "2  Geographic data in Python",
    "section": "2.3 Raster data",
    "text": "2.3 Raster data\n\n2.3.1 Introduction\nAs mentioned above, working with rasters in Python is less organized around one comprehensive package (such as the case for vector layers and geopandas). Instead, there are several packages providing alternative (subsets of methods) of working with raster data.\nThe two most notable approaches for working with rasters in Python are provided by the rasterio and xarray packages. As we will see shortly, they differ in their scope and underlying data models. Specifically, rasterio represents rasters as numpy arrays associated with a separate object holding the spatial metadata. The xarray package, however, represents rasters with the native DataArray object, which is an extension of numpy array designed to hold axis labels and attributes, in the same object, together with the array of raster values.\nBoth packages are not comprehensive in the same way as geopandas is. For example, when working with rasterio, on the one hand, more packages may be needed to accomplish (commonly used) tasks such as zonal statistics (package rasterstats) or calculating topographic indices (package richdem). On the other hand, xarray was extended to accommodate spatial operators missing from the core package itself, with the rioxarray and xarray-spatial packages.\nIn the following two sections, we introduce the two well-established packages, rasterio and xarray, which form the basis for most raster functionality in Python. Using any of the add-on packages, or the extensions, should be straightforward, once the reader is familiar with the basics.\n\n\n2.3.2 Using rasterio\nTo work with the rasterio package, we first need to import it. We also import numpy, since (as we will see shortly), the underlying raster data are stored in numpy arrays. To effectively work with those we therefore expose all numpy functions. Finally, we import the show function from the rasterio.plot sub-module for quick visualization of rasters.\n\nimport numpy as np\nimport rasterio\nfrom rasterio.plot import show\nimport subprocess\n\nRasters are typically imported from existing files. When working with rasterio, “importing” a raster is actually a two-step process:\n\nFirst, we open a raster file “connection”, using rasterio.open\nSecond, we read raster values from the connection using the .read method\n\nThis kind of separation is analogous to basic Python functions for reading from files, such as open and .readline to read from a text file. The rationale is that we do not always want to read all information from the file into memory, which is particularly important as rasters size can be larger than RAM size. Accordingly, the second step (.read) is selective. For example, we may want to read just one raster band rather than reading all band.\nIn the first step, to create a file connection, we pass a file path to the rasterio.open function. For this example, we use a single-band raster representing elevation in Zion National Park:\n\nsrc = rasterio.open(\"data/srtm.tif\")\n\nTo get a first impression of the raster values, we can plot it using the show function:\n\nshow(src);\n\n\n\n\nThe “connection” object contains the raster metadata, that is, all of the information other than the raster values. Let us examine it:\n\nsrc.meta\n\n{'driver': 'GTiff',\n 'dtype': 'uint16',\n 'nodata': 65535.0,\n 'width': 465,\n 'height': 457,\n 'count': 1,\n 'crs': CRS.from_epsg(4326),\n 'transform': Affine(0.0008333333332777796, 0.0, -113.23958321278403,\n        0.0, -0.0008333333332777843, 37.512916763165805)}\n\n\nImportantly, we can see:\n\nThe raster data type (dtype)\nRaster dimensions (width, height, and count, i.e., number of layers)\nRaster Coordinate Reference System (crs)\nThe raster affine transformation matrix (transform)\n\nThe last item (i.e., transform) deserves a few more words. To position a raster in geographical space, in addition to the CRS we must specify the raster origin (\\(x_{min}\\), \\(y_{max}\\)) and resolution (\\(delta_{x}\\), \\(delta_{y}\\)). In the transform matrix notation, these data items are stored as follows:\nAffine(delta_x, 0.0, x_min,\n       0.0, delta_y, y_max)\nNote that, by convention, raster y-axis origin is set to the maximum value (\\(y_{max}\\)) rather than the minimum, and, accordingly, the y-axis resolution (\\(delta_{y}\\)) is negative.\nThe .read method of a raster file connection object is used to read the last but not least piece of information: the raster values. Importantly, we can read:\n\nA particular layer, passing a numeric index (as in .read(1))\nA subset of layers, passing a list of indices (as in .read([1,2]))\nAll layers (as in .read())\n\nNote that the layer indices start from 1 contrary to the Python convention of the first index being 0.\nThe resulting object is a numpy array, with either two or three dimensions:\n\nThree dimensions, when reading all layers or more than one layer (e.g., .read() or .read([1,2])). In such case, the dimensions pattern is (layers, rows, columns)\nTwo dimensions, when reading one specific layer (e.g., .read(1))\n\nFor example, let us read the first (and only) layer from the srtm.tif raster, using the file connection object src:\n\ns = src.read(1)\ns\n\narray([[1728, 1718, 1715, ..., 2654, 2674, 2685],\n       [1737, 1727, 1717, ..., 2649, 2677, 2693],\n       [1739, 1734, 1727, ..., 2644, 2672, 2695],\n       ...,\n       [1326, 1328, 1329, ..., 1777, 1778, 1775],\n       [1320, 1323, 1326, ..., 1771, 1770, 1772],\n       [1319, 1319, 1322, ..., 1768, 1770, 1772]], dtype=uint16)\n\n\n\n\n2.3.3 Using xarray\n…\n\nimport xarray as xr\n\nReading source:\n\nx = xr.open_dataset(\"data/absolute_v5.nc\")\nx\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n<xarray.Dataset>\nDimensions:  (time: 12, lon: 72, lat: 36)\nCoordinates:\n  * time     (time) float64 0.5 1.5 2.5 3.5 4.5 5.5 6.5 7.5 8.5 9.5 10.5 11.5\n  * lon      (lon) float32 -177.5 -172.5 -167.5 -162.5 ... 167.5 172.5 177.5\n  * lat      (lat) float32 -87.5 -82.5 -77.5 -72.5 -67.5 ... 72.5 77.5 82.5 87.5\nData variables:\n    tem      (time, lat, lon) float32 -26.6 -27.4 -25.2 ... -29.4 -29.3 -29.4\nAttributes:\n    CDI:                       Climate Data Interface version ?? (http://mpim...\n    Conventions:               CF-1.6\n    history:                   Wed May 20 16:30:15 2020: ncap2 -O -s time=tim...\n    CDO:                       Climate Data Operators version 1.9.3 (http://m...\n    NCO:                       4.7.2\n    nco_openmp_thread_number:  1\n    reference:                 Osborn TJ, Jones PD, Lister DH, Morice CP, Sim...\n    licence:                   Open Government Licence http://www.nationalarc...xarray.DatasetDimensions:time: 12lon: 72lat: 36Coordinates: (3)time(time)float640.5 1.5 2.5 3.5 ... 9.5 10.5 11.5axis :Tcalendar :proleptic_gregorianstandard_name :timeunits :monthsarray([ 0.5,  1.5,  2.5,  3.5,  4.5,  5.5,  6.5,  7.5,  8.5,  9.5, 10.5, 11.5])lon(lon)float32-177.5 -172.5 ... 172.5 177.5standard_name :longitudelong_name :longitudeunits :degrees_eastaxis :Xarray([-177.5, -172.5, -167.5, -162.5, -157.5, -152.5, -147.5, -142.5, -137.5,\n       -132.5, -127.5, -122.5, -117.5, -112.5, -107.5, -102.5,  -97.5,  -92.5,\n        -87.5,  -82.5,  -77.5,  -72.5,  -67.5,  -62.5,  -57.5,  -52.5,  -47.5,\n        -42.5,  -37.5,  -32.5,  -27.5,  -22.5,  -17.5,  -12.5,   -7.5,   -2.5,\n          2.5,    7.5,   12.5,   17.5,   22.5,   27.5,   32.5,   37.5,   42.5,\n         47.5,   52.5,   57.5,   62.5,   67.5,   72.5,   77.5,   82.5,   87.5,\n         92.5,   97.5,  102.5,  107.5,  112.5,  117.5,  122.5,  127.5,  132.5,\n        137.5,  142.5,  147.5,  152.5,  157.5,  162.5,  167.5,  172.5,  177.5],\n      dtype=float32)lat(lat)float32-87.5 -82.5 -77.5 ... 82.5 87.5standard_name :latitudelong_name :latitudeunits :degrees_northaxis :Yarray([-87.5, -82.5, -77.5, -72.5, -67.5, -62.5, -57.5, -52.5, -47.5, -42.5,\n       -37.5, -32.5, -27.5, -22.5, -17.5, -12.5,  -7.5,  -2.5,   2.5,   7.5,\n        12.5,  17.5,  22.5,  27.5,  32.5,  37.5,  42.5,  47.5,  52.5,  57.5,\n        62.5,  67.5,  72.5,  77.5,  82.5,  87.5], dtype=float32)Data variables: (1)tem(time, lat, lon)float32...long_name :CRU_Global_1961-1990_Mean_Monthly_Surface_Temperature_Climatologyunits :celsiusarray([[[-26.599998, -27.4     , ..., -27.4     , -27.5     ],\n        [ -4.7     ,  -4.4     , ...,  -6.4     ,  -5.6     ],\n        ...,\n        [-29.3     , -29.199999, ..., -29.5     , -29.3     ],\n        [-30.099998, -30.099998, ..., -30.699999, -30.5     ]],\n\n       [[-38.3     , -39.2     , ..., -39.399998, -39.399998],\n        [-11.099999, -10.599999, ..., -13.4     , -12.3     ],\n        ...,\n        [-29.4     , -29.4     , ..., -29.599998, -29.5     ],\n        [-30.5     , -30.599998, ..., -31.      , -30.8     ]],\n\n       ...,\n\n       [[-36.899998, -37.7     , ..., -37.899998, -37.899998],\n        [-12.      , -11.7     , ..., -14.099999, -13.099999],\n        ...,\n        [-22.3     , -22.199999, ..., -22.5     , -22.5     ],\n        [-24.4     , -24.5     , ..., -24.6     , -24.699999]],\n\n       [[-26.699999, -27.4     , ..., -27.5     , -27.599998],\n        [ -5.2     ,  -4.9     , ...,  -6.9     ,  -6.1     ],\n        ...,\n        [-27.      , -27.099998, ..., -27.099998, -27.099998],\n        [-29.3     , -29.5     , ..., -29.3     , -29.4     ]]], dtype=float32)Attributes: (8)CDI :Climate Data Interface version ?? (http://mpimet.mpg.de/cdi)Conventions :CF-1.6history :Wed May 20 16:30:15 2020: ncap2 -O -s time=time-1 better_absolute_2.nc better_absolute_3.nc\nWed May 20 16:30:15 2020: cdo invertlat better_absolute_1.nc better_absolute_2.ncCDO :Climate Data Operators version 1.9.3 (http://mpimet.mpg.de/cdo)NCO :4.7.2nco_openmp_thread_number :1reference :Osborn TJ, Jones PD, Lister DH, Morice CP, Simpson IR, Winn J, Hogan E and Harris IC (submitted) Land surface air temperature variations across the globe updated to 2019: the CRUTEM5 dataset. Submitted to Journal of Geophysical Research.licence :Open Government Licence http://www.nationalarchives.gov.uk/doc/open-government-licence/version/3/\n\n\n\nx[\"tem\"]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n<xarray.DataArray 'tem' (time: 12, lat: 36, lon: 72)>\narray([[[-26.599998, -27.4     , ..., -27.4     , -27.5     ],\n        [ -4.7     ,  -4.4     , ...,  -6.4     ,  -5.6     ],\n        ...,\n        [-29.3     , -29.199999, ..., -29.5     , -29.3     ],\n        [-30.099998, -30.099998, ..., -30.699999, -30.5     ]],\n\n       [[-38.3     , -39.2     , ..., -39.399998, -39.399998],\n        [-11.099999, -10.599999, ..., -13.4     , -12.3     ],\n        ...,\n        [-29.4     , -29.4     , ..., -29.599998, -29.5     ],\n        [-30.5     , -30.599998, ..., -31.      , -30.8     ]],\n\n       ...,\n\n       [[-36.899998, -37.7     , ..., -37.899998, -37.899998],\n        [-12.      , -11.7     , ..., -14.099999, -13.099999],\n        ...,\n        [-22.3     , -22.199999, ..., -22.5     , -22.5     ],\n        [-24.4     , -24.5     , ..., -24.6     , -24.699999]],\n\n       [[-26.699999, -27.4     , ..., -27.5     , -27.599998],\n        [ -5.2     ,  -4.9     , ...,  -6.9     ,  -6.1     ],\n        ...,\n        [-27.      , -27.099998, ..., -27.099998, -27.099998],\n        [-29.3     , -29.5     , ..., -29.3     , -29.4     ]]], dtype=float32)\nCoordinates:\n  * time     (time) float64 0.5 1.5 2.5 3.5 4.5 5.5 6.5 7.5 8.5 9.5 10.5 11.5\n  * lon      (lon) float32 -177.5 -172.5 -167.5 -162.5 ... 167.5 172.5 177.5\n  * lat      (lat) float32 -87.5 -82.5 -77.5 -72.5 -67.5 ... 72.5 77.5 82.5 87.5\nAttributes:\n    long_name:  CRU_Global_1961-1990_Mean_Monthly_Surface_Temperature_Climato...\n    units:      celsiusxarray.DataArray'tem'time: 12lat: 36lon: 72-26.6 -27.4 -25.2 -21.2 -19.8 -17.8 ... -29.5 -29.4 -29.4 -29.3 -29.4array([[[-26.599998, -27.4     , ..., -27.4     , -27.5     ],\n        [ -4.7     ,  -4.4     , ...,  -6.4     ,  -5.6     ],\n        ...,\n        [-29.3     , -29.199999, ..., -29.5     , -29.3     ],\n        [-30.099998, -30.099998, ..., -30.699999, -30.5     ]],\n\n       [[-38.3     , -39.2     , ..., -39.399998, -39.399998],\n        [-11.099999, -10.599999, ..., -13.4     , -12.3     ],\n        ...,\n        [-29.4     , -29.4     , ..., -29.599998, -29.5     ],\n        [-30.5     , -30.599998, ..., -31.      , -30.8     ]],\n\n       ...,\n\n       [[-36.899998, -37.7     , ..., -37.899998, -37.899998],\n        [-12.      , -11.7     , ..., -14.099999, -13.099999],\n        ...,\n        [-22.3     , -22.199999, ..., -22.5     , -22.5     ],\n        [-24.4     , -24.5     , ..., -24.6     , -24.699999]],\n\n       [[-26.699999, -27.4     , ..., -27.5     , -27.599998],\n        [ -5.2     ,  -4.9     , ...,  -6.9     ,  -6.1     ],\n        ...,\n        [-27.      , -27.099998, ..., -27.099998, -27.099998],\n        [-29.3     , -29.5     , ..., -29.3     , -29.4     ]]], dtype=float32)Coordinates: (3)time(time)float640.5 1.5 2.5 3.5 ... 9.5 10.5 11.5axis :Tcalendar :proleptic_gregorianstandard_name :timeunits :monthsarray([ 0.5,  1.5,  2.5,  3.5,  4.5,  5.5,  6.5,  7.5,  8.5,  9.5, 10.5, 11.5])lon(lon)float32-177.5 -172.5 ... 172.5 177.5standard_name :longitudelong_name :longitudeunits :degrees_eastaxis :Xarray([-177.5, -172.5, -167.5, -162.5, -157.5, -152.5, -147.5, -142.5, -137.5,\n       -132.5, -127.5, -122.5, -117.5, -112.5, -107.5, -102.5,  -97.5,  -92.5,\n        -87.5,  -82.5,  -77.5,  -72.5,  -67.5,  -62.5,  -57.5,  -52.5,  -47.5,\n        -42.5,  -37.5,  -32.5,  -27.5,  -22.5,  -17.5,  -12.5,   -7.5,   -2.5,\n          2.5,    7.5,   12.5,   17.5,   22.5,   27.5,   32.5,   37.5,   42.5,\n         47.5,   52.5,   57.5,   62.5,   67.5,   72.5,   77.5,   82.5,   87.5,\n         92.5,   97.5,  102.5,  107.5,  112.5,  117.5,  122.5,  127.5,  132.5,\n        137.5,  142.5,  147.5,  152.5,  157.5,  162.5,  167.5,  172.5,  177.5],\n      dtype=float32)lat(lat)float32-87.5 -82.5 -77.5 ... 82.5 87.5standard_name :latitudelong_name :latitudeunits :degrees_northaxis :Yarray([-87.5, -82.5, -77.5, -72.5, -67.5, -62.5, -57.5, -52.5, -47.5, -42.5,\n       -37.5, -32.5, -27.5, -22.5, -17.5, -12.5,  -7.5,  -2.5,   2.5,   7.5,\n        12.5,  17.5,  22.5,  27.5,  32.5,  37.5,  42.5,  47.5,  52.5,  57.5,\n        62.5,  67.5,  72.5,  77.5,  82.5,  87.5], dtype=float32)Attributes: (2)long_name :CRU_Global_1961-1990_Mean_Monthly_Surface_Temperature_Climatologyunits :celsius\n\n\nPlot:\n\nx[\"tem\"].plot(col=\"time\", col_wrap=4)\n\n<xarray.plot.facetgrid.FacetGrid at 0x7f1d05313a90>"
  },
  {
    "objectID": "02-spatial-data.html#coordinate-reference-systems",
    "href": "02-spatial-data.html#coordinate-reference-systems",
    "title": "2  Geographic data in Python",
    "section": "2.4 Coordinate Reference Systems",
    "text": "2.4 Coordinate Reference Systems\n\ngdf.crs\n\n<Geographic 2D CRS: EPSG:4326>\nName: WGS 84\nAxis Info [ellipsoidal]:\n- Lat[north]: Geodetic latitude (degree)\n- Lon[east]: Geodetic longitude (degree)\nArea of Use:\n- name: World.\n- bounds: (-180.0, -90.0, 180.0, 90.0)\nDatum: World Geodetic System 1984 ensemble\n- Ellipsoid: WGS 84\n- Prime Meridian: Greenwich\n\n\n\nsrc.crs\n\nCRS.from_epsg(4326)"
  },
  {
    "objectID": "02-spatial-data.html#exercises",
    "href": "02-spatial-data.html#exercises",
    "title": "2  Geographic data in Python",
    "section": "2.5 Exercises",
    "text": "2.5 Exercises\n…"
  },
  {
    "objectID": "03-attribute-operations.html#prerequisites",
    "href": "03-attribute-operations.html#prerequisites",
    "title": "3  Attribute data operations",
    "section": "3.1 Prerequisites",
    "text": "3.1 Prerequisites\nPackages…\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport geopandas as gpd\nimport rasterio\n\nSample data…\n\n\nAttempting to get the data\n\n\n\nworld = gpd.read_file(\"data/world.gpkg\")\nsrc_elev = rasterio.open(\"data/elev.tif\")\nsrc_multi_rast = rasterio.open(\"data/landsat.tif\")"
  },
  {
    "objectID": "03-attribute-operations.html#introduction",
    "href": "03-attribute-operations.html#introduction",
    "title": "3  Attribute data operations",
    "section": "3.2 Introduction",
    "text": "3.2 Introduction\n…"
  },
  {
    "objectID": "03-attribute-operations.html#vector-attribute-manipulation",
    "href": "03-attribute-operations.html#vector-attribute-manipulation",
    "title": "3  Attribute data operations",
    "section": "3.3 Vector attribute manipulation",
    "text": "3.3 Vector attribute manipulation\nAs mentioned previously (…), vector layers (GeoDataFrame, from package geopandas) are basically extended tables (DataFrame from package pandas), the difference being that a vector layer has a geometry column. Since GeoDataFrame extends DataFrame, all ordinary table-related operations from package pandas are supported for vector laters as well, as shown below.\n\n3.3.1 Vector attribute subsetting\npandas supports several subsetting interfaces, though the most recommended ones are:\n\n.loc, which uses pandas indices, and\n.iloc, which uses (implicit) numpy-style numeric indices.\n\nIn both cases the method is followed by square brackets, and two indices, separated by a comma. Each index can comprise:\n\nA specific value, as in 1\nA slice, as in 0:3\nA list, as in [0,2,4]\n:—indicating “all” indices\n\nThe once exception which we are going to with subsetting by indices is when selecting columns, directly using a list, as in df[[\"a\",\"b\"]], instead of df.loc[:, [\"a\",\"b\"]], to select columns \"a\" and \"b\" from df.\nHere are few examples of subsetting the GeoDataFrame of world countries.\nSubsetting rows by position:\n\nworld.iloc[0:3, :]\n\n\n\n\n  \n    \n      \n      iso_a2\n      name_long\n      continent\n      ...\n      lifeExp\n      gdpPercap\n      geometry\n    \n  \n  \n    \n      0\n      FJ\n      Fiji\n      Oceania\n      ...\n      69.960\n      8222.253784\n      MULTIPOLYGON (((-180.00000 -16....\n    \n    \n      1\n      TZ\n      Tanzania\n      Africa\n      ...\n      64.163\n      2402.099404\n      MULTIPOLYGON (((33.90371 -0.950...\n    \n    \n      2\n      EH\n      Western Sahara\n      Africa\n      ...\n      NaN\n      NaN\n      MULTIPOLYGON (((-8.66559 27.656...\n    \n  \n\n3 rows × 11 columns\n\n\n\nSubsetting columns by position:\n\nworld.iloc[:, 0:3]\n\n\n\n\n  \n    \n      \n      iso_a2\n      name_long\n      continent\n    \n  \n  \n    \n      0\n      FJ\n      Fiji\n      Oceania\n    \n    \n      1\n      TZ\n      Tanzania\n      Africa\n    \n    \n      2\n      EH\n      Western Sahara\n      Africa\n    \n    \n      ...\n      ...\n      ...\n      ...\n    \n    \n      174\n      XK\n      Kosovo\n      Europe\n    \n    \n      175\n      TT\n      Trinidad and Tobago\n      North America\n    \n    \n      176\n      SS\n      South Sudan\n      Africa\n    \n  \n\n177 rows × 3 columns\n\n\n\nSubsetting rows and columns by position:\n\nworld.iloc[0:3, 0:3]\n\n\n\n\n  \n    \n      \n      iso_a2\n      name_long\n      continent\n    \n  \n  \n    \n      0\n      FJ\n      Fiji\n      Oceania\n    \n    \n      1\n      TZ\n      Tanzania\n      Africa\n    \n    \n      2\n      EH\n      Western Sahara\n      Africa\n    \n  \n\n\n\n\nSubsetting columns by name:\n\nworld[[\"name_long\", \"geometry\"]]\n\n\n\n\n  \n    \n      \n      name_long\n      geometry\n    \n  \n  \n    \n      0\n      Fiji\n      MULTIPOLYGON (((-180.00000 -16....\n    \n    \n      1\n      Tanzania\n      MULTIPOLYGON (((33.90371 -0.950...\n    \n    \n      2\n      Western Sahara\n      MULTIPOLYGON (((-8.66559 27.656...\n    \n    \n      ...\n      ...\n      ...\n    \n    \n      174\n      Kosovo\n      MULTIPOLYGON (((20.59025 41.855...\n    \n    \n      175\n      Trinidad and Tobago\n      MULTIPOLYGON (((-61.68000 10.76...\n    \n    \n      176\n      South Sudan\n      MULTIPOLYGON (((30.83385 3.5091...\n    \n  \n\n177 rows × 2 columns\n\n\n\n“Slice” of columns between given ones:\n\nworld.loc[:, \"name_long\":\"pop\"]\n\n\n\n\n  \n    \n      \n      name_long\n      continent\n      region_un\n      ...\n      type\n      area_km2\n      pop\n    \n  \n  \n    \n      0\n      Fiji\n      Oceania\n      Oceania\n      ...\n      Sovereign country\n      19289.970733\n      885806.0\n    \n    \n      1\n      Tanzania\n      Africa\n      Africa\n      ...\n      Sovereign country\n      932745.792357\n      52234869.0\n    \n    \n      2\n      Western Sahara\n      Africa\n      Africa\n      ...\n      Indeterminate\n      96270.601041\n      NaN\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      174\n      Kosovo\n      Europe\n      Europe\n      ...\n      Sovereign country\n      11230.261672\n      1821800.0\n    \n    \n      175\n      Trinidad and Tobago\n      North America\n      Americas\n      ...\n      Sovereign country\n      7737.809855\n      1354493.0\n    \n    \n      176\n      South Sudan\n      Africa\n      Africa\n      ...\n      Sovereign country\n      624909.099086\n      11530971.0\n    \n  \n\n177 rows × 7 columns\n\n\n\nSubsetting by a boolean series:\n\nx = np.array([1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0], dtype=bool)\nworld.iloc[:, x]\n\n\n\n\n  \n    \n      \n      iso_a2\n      name_long\n      pop\n      lifeExp\n    \n  \n  \n    \n      0\n      FJ\n      Fiji\n      885806.0\n      69.960000\n    \n    \n      1\n      TZ\n      Tanzania\n      52234869.0\n      64.163000\n    \n    \n      2\n      EH\n      Western Sahara\n      NaN\n      NaN\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      174\n      XK\n      Kosovo\n      1821800.0\n      71.097561\n    \n    \n      175\n      TT\n      Trinidad and Tobago\n      1354493.0\n      70.426000\n    \n    \n      176\n      SS\n      South Sudan\n      11530971.0\n      55.817000\n    \n  \n\n177 rows × 4 columns\n\n\n\nWe can remove specific columns using the .drop method and axis=1 (i.e., columns):\n\nworld.drop([\"name_long\", \"continent\"], axis=1)\n\n\n\n\n  \n    \n      \n      iso_a2\n      region_un\n      subregion\n      ...\n      lifeExp\n      gdpPercap\n      geometry\n    \n  \n  \n    \n      0\n      FJ\n      Oceania\n      Melanesia\n      ...\n      69.960000\n      8222.253784\n      MULTIPOLYGON (((-180.00000 -16....\n    \n    \n      1\n      TZ\n      Africa\n      Eastern Africa\n      ...\n      64.163000\n      2402.099404\n      MULTIPOLYGON (((33.90371 -0.950...\n    \n    \n      2\n      EH\n      Africa\n      Northern Africa\n      ...\n      NaN\n      NaN\n      MULTIPOLYGON (((-8.66559 27.656...\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      174\n      XK\n      Europe\n      Southern Europe\n      ...\n      71.097561\n      8698.291559\n      MULTIPOLYGON (((20.59025 41.855...\n    \n    \n      175\n      TT\n      Americas\n      Caribbean\n      ...\n      70.426000\n      31181.821196\n      MULTIPOLYGON (((-61.68000 10.76...\n    \n    \n      176\n      SS\n      Africa\n      Eastern Africa\n      ...\n      55.817000\n      1935.879400\n      MULTIPOLYGON (((30.83385 3.5091...\n    \n  \n\n177 rows × 9 columns\n\n\n\nWe can rename (some of) the selected columns using the .rename method:\n\nworld[[\"name_long\", \"pop\"]].rename(columns={\"pop\": \"population\"})\n\n\n\n\n  \n    \n      \n      name_long\n      population\n    \n  \n  \n    \n      0\n      Fiji\n      885806.0\n    \n    \n      1\n      Tanzania\n      52234869.0\n    \n    \n      2\n      Western Sahara\n      NaN\n    \n    \n      ...\n      ...\n      ...\n    \n    \n      174\n      Kosovo\n      1821800.0\n    \n    \n      175\n      Trinidad and Tobago\n      1354493.0\n    \n    \n      176\n      South Sudan\n      11530971.0\n    \n  \n\n177 rows × 2 columns\n\n\n\nThe standard numpy comparison operators can be used in boolean subsetting, as illustrated in Table …\nTABLE …: Comparison operators that return Booleans (TRUE/FALSE).\n\n\n\nSymbol\nName\n\n\n\n\n==\nEqual to\n\n\n!=\nNot equal to\n\n\n>, <\nGreater/Less than\n\n\n>=, <=\nGreater/Less than or equal\n\n\n&, |, ~\nLogical operators: And, Or, Not\n\n\n\nA demonstration of the utility of using logical vectors for subsetting is shown in the code chunk below. This creates a new object, small_countries, containing nations whose surface area is smaller than 10,000 km2:\n\ni_small = world[\"area_km2\"] < 10000  ## a logical 'Series'\nsmall_countries = world[i_small]\nsmall_countries\n\n\n\n\n  \n    \n      \n      iso_a2\n      name_long\n      continent\n      ...\n      lifeExp\n      gdpPercap\n      geometry\n    \n  \n  \n    \n      45\n      PR\n      Puerto Rico\n      North America\n      ...\n      79.390122\n      35066.046376\n      MULTIPOLYGON (((-66.28243 18.51...\n    \n    \n      79\n      PS\n      Palestine\n      Asia\n      ...\n      73.126000\n      4319.528283\n      MULTIPOLYGON (((35.39756 31.489...\n    \n    \n      89\n      VU\n      Vanuatu\n      Oceania\n      ...\n      71.709000\n      2892.341604\n      MULTIPOLYGON (((166.79316 -15.6...\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      160\n      None\n      Northern Cyprus\n      Asia\n      ...\n      NaN\n      NaN\n      MULTIPOLYGON (((32.73178 35.140...\n    \n    \n      161\n      CY\n      Cyprus\n      Asia\n      ...\n      80.173000\n      29786.365653\n      MULTIPOLYGON (((32.73178 35.140...\n    \n    \n      175\n      TT\n      Trinidad and Tobago\n      North America\n      ...\n      70.426000\n      31181.821196\n      MULTIPOLYGON (((-61.68000 10.76...\n    \n  \n\n7 rows × 11 columns\n\n\n\nThe intermediary i_small (short for index representing small countries) is a boolean Series that can be used to subset the seven smallest countries in the world by surface area. A more concise command, which omits the intermediary object, generates the same result:\n\nsmall_countries = world[world[\"area_km2\"] < 10000]\n\nThe various methods shown above can be chained for any combination with several subsetting steps. For example:\n\nworld[world[\"continent\"] == \"Asia\"]  \\\n    .loc[:, [\"name_long\", \"continent\"]]  \\\n    .iloc[0:5, :]\n\n\n\n\n  \n    \n      \n      name_long\n      continent\n    \n  \n  \n    \n      5\n      Kazakhstan\n      Asia\n    \n    \n      6\n      Uzbekistan\n      Asia\n    \n    \n      8\n      Indonesia\n      Asia\n    \n    \n      24\n      Timor-Leste\n      Asia\n    \n    \n      76\n      Israel\n      Asia\n    \n  \n\n\n\n\n\n\n3.3.2 Vector attribute aggregation\nAggregation involves summarizing data with one or more grouping variables, typically from columns in the table to be aggregated (geographic aggregation is covered in the next chapter). An example of attribute aggregation is calculating the number of people per continent based on country-level data (one row per country). The world dataset contains the necessary ingredients: the columns pop and continent, the population and the grouping variable, respectively. The aim is to find the sum() of country populations for each continent, resulting in a smaller data frame (aggregation is a form of data reduction and can be a useful early step when working with large datasets). This can be done with a combination of .groupby and .sum:\n\nworld_agg1 = world[['continent', 'pop']].groupby('continent').sum()\nworld_agg1\n\n\n\n\n  \n    \n      \n      pop\n    \n    \n      continent\n      \n    \n  \n  \n    \n      Africa\n      1.154947e+09\n    \n    \n      Antarctica\n      0.000000e+00\n    \n    \n      Asia\n      4.311408e+09\n    \n    \n      ...\n      ...\n    \n    \n      Oceania\n      3.775783e+07\n    \n    \n      Seven seas (open ocean)\n      0.000000e+00\n    \n    \n      South America\n      4.120608e+08\n    \n  \n\n8 rows × 1 columns\n\n\n\nThe result is a (non-spatial) table with eight rows, one per continent, and two columns reporting the name and population of each continent.\nAlternatively, to include the geometry in the aggregation result, we can use the .dissolve method. That way, in addition to the summed population we also get the associated geometry per continent, i.e., the union of all countries. Note that we use the by parameter to choose which column(s) are used for grouping, and the aggfunc parameter to choose the summary function for non-geometry columns:\n\nworld_agg2 = world[['continent', 'pop', 'geometry']] \\\n    .dissolve(by='continent', aggfunc='sum')\nworld_agg2\n\n\n\n\n  \n    \n      \n      geometry\n      pop\n    \n    \n      continent\n      \n      \n    \n  \n  \n    \n      Africa\n      MULTIPOLYGON (((-11.43878 6.785...\n      1.154947e+09\n    \n    \n      Antarctica\n      MULTIPOLYGON (((-61.13898 -79.9...\n      0.000000e+00\n    \n    \n      Asia\n      MULTIPOLYGON (((48.67923 14.003...\n      4.311408e+09\n    \n    \n      ...\n      ...\n      ...\n    \n    \n      Oceania\n      MULTIPOLYGON (((147.91405 -43.2...\n      3.775783e+07\n    \n    \n      Seven seas (open ocean)\n      POLYGON ((68.93500 -48.62500, 6...\n      0.000000e+00\n    \n    \n      South America\n      MULTIPOLYGON (((-68.63999 -55.5...\n      4.120608e+08\n    \n  \n\n8 rows × 2 columns\n\n\n\nHere is a plot of the result:\n\nworld_agg2.plot(column='pop');\n\n\n\n\nThe resulting world_agg2 object is a vector layer containing 8 features representing the continents of the world (and the open ocean).\nOther options for the aggfunc parameter in .dissolve include:\n\n'first'\n'last'\n'min'\n'max'\n'sum'\n'mean'\n'median'\n\nAdditionally, we can pass a custom functiom.\nFor example, here is how we can calculate the summed population, summed area, and count of countries, per continent. We do this in two steps, then join the results:\n\nworld_agg3a = world[['continent', 'area_km2', 'geometry']] \\\n    .dissolve(by='continent', aggfunc='sum')\nworld_agg3b = world[['continent', 'name_long', 'geometry']] \\\n    .dissolve(by='continent', aggfunc=lambda x: x.nunique()) \\\n    .rename(columns={\"name_long\": \"n\"})\nworld_agg = pd.merge(world_agg3a, world_agg3b, on='continent')\n\n…\n\n\n3.3.3 Vector attribute joining\nJoin by attribute…\n\ncoffee_data = pd.read_csv(\"data/coffee_data.csv\")\ncoffee_data\n\n\n\n\n  \n    \n      \n      name_long\n      coffee_production_2016\n      coffee_production_2017\n    \n  \n  \n    \n      0\n      Angola\n      NaN\n      NaN\n    \n    \n      1\n      Bolivia\n      3.0\n      4.0\n    \n    \n      2\n      Brazil\n      3277.0\n      2786.0\n    \n    \n      ...\n      ...\n      ...\n      ...\n    \n    \n      44\n      Zambia\n      3.0\n      NaN\n    \n    \n      45\n      Zimbabwe\n      1.0\n      1.0\n    \n    \n      46\n      Others\n      23.0\n      26.0\n    \n  \n\n47 rows × 3 columns\n\n\n\nJoin by \"name_long\" column…\n\nworld_coffee = pd.merge(world, coffee_data, on=\"name_long\", how=\"left\")\nworld_coffee\n\n\n\n\n  \n    \n      \n      iso_a2\n      name_long\n      continent\n      ...\n      geometry\n      coffee_production_2016\n      coffee_production_2017\n    \n  \n  \n    \n      0\n      FJ\n      Fiji\n      Oceania\n      ...\n      MULTIPOLYGON (((-180.00000 -16....\n      NaN\n      NaN\n    \n    \n      1\n      TZ\n      Tanzania\n      Africa\n      ...\n      MULTIPOLYGON (((33.90371 -0.950...\n      81.0\n      66.0\n    \n    \n      2\n      EH\n      Western Sahara\n      Africa\n      ...\n      MULTIPOLYGON (((-8.66559 27.656...\n      NaN\n      NaN\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      174\n      XK\n      Kosovo\n      Europe\n      ...\n      MULTIPOLYGON (((20.59025 41.855...\n      NaN\n      NaN\n    \n    \n      175\n      TT\n      Trinidad and Tobago\n      North America\n      ...\n      MULTIPOLYGON (((-61.68000 10.76...\n      NaN\n      NaN\n    \n    \n      176\n      SS\n      South Sudan\n      Africa\n      ...\n      MULTIPOLYGON (((30.83385 3.5091...\n      NaN\n      NaN\n    \n  \n\n177 rows × 13 columns\n\n\n\nPlot…\n\nbase = world.plot(color=\"white\", edgecolor=\"lightgrey\")\nworld_coffee.plot(ax=base, column=\"coffee_production_2017\");\n\n\n\n\n\n\n3.3.4 Creating attributes and removing spatial information\nCalculate new column…\n\nworld2 = world.copy()\nworld2[\"pop_dens\"] = world2[\"pop\"] / world2[\"area_km2\"]\n\nUnite columns…\n\nworld2[\"con_reg\"] = world[\"continent\"] + \":\" + world2[\"region_un\"]\nworld2 = world2.drop([\"continent\", \"region_un\"], axis=1)\n\nSplit column…\n\nworld2[[\"continent\", \"region_un\"]] = world2[\"con_reg\"] \\\n    .str.split(\":\", expand=True)\n\nRename…\n\nworld2.rename(columns={\"name_long\": \"name\"})\n\n\n\n\n  \n    \n      \n      iso_a2\n      name\n      subregion\n      ...\n      con_reg\n      continent\n      region_un\n    \n  \n  \n    \n      0\n      FJ\n      Fiji\n      Melanesia\n      ...\n      Oceania:Oceania\n      Oceania\n      Oceania\n    \n    \n      1\n      TZ\n      Tanzania\n      Eastern Africa\n      ...\n      Africa:Africa\n      Africa\n      Africa\n    \n    \n      2\n      EH\n      Western Sahara\n      Northern Africa\n      ...\n      Africa:Africa\n      Africa\n      Africa\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      174\n      XK\n      Kosovo\n      Southern Europe\n      ...\n      Europe:Europe\n      Europe\n      Europe\n    \n    \n      175\n      TT\n      Trinidad and Tobago\n      Caribbean\n      ...\n      North America:Americas\n      North America\n      Americas\n    \n    \n      176\n      SS\n      South Sudan\n      Eastern Africa\n      ...\n      Africa:Africa\n      Africa\n      Africa\n    \n  \n\n177 rows × 13 columns\n\n\n\nRenaming all columns…\n\nnew_names =[\"i\", \"n\", \"c\", \"r\", \"s\", \"t\", \"a\", \"p\", \"l\", \"gP\", \"geom\"]\nworld.columns = new_names\n\nDropping geometry…\n\npd.DataFrame(world.drop(columns=\"geom\"))\n\n\n\n\n  \n    \n      \n      i\n      n\n      c\n      ...\n      p\n      l\n      gP\n    \n  \n  \n    \n      0\n      FJ\n      Fiji\n      Oceania\n      ...\n      885806.0\n      69.960000\n      8222.253784\n    \n    \n      1\n      TZ\n      Tanzania\n      Africa\n      ...\n      52234869.0\n      64.163000\n      2402.099404\n    \n    \n      2\n      EH\n      Western Sahara\n      Africa\n      ...\n      NaN\n      NaN\n      NaN\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      174\n      XK\n      Kosovo\n      Europe\n      ...\n      1821800.0\n      71.097561\n      8698.291559\n    \n    \n      175\n      TT\n      Trinidad and Tobago\n      North America\n      ...\n      1354493.0\n      70.426000\n      31181.821196\n    \n    \n      176\n      SS\n      South Sudan\n      Africa\n      ...\n      11530971.0\n      55.817000\n      1935.879400\n    \n  \n\n177 rows × 10 columns"
  },
  {
    "objectID": "03-attribute-operations.html#manipulating-raster-objects",
    "href": "03-attribute-operations.html#manipulating-raster-objects",
    "title": "3  Attribute data operations",
    "section": "3.4 Manipulating raster objects",
    "text": "3.4 Manipulating raster objects\n\n3.4.1 Raster subsetting\nWhen using rasterio, raster values are accessible through a numpy array, which can be imported with the .read method:\n\nelev = src_elev.read(1)\nelev\n\narray([[ 1.,  2.,  3.,  4.,  5.,  6.],\n       [ 7.,  8.,  9., 10., 11., 12.],\n       [13., 14., 15., 16., 17., 18.],\n       [19., 20., 21., 22., 23., 24.],\n       [25., 26., 27., 28., 29., 30.],\n       [31., 32., 33., 34., 35., 36.]], dtype=float32)\n\n\nThen, we can access any subset of cell values using numpy methods. For example:\n\nelev[0, 0]  ## Value at row 1, column 1\n\n1.0\n\n\nCell values can be modified by overwriting existing values in conjunction with a subsetting operation. The following expression, for example, sets the upper left cell of elev to 0:\n\nelev[0, 0] = 0\nelev\n\narray([[ 0.,  2.,  3.,  4.,  5.,  6.],\n       [ 7.,  8.,  9., 10., 11., 12.],\n       [13., 14., 15., 16., 17., 18.],\n       [19., 20., 21., 22., 23., 24.],\n       [25., 26., 27., 28., 29., 30.],\n       [31., 32., 33., 34., 35., 36.]], dtype=float32)\n\n\nMultiple cells can also be modified in this way:\n\nelev[0, 0:2] = 0\nelev\n\narray([[ 0.,  0.,  3.,  4.,  5.,  6.],\n       [ 7.,  8.,  9., 10., 11., 12.],\n       [13., 14., 15., 16., 17., 18.],\n       [19., 20., 21., 22., 23., 24.],\n       [25., 26., 27., 28., 29., 30.],\n       [31., 32., 33., 34., 35., 36.]], dtype=float32)\n\n\n\n\n3.4.2 Summarizing raster objects\nGlobal summaries of raster values can be calculated by applying numpy summary functions—such as np.mean—on the array with raster values. For example:\n\nnp.mean(elev)\n\n18.416666\n\n\nNote that “No Data”-safe functions–such as np.nanmean—should be used in case the raster contains “No Data” values which need to be ignored:\n\nelev[0, 2] = np.nan\nelev\n\narray([[ 0.,  0., nan,  4.,  5.,  6.],\n       [ 7.,  8.,  9., 10., 11., 12.],\n       [13., 14., 15., 16., 17., 18.],\n       [19., 20., 21., 22., 23., 24.],\n       [25., 26., 27., 28., 29., 30.],\n       [31., 32., 33., 34., 35., 36.]], dtype=float32)\n\n\n\nnp.mean(elev)\n\nnan\n\n\n\nnp.nanmean(elev)\n\n18.857143\n\n\nRaster value statistics can be visualized in a variety of ways. One approach is to “flatten” the raster values into a one-dimensional array, then use a graphical function such as plt.hist or plt.boxplot (from matplotlib.pyplot). For example:\n\nx = elev.flatten()\nplt.hist(x);"
  },
  {
    "objectID": "03-attribute-operations.html#exercises",
    "href": "03-attribute-operations.html#exercises",
    "title": "3  Attribute data operations",
    "section": "3.5 Exercises",
    "text": "3.5 Exercises"
  },
  {
    "objectID": "04-spatial-operations.html#prerequisites",
    "href": "04-spatial-operations.html#prerequisites",
    "title": "4  Spatial data operations",
    "section": "4.1 Prerequisites",
    "text": "4.1 Prerequisites\nPackages…\n\nimport numpy as np\nimport geopandas as gpd\nimport rasterio\nfrom rasterio.plot import show\n\nLet us load the sample data for this chapter:\n\nnz = gpd.read_file(\"data/nz.gpkg\")\nnz_height = gpd.read_file(\"data/nz_height.gpkg\")\nsrc_elev = rasterio.open(\"data/elev.tif\")\nsrc_multi_rast = rasterio.open(\"data/landsat.tif\")"
  },
  {
    "objectID": "04-spatial-operations.html#introduction",
    "href": "04-spatial-operations.html#introduction",
    "title": "4  Spatial data operations",
    "section": "4.2 Introduction",
    "text": "4.2 Introduction"
  },
  {
    "objectID": "04-spatial-operations.html#spatial-vec",
    "href": "04-spatial-operations.html#spatial-vec",
    "title": "4  Spatial data operations",
    "section": "4.3 Spatial operations on vector data",
    "text": "4.3 Spatial operations on vector data\n\n4.3.1 Spatial subsetting\nPlot…\n\nbase = nz.plot(color=\"white\", edgecolor=\"lightgrey\")\nnz_height.plot(ax=base, color=\"None\", edgecolor=\"red\");\n\n\n\n\nSpatial subsetting…\n\ncanterbury = nz[nz[\"Name\"] == \"Canterbury\"]\nsel = nz_height.intersects(canterbury[\"geometry\"].iloc[0])\ncanterbury_height = nz_height[sel]\n\nPlot…\n\nbase = nz.plot(color=\"white\", edgecolor=\"lightgrey\")\ncanterbury_height.plot(ax=base, color=\"None\", edgecolor=\"red\");\n\n\n\n\nSpatial subsetting 2…\n\nsel = nz_height.disjoint(canterbury[\"geometry\"].iloc[0])\nnon_canterbury_height = nz_height[sel]\n\nPlot…\n\nbase = nz.plot(color=\"white\", edgecolor=\"lightgrey\")\nnon_canterbury_height.plot(ax=base, color=\"None\", edgecolor=\"red\");\n\n\n\n\n…\n\n\n4.3.2 Topological relations\n…\n\n\n4.3.3 DE-9IM strings\n…\n\n\n4.3.4 Spatial joining\n…\n\n\n4.3.5 Non-overlapping joins\n…\n\n\n4.3.6 Spatial aggregation\n…\n\n\n4.3.7 Joining incongruent layers\n…\n\n\n4.3.8 Distance relations\n…"
  },
  {
    "objectID": "04-spatial-operations.html#spatial-ras",
    "href": "04-spatial-operations.html#spatial-ras",
    "title": "4  Spatial data operations",
    "section": "4.4 Spatial operations on raster data",
    "text": "4.4 Spatial operations on raster data\n\n4.4.1 Spatial subsetting\n…\n\n\n4.4.2 Map algebra\n…\n\n\n4.4.3 Local operations\nFirst, we need to read raster values:\n\nelev = src_elev.read()\nelev\n\narray([[[ 1.,  2.,  3.,  4.,  5.,  6.],\n        [ 7.,  8.,  9., 10., 11., 12.],\n        [13., 14., 15., 16., 17., 18.],\n        [19., 20., 21., 22., 23., 24.],\n        [25., 26., 27., 28., 29., 30.],\n        [31., 32., 33., 34., 35., 36.]]], dtype=float32)\n\n\nNow, any element-wise array operation can be applied. For example:\n\nelev + elev\n\narray([[[ 2.,  4.,  6.,  8., 10., 12.],\n        [14., 16., 18., 20., 22., 24.],\n        [26., 28., 30., 32., 34., 36.],\n        [38., 40., 42., 44., 46., 48.],\n        [50., 52., 54., 56., 58., 60.],\n        [62., 64., 66., 68., 70., 72.]]], dtype=float32)\n\n\nHere are few more examples:\n\nfig, axes = plt.subplots(ncols=4, figsize=(9,5))\nshow(elev + elev, ax=axes[0], cmap=\"Oranges\")\nshow(elev ** 2, ax=axes[1], cmap=\"Oranges\")\nshow(np.log(elev), ax=axes[2], cmap=\"Oranges\")\nshow(elev > 5, ax=axes[3], cmap=\"Oranges\")\naxes[0].set_title(\"elev+elev\")\naxes[1].set_title(\"elev ** 2\")\naxes[2].set_title(\"np.log(elev)\")\naxes[3].set_title(\"elev > 5\");\n\n\n\n\nAnother good example of local operations is the classification of intervals of numeric values into groups such as grouping a digital elevation model into low (class 1), middle (class 2) and high elevations (class 3). Here, we assign the raster values in the ranges 0–12, 12–24 and 24–36 are reclassified to take values 1, 2 and 3, respectively…\n\nrecl = elev.copy()\nrecl[(elev > 0)  & (elev <= 12)] = 1\nrecl[(elev > 12) & (elev <= 24)] = 2\nrecl[(elev > 24) & (elev <= 36)] = 3\n\nPlot…\n\nfig, axes = plt.subplots(ncols=2, figsize=(9,5))\nshow(elev, ax=axes[0], cmap=\"Oranges\")\nshow(recl, ax=axes[1], cmap=\"Oranges\")\naxes[0].set_title(\"Original\")\naxes[1].set_title(\"Reclassified\");\n\n\n\n\nThe calculation of the normalized difference vegetation index (NDVI) is a well-known local (pixel-by-pixel) raster operation. It returns a raster with values between -1 and 1; positive values indicate the presence of living plants (mostly > 0.2). NDVI is calculated from red and near-infrared (NIR) bands of remotely sensed imagery, typically from satellite systems such as Landsat or Sentinel. Vegetation absorbs light heavily in the visible light spectrum, and especially in the red channel, while reflecting NIR light, explaining the NVDI formula:\n\\(NDVI=\\frac{NIR+Red} {NIR-Red}\\)\nLet’s calculate NDVI for the multispectral satellite file of the Zion National Park.\n\nmulti_rast = src_multi_rast.read()\nnir = multi_rast[3,:,:]\nred = multi_rast[2,:,:]\nndvi = (nir-red)/(nir+red)\n\nConvert values >1 to “No Data”:\n\nndvi[ndvi>1] = np.nan\n\nWhen plotting an RGB image using the show function, the function assumes that:\n\nValues are in the range [0,1] for floats, or [0,255] for integers (otherwise clipped)\nThe order of bands is RGB\n\nTo “prepare” the multi-band raster for show, we therefore reverse the order of bands (which is originally BGR+NIR), and divided by the maximum to set the maximum value at 1:\n\nmulti_rast_rgb = multi_rast[(2,1,0), :, :]/multi_rast.max()\n\nPlot…\n\nfig, axes = plt.subplots(ncols=2, figsize=(9,5))\nshow(multi_rast_rgb, ax=axes[0], cmap=\"RdYlGn\")\nshow(ndvi, ax=axes[1], cmap=\"Greens\")\naxes[0].set_title(\"RGB image\")\naxes[1].set_title(\"NDVI\");\n\n\n\n\n\n\n4.4.4 Focal operations\n…\n\n\n4.4.5 Zonal operations\n…\n\n\n4.4.6 Global operations and distances\n…\n\n\n4.4.7 Map algebra counterparts in vector processing\n…\n\n\n4.4.8 Merging rasters\n…"
  },
  {
    "objectID": "04-spatial-operations.html#exercises",
    "href": "04-spatial-operations.html#exercises",
    "title": "4  Spatial data operations",
    "section": "4.5 Exercises",
    "text": "4.5 Exercises"
  },
  {
    "objectID": "05-geometry-operations.html#prerequisites",
    "href": "05-geometry-operations.html#prerequisites",
    "title": "5  Geometry operations",
    "section": "5.1 Prerequisites",
    "text": "5.1 Prerequisites\nPackages…\n\nimport shapely.geometry\nimport geopandas as gpd\n\nSample data…\n\nseine = gpd.read_file(\"data/seine.gpkg\")\nus_states = gpd.read_file(\"data/us_states.gpkg\")\nnz = gpd.read_file(\"data/nz.gpkg\")"
  },
  {
    "objectID": "05-geometry-operations.html#introduction",
    "href": "05-geometry-operations.html#introduction",
    "title": "5  Geometry operations",
    "section": "5.2 Introduction",
    "text": "5.2 Introduction"
  },
  {
    "objectID": "05-geometry-operations.html#geo-vec",
    "href": "05-geometry-operations.html#geo-vec",
    "title": "5  Geometry operations",
    "section": "5.3 Geometric operations on vector data",
    "text": "5.3 Geometric operations on vector data\n\n5.3.1 Simplification\nSimplify…\n\nseine_simp = seine.simplify(2000)  # 2000 m\n\nPlot:\n\nfig, axes = plt.subplots(ncols=2)\nseine.plot(ax=axes[0])\nseine_simp.plot(ax=axes[1])\naxes[0].set_title(\"Original\")\naxes[1].set_title(\"Simplified (d=2000 m)\");\n\n\n\n\nCompare number of nodes:\n\nimport sys\nsys.getsizeof(seine)       ## Original (bytes)\n\n354\n\n\n\nsys.getsizeof(seine_simp)  ## Simplified (bytes)\n\n168\n\n\nUS states example…. Transform…\n\nus_states2163 = us_states.to_crs(2163)\n\nSimplify…\n\nus_states_simp1 = us_states2163.simplify(100000)\n\nPlot…\n\nus_states_simp1.plot();\n\n\n\n\n\nimport topojson as tp\ntopo = tp.Topology(us_states2163, prequantize=False)\nus_states_simp2 = topo.toposimplify(100000).to_gdf()\n\n/usr/local/lib/python3.8/dist-packages/topojson/core/extract.py:332: ShapelyDeprecationWarning: Iteration over multi-part geometries is deprecated and will be removed in Shapely 2.0. Use the `geoms` property to access the constituent parts of a multi-part geometry.\n  for ring in geom:\n<__array_function__ internals>:180: ShapelyDeprecationWarning: The array interface is deprecated and will no longer work in Shapely 2.0. Convert the '.coords' to a numpy array instead.\n/usr/local/lib/python3.8/dist-packages/topojson/core/topology.py:482: ShapelyDeprecationWarning: The array interface is deprecated and will no longer work in Shapely 2.0. Convert the '.coords' to a numpy array instead.\n  result.output[\"arcs\"] = simplify(\n\n\n\nfig, axes = plt.subplots(ncols=3, figsize=(9,5))\nus_states2163.plot(ax=axes[0])\nus_states_simp1.plot(ax=axes[1])\nus_states_simp2.plot(ax=axes[2])\naxes[0].set_title(\"Original\")\naxes[1].set_title(\"Simplified (w/ geopandas)\")\naxes[2].set_title(\"Simplified (w/ topojson)\");\n\n\n\n\n\n\n5.3.2 Centroids\nCentroid operations identify the center of geographic objects. Like statistical measures of central tendency (including mean and median definitions of ‘average’), there are many ways to define the geographic center of an object. All of them create single point representations of more complex vector objects.\nThe most commonly used centroid operation is the geographic centroid. This type of centroid operation (often referred to as ‘the centroid’) represents the center of mass in a spatial object (think of balancing a plate on your finger). Geographic centroids have many uses, for example to create a simple point representation of complex geometries, or to estimate distances between polygons. Centroids of the geometries in a GeoSeries or a GeoDataFrame are accessible through the .centroid property, as demonstrated in the code below, which generates the geographic centroids of regions in New Zealand and tributaries to the River Seine, illustrated with black points in Figure ….\n\nnz_centroid = nz.centroid\nseine_centroid = seine.centroid\n\nSometimes the geographic centroid falls outside the boundaries of their parent objects (think of a doughnut). In such cases point on surface operations can be used to guarantee the point will be in the parent object (e.g., for labeling irregular multipolygon objects such as island states), as illustrated by the red points in Figure …. Notice that these red points always lie on their parent objects. They were created with the representative_point method, as follows:\n\nnz_pos = nz.representative_point()\nseine_pos = seine.representative_point()\n\nThe centroids and points in surface are illustrated in Figure 5.1:\n\nfig, axes = plt.subplots(ncols=2)\nbase = nz.plot(ax=axes[0], color=\"white\", edgecolor=\"lightgrey\")\nnz_centroid.plot(ax=axes[0], color=\"None\", edgecolor=\"black\")\nnz_pos.plot(ax=axes[0], color=\"None\", edgecolor=\"red\");\nbase = seine.plot(ax=axes[1], color=\"grey\")\nseine_centroid.plot(ax=axes[1], color=\"None\", edgecolor=\"black\")\nseine_pos.plot(ax=axes[1], color=\"None\", edgecolor=\"red\");\n\n\n\n\nFigure 5.1: Centroids (black) and points on surface red of New Zealand and Seine datasets.\n\n\n\n\n\n\n5.3.3 Buffers\nBuffers…\n\nseine_buff_5km = seine.buffer(5000)\nseine_buff_50km = seine.buffer(50000)\n\nPlot…\n\nfig, axes = plt.subplots(ncols=2)\nseine_buff_5km.plot(ax=axes[0], color=\"None\", edgecolor=[\"red\", \"green\", \"blue\"])\nseine_buff_50km.plot(ax=axes[1], color=\"None\", edgecolor=[\"red\", \"green\", \"blue\"])\naxes[0].set_title(\"5 km buffer\")\naxes[1].set_title(\"50 km buffer\");\n\n\n\n\n\n\n5.3.4 Affine transformations\nAffine transformations of GeoSeries can be done using the .affine_transform method, which is a wrapper around the shapely.affinity.affine_transform function. According to the documentation, a 2D affine transformation requires a six-parameter list [a,b,d,e,xoff,yoff] which represents the following equations for transforming the coordinates:\n\\[\nx' = a x + b y + x_\\mathrm{off}\n\\]\n\\[\ny' = d x + e y + y_\\mathrm{off}\n\\]\nThere are also simplified GeoSeries methods for specific scenarios:\n\nGeoSeries.rotate(angle, origin='center', use_radians=False)\nGeoSeries.scale(xfact=1.0, yfact=1.0, zfact=1.0, origin='center')\nGeoSeries.skew(angle, origin='center', use_radians=False)\nGeoSeries.translate(xoff=0.0, yoff=0.0, zoff=0.0)\n\nFor example, shifting only requires the \\(x_{off}\\) and \\(y_{off}\\), using .translate. The code below shifts the y-coordinates by 100,000 meters to the north, but leaves the x-coordinates untouched:\n\nnz_shift = nz[\"geometry\"].translate(0, 100000)\n\nScale…\n\nnz_scale = nz[\"geometry\"].scale(0.5, 0.5, origin=\"centroid\")\n\nRotate…\n\nnz_rotate = nz[\"geometry\"].rotate(-30, origin=\"centroid\")\n\nPlot…\n\nfig, axes = plt.subplots(ncols=3, figsize=(9,5))\nnz.plot(ax=axes[0], color=\"lightgrey\", edgecolor=\"darkgrey\")\nnz_shift.plot(ax=axes[0], color=\"red\", edgecolor=\"darkgrey\")\nnz.plot(ax=axes[1], color=\"lightgrey\", edgecolor=\"darkgrey\")\nnz_scale.plot(ax=axes[1], color=\"red\", edgecolor=\"darkgrey\")\nnz.plot(ax=axes[2], color=\"lightgrey\", edgecolor=\"darkgrey\")\nnz_rotate.plot(ax=axes[2], color=\"red\", edgecolor=\"darkgrey\")\naxes[0].set_title(\"Shift\")\naxes[1].set_title(\"Scale\")\naxes[2].set_title(\"Rotate\");\n\n\n\n\n\n\n5.3.5 Clipping\n…\n\n\n5.3.6 Subsetting and clipping\n…\n\n\n5.3.7 Geometry unions\n…\n\n\n5.3.8 Type transformations\nTransformation of geometries, from one type to another, also known as “geometry casting”, is often required to facilitate spatial analysis. The shapely package can be used for geometry casting. The exact expression(s) depend on the specific transformation we are interested in. In general, you need to figure out the required input of the respective construstor function according to the “destination” geometry (e.g., shapely.geometry.LineString, etc.), then reshape the input of the “source” geometry into the right form to be passed to that function.\nLet’s create a \"MultiPoint\" to illustrate how geometry casting works on shapely geometry objects:\n\nmultipoint = shapely.geometry.MultiPoint([(1,1), (3,3), (5,1)])\nmultipoint\n\n\n\n\nA \"LineString\" can be created using shapely.geometry.LineString from a list of points. Consequently, a \"MultiPoint\" can be converted to a \"LineString\" by extracting the individual points into a list, then passing them to shapely.geometry.LineString:\n\nlinestring = shapely.geometry.LineString(list(multipoint.geoms))\nlinestring\n\n\n\n\nA \"Polygon\" can also be created using funtion shapely.geometry.Polygon, which acceps accepts a sequence of points. In principle, the last coordinate must be equal to the first, in order to form a closed shape. However, shapely.geometry.Polygon is able to complete the last coordinate automatically. Therefore:\n\npolygon = shapely.geometry.Polygon(list(multipoint.geoms))\npolygon\n\n\n\n\nThe source \"MultiPoint\" geometry, and the derived \"LineString\" and \"Polygon\" geometries are shown in Figure 5.2. Note that we convert the shapely geometries to GeoSeries for easier multi-panel plotting:\n\nfig, axes = plt.subplots(ncols=3, figsize=(9,5))\ngpd.GeoSeries(multipoint).plot(ax=axes[0])\ngpd.GeoSeries(linestring).plot(ax=axes[1])\ngpd.GeoSeries(polygon).plot(ax=axes[2])\naxes[0].set_title(\"MultiPoint\")\naxes[1].set_title(\"LineString\")\naxes[2].set_title(\"Polygon\");\n\n\n\n\nFigure 5.2: Examples of linestring and polygon casted from a multipoint geometry.\n\n\n\n\nConversion from multipoint to linestring is a common operation that creates a line object from ordered point observations, such as GPS measurements or geotagged media. This allows spatial operations such as the length of the path traveled. Conversion from multipoint or linestring to polygon is often used to calculate an area, for example from the set of GPS measurements taken around a lake or from the corners of a building lot.\nOur \"LineString\" geometry can be converted bact to a \"MultiPoint\" geometry by passing its coordinates directly to shapely.geometry.MultiPoint:\n\n# 'LineString' -> 'MultiPoint'\nshapely.geometry.MultiPoint(linestring.coords)\n\n\n\n\nThe \"Polygon\" (exterior) coordinates can be passed to shapely.geometry.MultiPoint as well:\n\n# 'Polygon' -> 'MultiPoint'\nshapely.geometry.MultiPoint(polygon.exterior.coords)\n\n\n\n\n…"
  },
  {
    "objectID": "05-geometry-operations.html#geo-ras",
    "href": "05-geometry-operations.html#geo-ras",
    "title": "5  Geometry operations",
    "section": "5.4 Geometric operations on raster data",
    "text": "5.4 Geometric operations on raster data\n\n5.4.1 Geometric intersections\n…\n\n\n5.4.2 Extent and origin\n…\n\n\n5.4.3 Aggregation and disaggregation\n…\n\n\n5.4.4 Resampling\n…"
  },
  {
    "objectID": "05-geometry-operations.html#exercises",
    "href": "05-geometry-operations.html#exercises",
    "title": "5  Geometry operations",
    "section": "5.5 Exercises",
    "text": "5.5 Exercises"
  },
  {
    "objectID": "06-raster-vector.html#prerequisites",
    "href": "06-raster-vector.html#prerequisites",
    "title": "6  Raster-vector interactions",
    "section": "6.1 Prerequisites",
    "text": "6.1 Prerequisites\nLet’s import the required packages:\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport geopandas as gpd\nimport rasterio\nimport rasterio.mask\nfrom rasterio.plot import show\n\nand load the sample data:\n\nsrc_srtm = rasterio.open(\"data/srtm.tif\")\nzion = gpd.read_file(\"data/zion.gpkg\")\nzion_points = gpd.read_file(\"data/zion_points.gpkg\")"
  },
  {
    "objectID": "06-raster-vector.html#introduction",
    "href": "06-raster-vector.html#introduction",
    "title": "6  Raster-vector interactions",
    "section": "6.2 Introduction",
    "text": "6.2 Introduction"
  },
  {
    "objectID": "06-raster-vector.html#raster-cropping",
    "href": "06-raster-vector.html#raster-cropping",
    "title": "6  Raster-vector interactions",
    "section": "6.3 Raster cropping",
    "text": "6.3 Raster cropping\nMany geographic data projects involve integrating data from many different sources, such as remote sensing images (rasters) and administrative boundaries (vectors). Often the extent of input raster datasets is larger than the area of interest. In this case raster cropping and masking are useful for unifying the spatial extent of input data. Both operations reduce object memory use and associated computational resources for subsequent analysis steps, and may be a necessary preprocessing step before creating attractive maps involving raster data.\nWe will use two objects to illustrate raster cropping:\n\nThe srtm.tif raster representing elevation (meters above sea level) in south-western Utah\nThe zion.gpkg vector layer representing the Zion National Park\n\nBoth target and cropping objects must have the same projection. The following reprojects the vector layer zion into the CRS of the raster src_srtm:\n\nzion = zion.to_crs(src_srtm.crs)\n\nTo mask the image, i.e., convert all pixels which do not intersect with the zion polygon to “No Data”, we use the rasterio.mask.mask function as follows:\n\nout_image_mask, out_transform_mask = rasterio.mask.mask(\n    src_srtm, \n    zion[\"geometry\"], \n    crop=False, \n    nodata=9999\n)\n\nNote that we need to specify a “No Data” value in agreement with the raster data type. Since srtm.tif is of type uint16, we choose 9999 (a positive integer that is guaranteed not to occur in the raster).\nThe result is the out_image array with the masked values:\n\nout_image_mask\n\narray([[[9999, 9999, 9999, ..., 9999, 9999, 9999],\n        [9999, 9999, 9999, ..., 9999, 9999, 9999],\n        [9999, 9999, 9999, ..., 9999, 9999, 9999],\n        ...,\n        [9999, 9999, 9999, ..., 9999, 9999, 9999],\n        [9999, 9999, 9999, ..., 9999, 9999, 9999],\n        [9999, 9999, 9999, ..., 9999, 9999, 9999]]], dtype=uint16)\n\n\nand the new out_transform:\n\nout_transform_mask\n\nAffine(0.0008333333332777796, 0.0, -113.23958321278403,\n       0.0, -0.0008333333332777843, 37.512916763165805)\n\n\nNote that masking (without cropping!) does not modify the raster spatial configuration. Therefore, the new transform is identical to the original:\n\nsrc_srtm.transform\n\nAffine(0.0008333333332777796, 0.0, -113.23958321278403,\n       0.0, -0.0008333333332777843, 37.512916763165805)\n\n\nUnfortunately, the out_image and out_transform object do not contain any information indicating that 9999 represents “No Data”. To associate the information with the raster, we must write it to file along with the corresponding metadata. For example, to write the cropped raster to file, we need to modify the “No Data” setting in the metadata:\n\nout_meta = src_srtm.meta\nout_meta.update(nodata=9999)\nout_meta\n\n{'driver': 'GTiff',\n 'dtype': 'uint16',\n 'nodata': 9999,\n 'width': 465,\n 'height': 457,\n 'count': 1,\n 'crs': CRS.from_epsg(4326),\n 'transform': Affine(0.0008333333332777796, 0.0, -113.23958321278403,\n        0.0, -0.0008333333332777843, 37.512916763165805)}\n\n\nThen we can write the cropped raster to file:\n\nnew_dataset = rasterio.open(\"output/srtm_masked.tif\", \"w\", **out_meta)\nnew_dataset.write(out_image_mask)\nnew_dataset.close()\n\nNow we can re-import the raster:\n\nsrc_srtm_mask = rasterio.open(\"output/srtm_masked.tif\")\n\nThe .meta property contains the nodata entry. Now, any relevant operation (such as plotting) will take “No Data” into account:\n\nsrc_srtm_mask.meta\n\n{'driver': 'GTiff',\n 'dtype': 'uint16',\n 'nodata': 9999.0,\n 'width': 465,\n 'height': 457,\n 'count': 1,\n 'crs': CRS.from_epsg(4326),\n 'transform': Affine(0.0008333333332777796, 0.0, -113.23958321278403,\n        0.0, -0.0008333333332777843, 37.512916763165805)}\n\n\nCropping means reducing the raster extent to the extent of the vector layer:\n\nTo crop and mask, we can use the same in rasterio.mask.mask expression shown above for masking, just setting crop=True instead of crop=False.\nTo just crop, without masking, we can derive the extent polygon and then crop using it.\n\nFor example, here is how we can obtain the extent polygon of zion, as a shapely geometry object:\n\nbb = zion.unary_union.envelope\nbb\n\n\n\n\nThe extent can now be used for masking. Here, we are also using the all_touched=True option so that pixels partially overlapping with the extent are included:\n\nout_image_crop, out_transform_crop = rasterio.mask.mask(\n    src_srtm, \n    [bb], \n    crop=True, \n    all_touched=True, \n    nodata=9999\n)\n\nFigure … shows the original raster, and the cropped and masked results.\n\nfig, axes = plt.subplots(ncols=3, figsize=(9,5))\nshow(src_srtm, ax=axes[0])\nzion.plot(ax=axes[0], color=\"none\", edgecolor=\"black\")\nshow(src_srtm_mask, ax=axes[1])\nzion.plot(ax=axes[1], color=\"none\", edgecolor=\"black\")\nshow(out_image_crop, transform=out_transform_crop, ax=axes[2])\nzion.plot(ax=axes[2], color=\"none\", edgecolor=\"black\")\naxes[0].set_title(\"Original\")\naxes[1].set_title(\"Mask\")\naxes[2].set_title(\"Crop\");"
  },
  {
    "objectID": "06-raster-vector.html#raster-extraction",
    "href": "06-raster-vector.html#raster-extraction",
    "title": "6  Raster-vector interactions",
    "section": "6.4 Raster extraction",
    "text": "6.4 Raster extraction\nFrom points…\nFrom line…\nFrom polygon (srtm)…\nFrom polygon (nlcd)…"
  },
  {
    "objectID": "06-raster-vector.html#rasterization",
    "href": "06-raster-vector.html#rasterization",
    "title": "6  Raster-vector interactions",
    "section": "6.5 Rasterization",
    "text": "6.5 Rasterization"
  },
  {
    "objectID": "06-raster-vector.html#spatial-vectorization",
    "href": "06-raster-vector.html#spatial-vectorization",
    "title": "6  Raster-vector interactions",
    "section": "6.6 Spatial vectorization",
    "text": "6.6 Spatial vectorization\n\nsrc = rasterio.open(\"data/grain.tif\")"
  },
  {
    "objectID": "06-raster-vector.html#exercises",
    "href": "06-raster-vector.html#exercises",
    "title": "6  Raster-vector interactions",
    "section": "6.7 Exercises",
    "text": "6.7 Exercises"
  },
  {
    "objectID": "07-reproj.html#introduction",
    "href": "07-reproj.html#introduction",
    "title": "7  Reprojecting geographic data",
    "section": "7.1 Introduction",
    "text": "7.1 Introduction"
  },
  {
    "objectID": "07-reproj.html#coordinate-reference-systems",
    "href": "07-reproj.html#coordinate-reference-systems",
    "title": "7  Reprojecting geographic data",
    "section": "7.2 Coordinate Reference Systems",
    "text": "7.2 Coordinate Reference Systems"
  },
  {
    "objectID": "07-reproj.html#querying-and-setting-coordinate-systems",
    "href": "07-reproj.html#querying-and-setting-coordinate-systems",
    "title": "7  Reprojecting geographic data",
    "section": "7.3 Querying and setting coordinate systems",
    "text": "7.3 Querying and setting coordinate systems"
  },
  {
    "objectID": "07-reproj.html#geometry-operations-on-projected-and-unprojected-data",
    "href": "07-reproj.html#geometry-operations-on-projected-and-unprojected-data",
    "title": "7  Reprojecting geographic data",
    "section": "7.4 Geometry operations on projected and unprojected data",
    "text": "7.4 Geometry operations on projected and unprojected data"
  },
  {
    "objectID": "07-reproj.html#when-to-reproject",
    "href": "07-reproj.html#when-to-reproject",
    "title": "7  Reprojecting geographic data",
    "section": "7.5 When to reproject?",
    "text": "7.5 When to reproject?"
  },
  {
    "objectID": "07-reproj.html#which-crs-to-use",
    "href": "07-reproj.html#which-crs-to-use",
    "title": "7  Reprojecting geographic data",
    "section": "7.6 Which CRS to use?",
    "text": "7.6 Which CRS to use?"
  },
  {
    "objectID": "07-reproj.html#reprojecting-vector-geometries",
    "href": "07-reproj.html#reprojecting-vector-geometries",
    "title": "7  Reprojecting geographic data",
    "section": "7.7 Reprojecting vector geometries",
    "text": "7.7 Reprojecting vector geometries"
  },
  {
    "objectID": "07-reproj.html#reprojecting-raster-geometries",
    "href": "07-reproj.html#reprojecting-raster-geometries",
    "title": "7  Reprojecting geographic data",
    "section": "7.8 Reprojecting raster geometries",
    "text": "7.8 Reprojecting raster geometries"
  },
  {
    "objectID": "07-reproj.html#custom-map-projections",
    "href": "07-reproj.html#custom-map-projections",
    "title": "7  Reprojecting geographic data",
    "section": "7.9 Custom map projections",
    "text": "7.9 Custom map projections"
  },
  {
    "objectID": "07-reproj.html#exercises",
    "href": "07-reproj.html#exercises",
    "title": "7  Reprojecting geographic data",
    "section": "7.10 Exercises",
    "text": "7.10 Exercises"
  },
  {
    "objectID": "08-read-write-plot.html#introduction",
    "href": "08-read-write-plot.html#introduction",
    "title": "8  Geographic data I/O",
    "section": "8.1 Introduction",
    "text": "8.1 Introduction"
  },
  {
    "objectID": "08-read-write-plot.html#retrieving-open-data",
    "href": "08-read-write-plot.html#retrieving-open-data",
    "title": "8  Geographic data I/O",
    "section": "8.2 Retrieving open data",
    "text": "8.2 Retrieving open data"
  },
  {
    "objectID": "08-read-write-plot.html#geographic-data-packages",
    "href": "08-read-write-plot.html#geographic-data-packages",
    "title": "8  Geographic data I/O",
    "section": "8.3 Geographic data packages",
    "text": "8.3 Geographic data packages"
  },
  {
    "objectID": "08-read-write-plot.html#geographic-web-services",
    "href": "08-read-write-plot.html#geographic-web-services",
    "title": "8  Geographic data I/O",
    "section": "8.4 Geographic web services",
    "text": "8.4 Geographic web services"
  },
  {
    "objectID": "08-read-write-plot.html#file-formats",
    "href": "08-read-write-plot.html#file-formats",
    "title": "8  Geographic data I/O",
    "section": "8.5 File formats",
    "text": "8.5 File formats"
  },
  {
    "objectID": "08-read-write-plot.html#data-input-i",
    "href": "08-read-write-plot.html#data-input-i",
    "title": "8  Geographic data I/O",
    "section": "8.6 Data input (I)",
    "text": "8.6 Data input (I)\n\n8.6.1 Vector data\n\n\n8.6.2 Raster data"
  },
  {
    "objectID": "08-read-write-plot.html#data-output-o",
    "href": "08-read-write-plot.html#data-output-o",
    "title": "8  Geographic data I/O",
    "section": "8.7 Data output (O)",
    "text": "8.7 Data output (O)\n\n8.7.1 Vector data\n\n\n8.7.2 Raster data"
  },
  {
    "objectID": "08-read-write-plot.html#visual-outputs",
    "href": "08-read-write-plot.html#visual-outputs",
    "title": "8  Geographic data I/O",
    "section": "8.8 Visual outputs",
    "text": "8.8 Visual outputs"
  },
  {
    "objectID": "08-read-write-plot.html#exercises",
    "href": "08-read-write-plot.html#exercises",
    "title": "8  Geographic data I/O",
    "section": "8.9 Exercises",
    "text": "8.9 Exercises"
  },
  {
    "objectID": "09-mapping.html#introduction",
    "href": "09-mapping.html#introduction",
    "title": "9  Making maps with Python",
    "section": "9.1 Introduction",
    "text": "9.1 Introduction"
  },
  {
    "objectID": "09-mapping.html#static-maps",
    "href": "09-mapping.html#static-maps",
    "title": "9  Making maps with Python",
    "section": "9.2 Static maps",
    "text": "9.2 Static maps\n\n9.2.1 tmap basics\n\n\n9.2.2 Map objects\n\n\n9.2.3 Aesthetics\n\n\n9.2.4 Color settings\n\n\n9.2.5 Layouts\n\n\n9.2.6 Faceted maps\n\n\n9.2.7 Inset maps"
  },
  {
    "objectID": "09-mapping.html#animated-maps",
    "href": "09-mapping.html#animated-maps",
    "title": "9  Making maps with Python",
    "section": "9.3 Animated maps",
    "text": "9.3 Animated maps"
  },
  {
    "objectID": "09-mapping.html#interactive-maps",
    "href": "09-mapping.html#interactive-maps",
    "title": "9  Making maps with Python",
    "section": "9.4 Interactive maps",
    "text": "9.4 Interactive maps"
  },
  {
    "objectID": "09-mapping.html#mapping-applications",
    "href": "09-mapping.html#mapping-applications",
    "title": "9  Making maps with Python",
    "section": "9.5 Mapping applications",
    "text": "9.5 Mapping applications"
  },
  {
    "objectID": "09-mapping.html#other-mapping-packages",
    "href": "09-mapping.html#other-mapping-packages",
    "title": "9  Making maps with Python",
    "section": "9.6 Other mapping packages",
    "text": "9.6 Other mapping packages"
  },
  {
    "objectID": "09-mapping.html#exercises",
    "href": "09-mapping.html#exercises",
    "title": "9  Making maps with Python",
    "section": "9.7 Exercises",
    "text": "9.7 Exercises"
  },
  {
    "objectID": "a1-starting.html#how-to-download-and-install-r",
    "href": "a1-starting.html#how-to-download-and-install-r",
    "title": "Appendix A — Installing R and RStudio",
    "section": "A.1 How to Download and Install R",
    "text": "A.1 How to Download and Install R\nR is maintained by an international team of developers who make the language available through the web page of The Comprehensive R Archive Network. The top of the web page provides three links for downloading R. Follow the link that describes your operating system: Windows, Mac, or Linux.\n\nA.1.1 Windows\nTo install R on Windows, click the “Download R for Windows” link. Then click the “base” link. Next, click the first link at the top of the new page. This link should say something like “Download R 3.0.3 for Windows,” except the 3.0.3 will be replaced by the most current version of R. The link downloads an installer program, which installs the most up-to-date version of R for Windows. Run this program and step through the installation wizard that appears. The wizard will install R into your program files folders and place a shortcut in your Start menu. Note that you’ll need to have all of the appropriate administration privileges to install new software on your machine.\n\n\nA.1.2 Mac\nTo install R on a Mac, click the “Download R for Mac” link. Next, click on the R-3.0.3 package link (or the package link for the most current release of R). An installer will download to guide you through the installation process, which is very easy. The installer lets you customize your installation, but the defaults will be suitable for most users. I’ve never found a reason to change them. If your computer requires a password before installing new progams, you’ll need it here.\n\n\n\n\n\n\nBinaries Versus Source\n\n\n\nR can be installed from precompiled binaries or built from source on any operating system. For Windows and Mac machines, installing R from binaries is extremely easy. The binary comes preloaded in its own installer. Although you can build R from source on these platforms, the process is much more complicated and won’t provide much benefit for most users. For Linux systems, the opposite is true. Precompiled binaries can be found for some systems, but it is much more common to build R from source files when installing on Linux. The download pages on CRAN’s website provide information about building R from source for the Windows, Mac, and Linux platforms.\n\n\n\n\nA.1.3 Linux\nR comes preinstalled on many Linux systems, but you’ll want the newest version of R if yours is out of date. The CRAN website provides files to build R from source on Debian, Redhat, SUSE, and Ubuntu systems under the link “Download R for Linux.” Click the link and then follow the directory trail to the version of Linux you wish to install on. The exact installation procedure will vary depending on the Linux system you use. CRAN guides the process by grouping each set of source files with documentation or README files that explain how to install on your system.\n\n\n\n\n\n\n32-bit Versus 64-bit\n\n\n\nR comes in both 32-bit and 64-bit versions. Which should you use? In most cases, it won’t matter. Both versions use 32-bit integers, which means they compute numbers to the same numerical precision. The difference occurs in the way each version manages memory. 64-bit R uses 64-bit memory pointers, and 32-bit R uses 32-bit memory pointers. This means 64-bit R has a larger memory space to use (and search through).\nAs a rule of thumb, 32-bit builds of R are faster than 64-bit builds, though not always. On the other hand, 64-bit builds can handle larger files and data sets with fewer memory management problems. In either version, the maximum allowable vector size tops out at around 2 billion elements. If your operating system doesn’t support 64-bit programs, or your RAM is less than 4 GB, 32-bit R is for you. The Windows and Mac installers will automatically install both versions if your system supports 64-bit R."
  },
  {
    "objectID": "a1-starting.html#using-r",
    "href": "a1-starting.html#using-r",
    "title": "Appendix A — Installing R and RStudio",
    "section": "A.2 Using R",
    "text": "A.2 Using R\nR isn’t a program that you can open and start using, like Microsoft Word or Internet Explorer. Instead, R is a computer language, like C, C++, or UNIX. You use R by writing commands in the R language and asking your computer to interpret them. In the old days, people ran R code in a UNIX terminal window—as if they were hackers in a movie from the 1980s. Now almost everyone uses R with an application called RStudio, and I recommend that you do, too.\n\n\n\n\n\n\nR and UNIX\n\n\n\nYou can still run R in a UNIX or BASH window by typing the command:\n$ R\nwhich opens an R interpreter. You can then do your work and close the interpreter by running q() when you are finished."
  },
  {
    "objectID": "a1-starting.html#rstudio",
    "href": "a1-starting.html#rstudio",
    "title": "Appendix A — Installing R and RStudio",
    "section": "A.3 RStudio",
    "text": "A.3 RStudio\nRStudio is an application like Microsoft Word—except that instead of helping you write in English, RStudio helps you write in R. I use RStudio throughout the book because it makes using R much easier. Also, the RStudio interface looks the same for Windows, Mac OS, and Linux. That will help me match the book to your personal experience.\nYou can download RStudio for free. Just click the “Download RStudio” button and follow the simple instructions that follow. Once you’ve installed RStudio, you can open it like any other program on your computer—usually by clicking an icon on your desktop.\n\n\n\n\n\n\nThe R GUIs\n\n\n\nWindows and Mac users usually do not program from a terminal window, so the Windows and Mac downloads for R come with a simple program that opens a terminal-like window for you to run R code in. This is what opens when you click the R icon on your Windows or Mac computer. These programs do a little more than the basic terminal window, but not much. You may hear people refer to them as the Windows or Mac R GUIs.\n\n\nWhen you open RStudio, a window appears with three panes in it, as in Figure A.1. The largest pane is a console window. This is where you’ll run your R code and see results. The console window is exactly what you’d see if you ran R from a UNIX console or the Windows or Mac GUIs. Everything else you see is unique to RStudio. Hidden in the other panes are a text editor, a graphics window, a debugger, a file manager, and much more. You’ll learn about these panes as they become useful throughout the course of this book.\n\n\n\nFigure A.1: The RStudio IDE for R.\n\n\n\n\n\n\n\n\nDo I still need to download R?\n\n\n\nEven if you use RStudio, you’ll still need to download R to your computer. RStudio helps you use the version of R that lives on your computer, but it doesn’t come with a version of R on its own."
  },
  {
    "objectID": "a1-starting.html#opening-r",
    "href": "a1-starting.html#opening-r",
    "title": "Appendix A — Installing R and RStudio",
    "section": "A.4 Opening R",
    "text": "A.4 Opening R\nNow that you have both R and RStudio on your computer, you can begin using R by opening the RStudio program. Open RStudio just as you would any program, by clicking on its icon or by typing “RStudio” at the Windows Run prompt."
  }
]